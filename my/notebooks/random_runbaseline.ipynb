{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cloud/myenv/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import math\n",
    "import utils.prepareDataCSV as prepare\n",
    "import utils.baselineModels as baseline\n",
    "import utils.train as train\n",
    "import utils.plot as p\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在乱序的数据集上面跑模型，注意：y仍然是按照原序的数据集来计算得到的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traint7path = '../../data/random_processed/stock0/randomOrder_train7_part0.csv'\n",
    "test7path = '../../data/random_processed/stock0/randomOrder_test7_part0.csv'\n",
    "test8path = '../../data/random_processed/stock0/randomOrder_test8_part0.csv'\n",
    "test9path = '../../data/random_processed/stock0/randomOrder_test9_part0.csv'\n",
    "dec_train, dec_val, dec_test = prepare.splitDataset(0.8,0.8,traint7path,test7path,test8path,test9path)\n",
    "train_loader, val_loader, test_loader = prepare.getDataLoader(dec_train,dec_val,dec_test,k=4,num_classes=3,T=100,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmNet(nn.Module):\n",
    "    def __init__(self, y_len, device, hidden_size=64):\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        super(LstmNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential( nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "                                    nn.LeakyReLU(negative_slope=0.01),\n",
    "                                    nn.BatchNorm2d(32),\n",
    "                                    nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "                                    nn.LeakyReLU(negative_slope=0.01),\n",
    "                                    nn.BatchNorm2d(32),\n",
    "                                    )\n",
    "        self.conv2 = nn.Sequential(\n",
    "                                    nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "                                    nn.Tanh(),\n",
    "                                    nn.BatchNorm2d(32),\n",
    "                                    nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "                                    nn.Tanh(),\n",
    "                                    nn.BatchNorm2d(32),\n",
    "                                )\n",
    "        self.conv3 = nn.Sequential( nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,10)),\n",
    "                                    nn.LeakyReLU(negative_slope=0.01),\n",
    "                                    nn.BatchNorm2d(32),\n",
    "                                    nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "                                    nn.LeakyReLU(negative_slope=0.01),\n",
    "                                    nn.BatchNorm2d(32),\n",
    "                                    )\n",
    "        # set size\n",
    "        self.lstm = nn.LSTM(input_size=32, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "        # self.relu = nn.LeakyReLU(negative_slope=0.01),\n",
    "        self.fc1 = nn.Linear(hidden_size, y_len)     \n",
    "\n",
    "    def forward(self, x):\n",
    "        # h0: (number of hidden layers, batch size, hidden size)\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(self.device)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(self.device)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        x = torch.reshape(x, (-1, x.shape[1], x.shape[2]))\n",
    "        x, _ = self.lstm(x, (h0, c0))\n",
    "        x = x[:, -1, :]\n",
    "  \n",
    "        x = self.fc1(x)\n",
    "        forecast_y = torch.softmax(x, dim=1)\n",
    "        return forecast_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LstmNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): Tanh()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): Tanh()\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 10), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (lstm): LSTM(32, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LstmNet(y_len=3, device=device, hidden_size=64)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LstmNet                                  --                        --\n",
       "├─Sequential: 1-1                        [64, 32, 97, 20]          --\n",
       "│    └─Conv2d: 2-1                       [64, 32, 100, 20]         96\n",
       "│    └─LeakyReLU: 2-2                    [64, 32, 100, 20]         --\n",
       "│    └─BatchNorm2d: 2-3                  [64, 32, 100, 20]         64\n",
       "│    └─Conv2d: 2-4                       [64, 32, 97, 20]          4,128\n",
       "│    └─LeakyReLU: 2-5                    [64, 32, 97, 20]          --\n",
       "│    └─BatchNorm2d: 2-6                  [64, 32, 97, 20]          64\n",
       "├─Sequential: 1-2                        [64, 32, 94, 10]          --\n",
       "│    └─Conv2d: 2-7                       [64, 32, 97, 10]          2,080\n",
       "│    └─Tanh: 2-8                         [64, 32, 97, 10]          --\n",
       "│    └─BatchNorm2d: 2-9                  [64, 32, 97, 10]          64\n",
       "│    └─Conv2d: 2-10                      [64, 32, 94, 10]          4,128\n",
       "│    └─Tanh: 2-11                        [64, 32, 94, 10]          --\n",
       "│    └─BatchNorm2d: 2-12                 [64, 32, 94, 10]          64\n",
       "├─Sequential: 1-3                        [64, 32, 91, 1]           --\n",
       "│    └─Conv2d: 2-13                      [64, 32, 94, 1]           10,272\n",
       "│    └─LeakyReLU: 2-14                   [64, 32, 94, 1]           --\n",
       "│    └─BatchNorm2d: 2-15                 [64, 32, 94, 1]           64\n",
       "│    └─Conv2d: 2-16                      [64, 32, 91, 1]           4,128\n",
       "│    └─LeakyReLU: 2-17                   [64, 32, 91, 1]           --\n",
       "│    └─BatchNorm2d: 2-18                 [64, 32, 91, 1]           64\n",
       "├─LSTM: 1-4                              [64, 91, 64]              25,088\n",
       "├─Linear: 1-5                            [64, 3]                   195\n",
       "==========================================================================================\n",
       "Total params: 50,499\n",
       "Trainable params: 50,499\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.13\n",
       "==========================================================================================\n",
       "Input size (MB): 1.02\n",
       "Forward/backward pass size (MB): 200.74\n",
       "Params size (MB): 0.20\n",
       "Estimated Total Size (MB): 201.96\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (64, 1, 100, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:07<05:50,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 1/50, Train Loss: 1.0709,           Validation Loss: 1.0545, Duration: 0:00:07.145034, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:14<05:37,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 2/50, Train Loss: 1.0554,           Validation Loss: 1.0539, Duration: 0:00:06.958972, Best Val Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:21<05:29,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 3/50, Train Loss: 1.0543,           Validation Loss: 1.0537, Duration: 0:00:06.994427, Best Val Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:28<05:24,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 4/50, Train Loss: 1.0512,           Validation Loss: 1.0504, Duration: 0:00:07.135409, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:35<05:18,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 5/50, Train Loss: 1.0437,           Validation Loss: 1.0455, Duration: 0:00:07.097705, Best Val Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:42<05:10,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 6/50, Train Loss: 1.0365,           Validation Loss: 1.0450, Duration: 0:00:07.045897, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:49<05:03,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Train Loss: 1.0299,           Validation Loss: 1.0464, Duration: 0:00:07.069054, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:56<04:58,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Train Loss: 1.0234,           Validation Loss: 1.0486, Duration: 0:00:07.167104, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [01:03<04:51,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Train Loss: 1.0167,           Validation Loss: 1.0514, Duration: 0:00:07.106840, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [01:10<04:44,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Train Loss: 1.0098,           Validation Loss: 1.0540, Duration: 0:00:07.130310, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [01:17<04:36,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Train Loss: 1.0020,           Validation Loss: 1.0586, Duration: 0:00:07.021829, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [01:25<04:29,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Train Loss: 0.9954,           Validation Loss: 1.0618, Duration: 0:00:07.120569, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [01:32<04:22,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Train Loss: 0.9871,           Validation Loss: 1.0652, Duration: 0:00:07.066087, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [01:38<04:12,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Train Loss: 0.9805,           Validation Loss: 1.0690, Duration: 0:00:06.885078, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [01:45<04:03,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Train Loss: 0.9737,           Validation Loss: 1.0705, Duration: 0:00:06.769825, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [01:52<03:54,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Train Loss: 0.9663,           Validation Loss: 1.0742, Duration: 0:00:06.757147, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [01:59<03:46,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Train Loss: 0.9597,           Validation Loss: 1.0779, Duration: 0:00:06.783706, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [02:06<03:39,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Train Loss: 0.9521,           Validation Loss: 1.0793, Duration: 0:00:06.903517, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [02:13<03:32,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Train Loss: 0.9463,           Validation Loss: 1.0809, Duration: 0:00:06.841652, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [02:19<03:26,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Train Loss: 0.9397,           Validation Loss: 1.0878, Duration: 0:00:06.880293, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [02:26<03:20,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Train Loss: 0.9344,           Validation Loss: 1.0883, Duration: 0:00:07.048345, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [02:34<03:15,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Train Loss: 0.9281,           Validation Loss: 1.0904, Duration: 0:00:07.059939, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [02:41<03:08,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Train Loss: 0.9229,           Validation Loss: 1.0924, Duration: 0:00:07.025449, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [02:48<03:02,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Train Loss: 0.9179,           Validation Loss: 1.0942, Duration: 0:00:07.067906, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [02:55<02:55,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Train Loss: 0.9123,           Validation Loss: 1.0946, Duration: 0:00:07.032223, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [03:02<02:48,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Train Loss: 0.9093,           Validation Loss: 1.0976, Duration: 0:00:07.065248, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [03:09<02:41,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Train Loss: 0.9043,           Validation Loss: 1.0982, Duration: 0:00:07.053652, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [03:16<02:35,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Train Loss: 0.8998,           Validation Loss: 1.0996, Duration: 0:00:07.129627, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [03:23<02:28,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Train Loss: 0.8968,           Validation Loss: 1.1002, Duration: 0:00:07.148861, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [03:30<02:21,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Train Loss: 0.8935,           Validation Loss: 1.0979, Duration: 0:00:07.101448, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [03:37<02:14,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Train Loss: 0.8905,           Validation Loss: 1.0979, Duration: 0:00:07.055009, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [03:44<02:05,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Train Loss: 0.8868,           Validation Loss: 1.0997, Duration: 0:00:06.771065, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [03:51<01:57,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Train Loss: 0.8844,           Validation Loss: 1.1021, Duration: 0:00:06.738149, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [03:57<01:49,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Train Loss: 0.8818,           Validation Loss: 1.1010, Duration: 0:00:06.735451, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [04:04<01:42,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Train Loss: 0.8797,           Validation Loss: 1.1017, Duration: 0:00:06.841449, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [04:11<01:35,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Train Loss: 0.8767,           Validation Loss: 1.1041, Duration: 0:00:06.809484, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [04:18<01:29,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Train Loss: 0.8749,           Validation Loss: 1.1023, Duration: 0:00:07.013063, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [04:25<01:22,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Train Loss: 0.8722,           Validation Loss: 1.1034, Duration: 0:00:06.769347, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [04:32<01:15,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Train Loss: 0.8712,           Validation Loss: 1.1056, Duration: 0:00:06.758711, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [04:39<01:08,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Train Loss: 0.8692,           Validation Loss: 1.1050, Duration: 0:00:06.989633, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [04:45<01:01,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Train Loss: 0.8675,           Validation Loss: 1.1050, Duration: 0:00:06.835466, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [04:52<00:54,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Train Loss: 0.8669,           Validation Loss: 1.1059, Duration: 0:00:06.890411, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [04:59<00:48,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Train Loss: 0.8648,           Validation Loss: 1.1049, Duration: 0:00:06.917790, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [05:06<00:41,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Train Loss: 0.8630,           Validation Loss: 1.1063, Duration: 0:00:06.920424, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [05:13<00:34,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Train Loss: 0.8627,           Validation Loss: 1.1043, Duration: 0:00:07.128547, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [05:20<00:27,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Train Loss: 0.8622,           Validation Loss: 1.1055, Duration: 0:00:06.949453, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [05:27<00:20,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Train Loss: 0.8604,           Validation Loss: 1.1088, Duration: 0:00:06.852676, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [05:34<00:13,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Train Loss: 0.8593,           Validation Loss: 1.1109, Duration: 0:00:06.932093, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [05:41<00:06,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Train Loss: 0.8587,           Validation Loss: 1.1085, Duration: 0:00:06.835437, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [05:48<00:00,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Train Loss: 0.8579,           Validation Loss: 1.1092, Duration: 0:00:06.822841, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "train_losses, val_losses = train.batch_gd(model, criterion, optimizer, train_loader, val_loader, epochs=50, device=device, savedModelName='./savedModels_randomOrder/LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3654    0.5547    0.4406      9558\n",
      "           1     0.0000    0.0000    0.0000      9503\n",
      "           2     0.3470    0.5274    0.4186      8756\n",
      "\n",
      "    accuracy                         0.3566     27817\n",
      "   macro avg     0.2375    0.3607    0.2864     27817\n",
      "weighted avg     0.2348    0.3566    0.2832     27817\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cloud/myenv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cloud/myenv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cloud/myenv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./savedModels_randomOrder/LSTM')\n",
    "all_targets, all_predictions = p.getReport(test_loader, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果表明直接使用之前的Y效果很差，所以需要将Y重构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算出midPrice变化的各个离散值 按照1：1：1的比值将他们划分为3类 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traint7path = '../../data/random_processed/stock0/randomOrder_train7_part0.csv'\n",
    "test7path = '../../data/random_processed/stock0/randomOrder_test7_part0.csv'\n",
    "test8path = '../../data/random_processed/stock0/randomOrder_test8_part0.csv'\n",
    "test9path = '../../data/random_processed/stock0/randomOrder_test9_part0.csv'\n",
    "df1 = pd.read_csv(traint7path)\n",
    "df2 = pd.read_csv(test7path)\n",
    "df3 = pd.read_csv(test8path)\n",
    "df4 = pd.read_csv(test9path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>midprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3466</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.3455</td>\n",
       "      <td>0.00369</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.00702</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.3468</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.34605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1730</td>\n",
       "      <td>0.06079</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.03289</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>0.04800</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.02355</td>\n",
       "      <td>0.1732</td>\n",
       "      <td>0.05670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.17285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1261</td>\n",
       "      <td>0.01511</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.02800</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>0.01216</td>\n",
       "      <td>0.1259</td>\n",
       "      <td>0.04169</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.02200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.12605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1304</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.01092</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.03820</td>\n",
       "      <td>0.1301</td>\n",
       "      <td>0.05760</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.01300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.13030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1264</td>\n",
       "      <td>0.00318</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>0.1265</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0.1261</td>\n",
       "      <td>0.01650</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.03910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.12630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50945</th>\n",
       "      <td>0.3503</td>\n",
       "      <td>0.01471</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.00171</td>\n",
       "      <td>0.3505</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.3495</td>\n",
       "      <td>0.01657</td>\n",
       "      <td>0.3506</td>\n",
       "      <td>0.00450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.35015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50946</th>\n",
       "      <td>0.2681</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>0.2683</td>\n",
       "      <td>0.00388</td>\n",
       "      <td>0.2672</td>\n",
       "      <td>0.01136</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>0.00267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.26770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50947</th>\n",
       "      <td>0.3524</td>\n",
       "      <td>0.00300</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.3525</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>0.3514</td>\n",
       "      <td>0.00690</td>\n",
       "      <td>0.3529</td>\n",
       "      <td>0.00490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.35195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50948</th>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.00288</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.01471</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.03018</td>\n",
       "      <td>0.1309</td>\n",
       "      <td>0.01768</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.01500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.13105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50949</th>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.01248</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.01720</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>0.01593</td>\n",
       "      <td>0.1269</td>\n",
       "      <td>0.02373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50950 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0        1       2        3       4        5       6        7  \\\n",
       "0      0.3466  0.00100  0.3455  0.00369  0.3467  0.00702  0.3450  0.00200   \n",
       "1      0.1730  0.06079  0.1727  0.03289  0.1731  0.04800  0.1726  0.02355   \n",
       "2      0.1261  0.01511  0.1260  0.02800  0.1262  0.01216  0.1259  0.04169   \n",
       "3      0.1304  0.02000  0.1302  0.01092  0.1305  0.03820  0.1301  0.05760   \n",
       "4      0.1264  0.00318  0.1262  0.01770  0.1265  0.00500  0.1261  0.01650   \n",
       "...       ...      ...     ...      ...     ...      ...     ...      ...   \n",
       "50945  0.3503  0.01471  0.3500  0.00171  0.3505  0.00100  0.3495  0.01657   \n",
       "50946  0.2681  0.00100  0.2673  0.00076  0.2683  0.00388  0.2672  0.01136   \n",
       "50947  0.3524  0.00300  0.3515  0.00200  0.3525  0.00293  0.3514  0.00690   \n",
       "50948  0.1311  0.00288  0.1310  0.01471  0.1312  0.03018  0.1309  0.01768   \n",
       "50949  0.1267  0.01248  0.1263  0.01720  0.1268  0.01800  0.1262  0.01593   \n",
       "\n",
       "            8        9  ...       140  141  142  143  144  145  146  147  148  \\\n",
       "0      0.3468  0.00200  ...  0.250617  0.0  0.0  0.0  3.0  2.0  3.0  3.0  1.0   \n",
       "1      0.1732  0.05670  ...  0.031428  0.0  0.0  0.0  2.0  2.0  2.0  3.0  1.0   \n",
       "2      0.1263  0.02200  ...  0.099537  0.0  0.0  0.0  1.0  1.0  1.0  1.0  3.0   \n",
       "3      0.1306  0.01300  ...  0.005489  0.0  0.0  0.0  2.0  2.0  2.0  1.0  1.0   \n",
       "4      0.1266  0.03910  ...  0.001936  0.0  0.0  0.0  2.0  3.0  3.0  3.0  3.0   \n",
       "...       ...      ...  ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "50945  0.3506  0.00450  ...  0.149009  0.0  0.0  0.0  2.0  2.0  2.0  2.0  2.0   \n",
       "50946  0.2684  0.00267  ...  0.127042  0.0  0.0  0.0  1.0  1.0  1.0  3.0  1.0   \n",
       "50947  0.3529  0.00490  ...  0.059051  0.0  0.0  0.0  2.0  1.0  1.0  2.0  1.0   \n",
       "50948  0.1313  0.01500  ...  0.001280  0.0  0.0  0.0  2.0  2.0  2.0  3.0  3.0   \n",
       "50949  0.1269  0.02373  ...  0.008547  0.0  0.0  0.0  2.0  1.0  1.0  1.0  2.0   \n",
       "\n",
       "       midprice  \n",
       "0       0.34605  \n",
       "1       0.17285  \n",
       "2       0.12605  \n",
       "3       0.13030  \n",
       "4       0.12630  \n",
       "...         ...  \n",
       "50945   0.35015  \n",
       "50946   0.26770  \n",
       "50947   0.35195  \n",
       "50948   0.13105  \n",
       "50949   0.12650  \n",
       "\n",
       "[50950 rows x 150 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['midprice'] = (df1['0']+df1['2'])/2.0\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34605, 0.17285, 0.12605, ..., 0.35195, 0.13105, 0.1265 ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MP_array = np.array(df1['midprice'])\n",
    "MP_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5188999999999999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(MP_array[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将每个元素替换为预测范围内的MP变化率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(MP_array)\n",
    "T = 10\n",
    "newArray = []\n",
    "for i in range(N):\n",
    "    # 前面大部分元素\n",
    "    if i<=N-1-T:\n",
    "        tmp = (np.mean(MP_array[i:i+T])-MP_array[i])/MP_array[i]\n",
    "        newArray.append(tmp)\n",
    "    # 对于最后一个元素 由于其没有后继 故补充0\n",
    "    elif i==N-1:\n",
    "        newArray.append(0)\n",
    "    # 尾部元素只需要计算剩下的全部值的均值即可\n",
    "    else:\n",
    "        tmp = (np.mean(MP_array[i:-1])-MP_array[i])/MP_array[i]\n",
    "        newArray.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>midprice</th>\n",
       "      <th>MPchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3466</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.3455</td>\n",
       "      <td>0.00369</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.00702</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.3468</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.34605</td>\n",
       "      <td>-0.468747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1730</td>\n",
       "      <td>0.06079</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.03289</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>0.04800</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.02355</td>\n",
       "      <td>0.1732</td>\n",
       "      <td>0.05670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.17285</td>\n",
       "      <td>0.061788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1261</td>\n",
       "      <td>0.01511</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.02800</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>0.01216</td>\n",
       "      <td>0.1259</td>\n",
       "      <td>0.04169</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.02200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.12605</td>\n",
       "      <td>0.531813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1304</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.01092</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.03820</td>\n",
       "      <td>0.1301</td>\n",
       "      <td>0.05760</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.01300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.13030</td>\n",
       "      <td>0.482310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1264</td>\n",
       "      <td>0.00318</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>0.1265</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0.1261</td>\n",
       "      <td>0.01650</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.03910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.12630</td>\n",
       "      <td>0.703919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50945</th>\n",
       "      <td>0.3503</td>\n",
       "      <td>0.01471</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.00171</td>\n",
       "      <td>0.3505</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.3495</td>\n",
       "      <td>0.01657</td>\n",
       "      <td>0.3506</td>\n",
       "      <td>0.00450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.35015</td>\n",
       "      <td>-0.214015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50946</th>\n",
       "      <td>0.2681</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>0.2683</td>\n",
       "      <td>0.00388</td>\n",
       "      <td>0.2672</td>\n",
       "      <td>0.01136</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>0.00267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.26770</td>\n",
       "      <td>-0.065247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50947</th>\n",
       "      <td>0.3524</td>\n",
       "      <td>0.00300</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.3525</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>0.3514</td>\n",
       "      <td>0.00690</td>\n",
       "      <td>0.3529</td>\n",
       "      <td>0.00490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.35195</td>\n",
       "      <td>-0.313823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50948</th>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.00288</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.01471</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.03018</td>\n",
       "      <td>0.1309</td>\n",
       "      <td>0.01768</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.01500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.13105</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50949</th>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.01248</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.01720</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>0.01593</td>\n",
       "      <td>0.1269</td>\n",
       "      <td>0.02373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50950 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0        1       2        3       4        5       6        7  \\\n",
       "0      0.3466  0.00100  0.3455  0.00369  0.3467  0.00702  0.3450  0.00200   \n",
       "1      0.1730  0.06079  0.1727  0.03289  0.1731  0.04800  0.1726  0.02355   \n",
       "2      0.1261  0.01511  0.1260  0.02800  0.1262  0.01216  0.1259  0.04169   \n",
       "3      0.1304  0.02000  0.1302  0.01092  0.1305  0.03820  0.1301  0.05760   \n",
       "4      0.1264  0.00318  0.1262  0.01770  0.1265  0.00500  0.1261  0.01650   \n",
       "...       ...      ...     ...      ...     ...      ...     ...      ...   \n",
       "50945  0.3503  0.01471  0.3500  0.00171  0.3505  0.00100  0.3495  0.01657   \n",
       "50946  0.2681  0.00100  0.2673  0.00076  0.2683  0.00388  0.2672  0.01136   \n",
       "50947  0.3524  0.00300  0.3515  0.00200  0.3525  0.00293  0.3514  0.00690   \n",
       "50948  0.1311  0.00288  0.1310  0.01471  0.1312  0.03018  0.1309  0.01768   \n",
       "50949  0.1267  0.01248  0.1263  0.01720  0.1268  0.01800  0.1262  0.01593   \n",
       "\n",
       "            8        9  ...  141  142  143  144  145  146  147  148  midprice  \\\n",
       "0      0.3468  0.00200  ...  0.0  0.0  0.0  3.0  2.0  3.0  3.0  1.0   0.34605   \n",
       "1      0.1732  0.05670  ...  0.0  0.0  0.0  2.0  2.0  2.0  3.0  1.0   0.17285   \n",
       "2      0.1263  0.02200  ...  0.0  0.0  0.0  1.0  1.0  1.0  1.0  3.0   0.12605   \n",
       "3      0.1306  0.01300  ...  0.0  0.0  0.0  2.0  2.0  2.0  1.0  1.0   0.13030   \n",
       "4      0.1266  0.03910  ...  0.0  0.0  0.0  2.0  3.0  3.0  3.0  3.0   0.12630   \n",
       "...       ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
       "50945  0.3506  0.00450  ...  0.0  0.0  0.0  2.0  2.0  2.0  2.0  2.0   0.35015   \n",
       "50946  0.2684  0.00267  ...  0.0  0.0  0.0  1.0  1.0  1.0  3.0  1.0   0.26770   \n",
       "50947  0.3529  0.00490  ...  0.0  0.0  0.0  2.0  1.0  1.0  2.0  1.0   0.35195   \n",
       "50948  0.1313  0.01500  ...  0.0  0.0  0.0  2.0  2.0  2.0  3.0  3.0   0.13105   \n",
       "50949  0.1269  0.02373  ...  0.0  0.0  0.0  2.0  1.0  1.0  1.0  2.0   0.12650   \n",
       "\n",
       "       MPchange  \n",
       "0     -0.468747  \n",
       "1      0.061788  \n",
       "2      0.531813  \n",
       "3      0.482310  \n",
       "4      0.703919  \n",
       "...         ...  \n",
       "50945 -0.214015  \n",
       "50946 -0.065247  \n",
       "50947 -0.313823  \n",
       "50948  0.000000  \n",
       "50949  0.000000  \n",
       "\n",
       "[50950 rows x 151 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['MPchange'] = np.array(newArray)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找2个三分位数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.22243820738917294, 0.4965095282925824)\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df1['MPchange'])\n",
    "point1, point2 = np.percentile(a,33), np.percentile(a,66)\n",
    "print((point1,point2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_y(inArray, point1, point2):\n",
    "    outarray = []\n",
    "    for x in inArray:\n",
    "        if x<point1:\n",
    "            outarray.append(0)\n",
    "        elif x>point2:\n",
    "            outarray.append(2)\n",
    "        else:\n",
    "            outarray.append(1)\n",
    "    outarray = np.array(outarray)\n",
    "    return outarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>midprice</th>\n",
       "      <th>MPchange</th>\n",
       "      <th>y10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3466</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.3455</td>\n",
       "      <td>0.00369</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.00702</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.3468</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.34605</td>\n",
       "      <td>-0.468747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1730</td>\n",
       "      <td>0.06079</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.03289</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>0.04800</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.02355</td>\n",
       "      <td>0.1732</td>\n",
       "      <td>0.05670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.17285</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1261</td>\n",
       "      <td>0.01511</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.02800</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>0.01216</td>\n",
       "      <td>0.1259</td>\n",
       "      <td>0.04169</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.02200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.12605</td>\n",
       "      <td>0.531813</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1304</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.01092</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.03820</td>\n",
       "      <td>0.1301</td>\n",
       "      <td>0.05760</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.01300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.13030</td>\n",
       "      <td>0.482310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1264</td>\n",
       "      <td>0.00318</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>0.1265</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0.1261</td>\n",
       "      <td>0.01650</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.03910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.12630</td>\n",
       "      <td>0.703919</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50945</th>\n",
       "      <td>0.3503</td>\n",
       "      <td>0.01471</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.00171</td>\n",
       "      <td>0.3505</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.3495</td>\n",
       "      <td>0.01657</td>\n",
       "      <td>0.3506</td>\n",
       "      <td>0.00450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.35015</td>\n",
       "      <td>-0.214015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50946</th>\n",
       "      <td>0.2681</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>0.2683</td>\n",
       "      <td>0.00388</td>\n",
       "      <td>0.2672</td>\n",
       "      <td>0.01136</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>0.00267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.26770</td>\n",
       "      <td>-0.065247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50947</th>\n",
       "      <td>0.3524</td>\n",
       "      <td>0.00300</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.3525</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>0.3514</td>\n",
       "      <td>0.00690</td>\n",
       "      <td>0.3529</td>\n",
       "      <td>0.00490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.35195</td>\n",
       "      <td>-0.313823</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50948</th>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.00288</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.01471</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.03018</td>\n",
       "      <td>0.1309</td>\n",
       "      <td>0.01768</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.01500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.13105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50949</th>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.01248</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.01720</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>0.01593</td>\n",
       "      <td>0.1269</td>\n",
       "      <td>0.02373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50950 rows × 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0        1       2        3       4        5       6        7  \\\n",
       "0      0.3466  0.00100  0.3455  0.00369  0.3467  0.00702  0.3450  0.00200   \n",
       "1      0.1730  0.06079  0.1727  0.03289  0.1731  0.04800  0.1726  0.02355   \n",
       "2      0.1261  0.01511  0.1260  0.02800  0.1262  0.01216  0.1259  0.04169   \n",
       "3      0.1304  0.02000  0.1302  0.01092  0.1305  0.03820  0.1301  0.05760   \n",
       "4      0.1264  0.00318  0.1262  0.01770  0.1265  0.00500  0.1261  0.01650   \n",
       "...       ...      ...     ...      ...     ...      ...     ...      ...   \n",
       "50945  0.3503  0.01471  0.3500  0.00171  0.3505  0.00100  0.3495  0.01657   \n",
       "50946  0.2681  0.00100  0.2673  0.00076  0.2683  0.00388  0.2672  0.01136   \n",
       "50947  0.3524  0.00300  0.3515  0.00200  0.3525  0.00293  0.3514  0.00690   \n",
       "50948  0.1311  0.00288  0.1310  0.01471  0.1312  0.03018  0.1309  0.01768   \n",
       "50949  0.1267  0.01248  0.1263  0.01720  0.1268  0.01800  0.1262  0.01593   \n",
       "\n",
       "            8        9  ...  142  143  144  145  146  147  148  midprice  \\\n",
       "0      0.3468  0.00200  ...  0.0  0.0  3.0  2.0  3.0  3.0  1.0   0.34605   \n",
       "1      0.1732  0.05670  ...  0.0  0.0  2.0  2.0  2.0  3.0  1.0   0.17285   \n",
       "2      0.1263  0.02200  ...  0.0  0.0  1.0  1.0  1.0  1.0  3.0   0.12605   \n",
       "3      0.1306  0.01300  ...  0.0  0.0  2.0  2.0  2.0  1.0  1.0   0.13030   \n",
       "4      0.1266  0.03910  ...  0.0  0.0  2.0  3.0  3.0  3.0  3.0   0.12630   \n",
       "...       ...      ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
       "50945  0.3506  0.00450  ...  0.0  0.0  2.0  2.0  2.0  2.0  2.0   0.35015   \n",
       "50946  0.2684  0.00267  ...  0.0  0.0  1.0  1.0  1.0  3.0  1.0   0.26770   \n",
       "50947  0.3529  0.00490  ...  0.0  0.0  2.0  1.0  1.0  2.0  1.0   0.35195   \n",
       "50948  0.1313  0.01500  ...  0.0  0.0  2.0  2.0  2.0  3.0  3.0   0.13105   \n",
       "50949  0.1269  0.02373  ...  0.0  0.0  2.0  1.0  1.0  1.0  2.0   0.12650   \n",
       "\n",
       "       MPchange  y10  \n",
       "0     -0.468747    0  \n",
       "1      0.061788    1  \n",
       "2      0.531813    2  \n",
       "3      0.482310    1  \n",
       "4      0.703919    2  \n",
       "...         ...  ...  \n",
       "50945 -0.214015    1  \n",
       "50946 -0.065247    1  \n",
       "50947 -0.313823    0  \n",
       "50948  0.000000    1  \n",
       "50949  0.000000    1  \n",
       "\n",
       "[50950 rows x 152 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = create_y(a, point1, point2)\n",
    "df1['y10'] = y_array\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试drop列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>midprice</th>\n",
       "      <th>MPchange</th>\n",
       "      <th>y10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3466</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.3455</td>\n",
       "      <td>0.00369</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.00702</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.3468</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250617</td>\n",
       "      <td>0.250617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.34605</td>\n",
       "      <td>-0.468747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1730</td>\n",
       "      <td>0.06079</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.03289</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>0.04800</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.02355</td>\n",
       "      <td>0.1732</td>\n",
       "      <td>0.05670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031428</td>\n",
       "      <td>0.031428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17285</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1261</td>\n",
       "      <td>0.01511</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.02800</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>0.01216</td>\n",
       "      <td>0.1259</td>\n",
       "      <td>0.04169</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.02200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099537</td>\n",
       "      <td>0.099537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12605</td>\n",
       "      <td>0.531813</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1304</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.01092</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.03820</td>\n",
       "      <td>0.1301</td>\n",
       "      <td>0.05760</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.01300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13030</td>\n",
       "      <td>0.482310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1264</td>\n",
       "      <td>0.00318</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>0.1265</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0.1261</td>\n",
       "      <td>0.01650</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.03910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12630</td>\n",
       "      <td>0.703919</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50945</th>\n",
       "      <td>0.3503</td>\n",
       "      <td>0.01471</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.00171</td>\n",
       "      <td>0.3505</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.3495</td>\n",
       "      <td>0.01657</td>\n",
       "      <td>0.3506</td>\n",
       "      <td>0.00450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149009</td>\n",
       "      <td>0.149009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35015</td>\n",
       "      <td>-0.214015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50946</th>\n",
       "      <td>0.2681</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>0.2683</td>\n",
       "      <td>0.00388</td>\n",
       "      <td>0.2672</td>\n",
       "      <td>0.01136</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>0.00267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127042</td>\n",
       "      <td>0.127042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26770</td>\n",
       "      <td>-0.065247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50947</th>\n",
       "      <td>0.3524</td>\n",
       "      <td>0.00300</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.3525</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>0.3514</td>\n",
       "      <td>0.00690</td>\n",
       "      <td>0.3529</td>\n",
       "      <td>0.00490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059051</td>\n",
       "      <td>0.059051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35195</td>\n",
       "      <td>-0.313823</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50948</th>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.00288</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.01471</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.03018</td>\n",
       "      <td>0.1309</td>\n",
       "      <td>0.01768</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.01500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50949</th>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.01248</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.01720</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>0.01593</td>\n",
       "      <td>0.1269</td>\n",
       "      <td>0.02373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50950 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0        1       2        3       4        5       6        7  \\\n",
       "0      0.3466  0.00100  0.3455  0.00369  0.3467  0.00702  0.3450  0.00200   \n",
       "1      0.1730  0.06079  0.1727  0.03289  0.1731  0.04800  0.1726  0.02355   \n",
       "2      0.1261  0.01511  0.1260  0.02800  0.1262  0.01216  0.1259  0.04169   \n",
       "3      0.1304  0.02000  0.1302  0.01092  0.1305  0.03820  0.1301  0.05760   \n",
       "4      0.1264  0.00318  0.1262  0.01770  0.1265  0.00500  0.1261  0.01650   \n",
       "...       ...      ...     ...      ...     ...      ...     ...      ...   \n",
       "50945  0.3503  0.01471  0.3500  0.00171  0.3505  0.00100  0.3495  0.01657   \n",
       "50946  0.2681  0.00100  0.2673  0.00076  0.2683  0.00388  0.2672  0.01136   \n",
       "50947  0.3524  0.00300  0.3515  0.00200  0.3525  0.00293  0.3514  0.00690   \n",
       "50948  0.1311  0.00288  0.1310  0.01471  0.1312  0.03018  0.1309  0.01768   \n",
       "50949  0.1267  0.01248  0.1263  0.01720  0.1268  0.01800  0.1262  0.01593   \n",
       "\n",
       "            8        9  ...  137       138       139       140  141  142  143  \\\n",
       "0      0.3468  0.00200  ...  0.0  0.000000  0.250617  0.250617  0.0  0.0  0.0   \n",
       "1      0.1732  0.05670  ...  0.0  0.000000  0.031428  0.031428  0.0  0.0  0.0   \n",
       "2      0.1263  0.02200  ...  0.0  0.000000  0.099537  0.099537  0.0  0.0  0.0   \n",
       "3      0.1306  0.01300  ...  0.0  0.000000  0.005489  0.005489  0.0  0.0  0.0   \n",
       "4      0.1266  0.03910  ...  0.0  0.000093  0.001843  0.001936  0.0  0.0  0.0   \n",
       "...       ...      ...  ...  ...       ...       ...       ...  ...  ...  ...   \n",
       "50945  0.3506  0.00450  ...  0.0  0.000000  0.149009  0.149009  0.0  0.0  0.0   \n",
       "50946  0.2684  0.00267  ...  0.0  0.000000  0.127042  0.127042  0.0  0.0  0.0   \n",
       "50947  0.3529  0.00490  ...  0.0  0.000000  0.059051  0.059051  0.0  0.0  0.0   \n",
       "50948  0.1313  0.01500  ...  0.0  0.000000  0.001280  0.001280  0.0  0.0  0.0   \n",
       "50949  0.1269  0.02373  ...  0.0  0.000000  0.008547  0.008547  0.0  0.0  0.0   \n",
       "\n",
       "       midprice  MPchange  y10  \n",
       "0       0.34605 -0.468747    0  \n",
       "1       0.17285  0.061788    1  \n",
       "2       0.12605  0.531813    2  \n",
       "3       0.13030  0.482310    1  \n",
       "4       0.12630  0.703919    2  \n",
       "...         ...       ...  ...  \n",
       "50945   0.35015 -0.214015    1  \n",
       "50946   0.26770 -0.065247    1  \n",
       "50947   0.35195 -0.313823    0  \n",
       "50948   0.13105  0.000000    1  \n",
       "50949   0.12650  0.000000    1  \n",
       "\n",
       "[50950 rows x 147 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.drop(columns=['144','145','146','147','148'],inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将前面的方法等装成一整个函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeDF(indf,T=10):\n",
    "    indf['midprice'] = (indf['0']+indf['2'])/2.0\n",
    "    MP_array = np.array(indf['midprice'])\n",
    "    N = len(MP_array)\n",
    "    newArray = []\n",
    "    for i in range(N):\n",
    "        # 前面大部分元素\n",
    "        if i<=N-1-T:\n",
    "            tmp = (np.mean(MP_array[i:i+T])-MP_array[i])/MP_array[i]\n",
    "            newArray.append(tmp)\n",
    "        # 对于最后一个元素 由于其没有后继 故补充0\n",
    "        elif i==N-1:\n",
    "            newArray.append(0)\n",
    "        # 尾部元素只需要计算剩下的全部值的均值即可\n",
    "        else:\n",
    "            tmp = (np.mean(MP_array[i:-1])-MP_array[i])/MP_array[i]\n",
    "            newArray.append(tmp)\n",
    "    indf['MPchange'] = np.array(newArray)\n",
    "    # 下面开始找三分位点\n",
    "    a=np.array(indf['MPchange'])\n",
    "    point1, point2 = np.percentile(a,33), np.percentile(a,66)\n",
    "    y_array = create_y(a, point1, point2)\n",
    "    indf[f'y{T}'] = y_array\n",
    "    indf.drop(columns=['144','145','146','147','148'],inplace=True)\n",
    "    return indf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将每个文件重新创建label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath = '../../data/random_processed/stock4/randomOrder_test9_part4.csv'\n",
    "df = pd.read_csv(inpath)\n",
    "outdf = changeDF(df)\n",
    "outdf.to_csv('../../data/random_processed/stock4/newY_test9_part4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在newY的文件上重跑实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train7path = '../../data/random_processed/stock0/newY_train7_part0.csv'\n",
    "test7path = '../../data/random_processed/stock0/newY_test7_part0.csv'\n",
    "test8path = '../../data/random_processed/stock0/newY_test8_part0.csv'\n",
    "test9path = '../../data/random_processed/stock0/newY_test9_part0.csv'\n",
    "dec_train, dec_val, dec_test = prepare.splitDataset(0.8,0.8,train7path,test7path,test8path,test9path)\n",
    "train_loader, val_loader, test_loader = prepare.getDataLoader(dec_train,dec_val,dec_test,k=-1,num_classes=3,T=100,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LstmNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): Tanh()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): Tanh()\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 10), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (lstm): LSTM(32, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = baseline.LstmNet(y_len=3, device=device, hidden_size=64)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LstmNet                                  --                        --\n",
       "├─Sequential: 1-1                        [64, 32, 97, 20]          --\n",
       "│    └─Conv2d: 2-1                       [64, 32, 100, 20]         96\n",
       "│    └─LeakyReLU: 2-2                    [64, 32, 100, 20]         --\n",
       "│    └─BatchNorm2d: 2-3                  [64, 32, 100, 20]         64\n",
       "│    └─Conv2d: 2-4                       [64, 32, 97, 20]          4,128\n",
       "│    └─LeakyReLU: 2-5                    [64, 32, 97, 20]          --\n",
       "│    └─BatchNorm2d: 2-6                  [64, 32, 97, 20]          64\n",
       "├─Sequential: 1-2                        [64, 32, 94, 10]          --\n",
       "│    └─Conv2d: 2-7                       [64, 32, 97, 10]          2,080\n",
       "│    └─Tanh: 2-8                         [64, 32, 97, 10]          --\n",
       "│    └─BatchNorm2d: 2-9                  [64, 32, 97, 10]          64\n",
       "│    └─Conv2d: 2-10                      [64, 32, 94, 10]          4,128\n",
       "│    └─Tanh: 2-11                        [64, 32, 94, 10]          --\n",
       "│    └─BatchNorm2d: 2-12                 [64, 32, 94, 10]          64\n",
       "├─Sequential: 1-3                        [64, 32, 91, 1]           --\n",
       "│    └─Conv2d: 2-13                      [64, 32, 94, 1]           10,272\n",
       "│    └─LeakyReLU: 2-14                   [64, 32, 94, 1]           --\n",
       "│    └─BatchNorm2d: 2-15                 [64, 32, 94, 1]           64\n",
       "│    └─Conv2d: 2-16                      [64, 32, 91, 1]           4,128\n",
       "│    └─LeakyReLU: 2-17                   [64, 32, 91, 1]           --\n",
       "│    └─BatchNorm2d: 2-18                 [64, 32, 91, 1]           64\n",
       "├─LSTM: 1-4                              [64, 91, 64]              25,088\n",
       "├─Linear: 1-5                            [64, 3]                   195\n",
       "==========================================================================================\n",
       "Total params: 50,499\n",
       "Trainable params: 50,499\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.13\n",
       "==========================================================================================\n",
       "Input size (MB): 1.02\n",
       "Forward/backward pass size (MB): 200.74\n",
       "Params size (MB): 0.20\n",
       "Estimated Total Size (MB): 201.96\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (64, 1, 100, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:07<06:07,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 1/50, Train Loss: 0.7146,           Validation Loss: 0.7027, Duration: 0:00:07.503053, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:15<06:05,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 2/50, Train Loss: 0.7147,           Validation Loss: 0.7027, Duration: 0:00:07.692009, Best Val Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:22<05:59,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 3/50, Train Loss: 0.7159,           Validation Loss: 0.7027, Duration: 0:00:07.669647, Best Val Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:30<05:49,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 4/50, Train Loss: 0.7146,           Validation Loss: 0.7027, Duration: 0:00:07.550642, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:37<05:35,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Train Loss: 0.7147,           Validation Loss: 0.7027, Duration: 0:00:07.160292, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:44<05:23,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Train Loss: 0.7146,           Validation Loss: 0.7027, Duration: 0:00:07.173845, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:51<05:14,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Train Loss: 0.7145,           Validation Loss: 0.7027, Duration: 0:00:07.213289, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:59<05:04,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Train Loss: 0.7145,           Validation Loss: 0.7027, Duration: 0:00:07.108026, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [01:06<04:56,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Train Loss: 0.7147,           Validation Loss: 0.7027, Duration: 0:00:07.165577, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [01:13<04:45,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Train Loss: 0.7156,           Validation Loss: 0.7027, Duration: 0:00:06.923033, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [01:20<04:35,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Train Loss: 0.7147,           Validation Loss: 0.7027, Duration: 0:00:06.895480, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [01:27<04:29,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Train Loss: 0.7148,           Validation Loss: 0.7027, Duration: 0:00:07.178605, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [01:34<04:21,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Train Loss: 0.7145,           Validation Loss: 0.7027, Duration: 0:00:06.983788, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [01:41<04:12,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Train Loss: 0.7145,           Validation Loss: 0.7027, Duration: 0:00:06.895926, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [01:48<04:05,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Train Loss: 0.7146,           Validation Loss: 0.7027, Duration: 0:00:07.004533, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [01:55<03:57,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Train Loss: 0.7146,           Validation Loss: 0.7027, Duration: 0:00:06.950320, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [02:02<03:50,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Train Loss: 0.7145,           Validation Loss: 0.7027, Duration: 0:00:06.934054, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [02:09<03:46,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Train Loss: 0.7145,           Validation Loss: 0.7027, Duration: 0:00:07.309213, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [02:16<03:38,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Train Loss: 0.7147,           Validation Loss: 0.7027, Duration: 0:00:06.985101, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [02:23<03:31,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Train Loss: 0.7146,           Validation Loss: 0.7027, Duration: 0:00:07.084501, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [02:30<03:24,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Train Loss: 0.7145,           Validation Loss: 0.7027, Duration: 0:00:07.067125, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [02:37<03:18,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Train Loss: 0.7147,           Validation Loss: 0.7027, Duration: 0:00:07.161374, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [02:44<03:12,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Train Loss: 0.7147,           Validation Loss: 0.7027, Duration: 0:00:07.247910, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [02:51<03:04,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Train Loss: 0.7147,           Validation Loss: 0.7027, Duration: 0:00:06.965910, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [02:58<02:56,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Train Loss: 0.7145,           Validation Loss: 0.7027, Duration: 0:00:06.957939, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [03:05<02:48,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Train Loss: 0.7145,           Validation Loss: 0.7027, Duration: 0:00:07.001042, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [03:12<02:41,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Train Loss: 0.7145,           Validation Loss: 0.7027, Duration: 0:00:06.979869, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [03:19<02:32,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Train Loss: 0.7148,           Validation Loss: 0.7027, Duration: 0:00:06.738864, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [03:26<02:26,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Train Loss: 0.7147,           Validation Loss: 0.7027, Duration: 0:00:07.138588, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [03:33<02:19,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Train Loss: 0.7148,           Validation Loss: 0.7027, Duration: 0:00:06.973981, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [03:40<02:12,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Train Loss: 0.7146,           Validation Loss: 0.7027, Duration: 0:00:06.963664, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [03:47<02:05,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Train Loss: 0.7146,           Validation Loss: 0.7027, Duration: 0:00:06.859461, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [03:54<01:57,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Train Loss: 0.7146,           Validation Loss: 0.7027, Duration: 0:00:06.915636, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [04:02<01:55,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Train Loss: 0.7146,           Validation Loss: 0.7027, Duration: 0:00:07.977516, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [04:09<01:49,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Train Loss: 0.7146,           Validation Loss: 0.7027, Duration: 0:00:07.365566, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [04:17<01:43,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Train Loss: 0.7145,           Validation Loss: 0.7027, Duration: 0:00:07.748580, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [04:24<01:36,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Train Loss: 0.7146,           Validation Loss: 0.7027, Duration: 0:00:07.296474, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [04:32<01:29,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Train Loss: 0.7145,           Validation Loss: 0.7027, Duration: 0:00:07.550479, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [04:40<01:24,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Train Loss: 0.7146,           Validation Loss: 0.7027, Duration: 0:00:08.247405, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [04:48<01:17,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Train Loss: 0.7145,           Validation Loss: 0.7027, Duration: 0:00:07.989214, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [04:56<01:09,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Train Loss: 0.7146,           Validation Loss: 0.7027, Duration: 0:00:07.443053, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [05:02<00:59,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Train Loss: 0.7147,           Validation Loss: 0.7027, Duration: 0:00:06.902184, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [05:09<00:50,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Train Loss: 0.7147,           Validation Loss: 0.7027, Duration: 0:00:06.860900, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [05:16<00:42,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Train Loss: 0.7147,           Validation Loss: 0.7027, Duration: 0:00:06.719974, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [05:23<00:35,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Train Loss: 0.7148,           Validation Loss: 0.7027, Duration: 0:00:06.874015, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [05:30<00:28,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Train Loss: 0.7146,           Validation Loss: 0.7027, Duration: 0:00:07.071851, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [05:37<00:21,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Train Loss: 0.7145,           Validation Loss: 0.7027, Duration: 0:00:07.146597, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [05:44<00:14,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Train Loss: 0.7147,           Validation Loss: 0.7027, Duration: 0:00:06.908370, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [05:51<00:06,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Train Loss: 0.7146,           Validation Loss: 0.7027, Duration: 0:00:06.913809, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [05:58<00:00,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Train Loss: 0.7145,           Validation Loss: 0.7027, Duration: 0:00:07.013406, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "train_losses, val_losses = train.batch_gd(model, criterion, optimizer, train_loader, val_loader, epochs=50, device=device, savedModelName='./savedModels_randomOrder/LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p.drawLossChange(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8382    0.9788    0.9030      9178\n",
      "           1     0.8665    0.5776    0.6932      9183\n",
      "           2     0.8046    0.9342    0.8646      9456\n",
      "\n",
      "    accuracy                         0.8312     27817\n",
      "   macro avg     0.8365    0.8302    0.8203     27817\n",
      "weighted avg     0.8361    0.8312    0.8207     27817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./savedModels_randomOrder/LSTM')\n",
    "all_targets, all_predictions = p.getReport(test_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p.seeConfusionMatrix(all_targets,all_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 发现在乱序数据上 对于label的预测效果很好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6379a49a5f1dae8e2bf9e9571591081e3adb0c6993333bb633f7202ba89f625"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
