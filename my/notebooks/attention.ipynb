{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.prepareDataAttention import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 10:38:14.318222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 10:38:14.330465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 10:38:14.330734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 10:38:14.332427: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-06 10:38:14.333645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 10:38:14.333897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 10:38:14.334070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 10:38:15.155649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 10:38:15.155933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 10:38:15.156116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 10:38:15.156309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:10:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# 指定GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(latent_dim):\n",
    "    input_train = keras.layers.Input(shape=(20, 42, 1))\n",
    "    # 第一CNN层\n",
    "    conv_first1 = keras.layers.Conv2D(32, (1, 2), strides=(1, 2))(input_train)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = keras.layers.Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = keras.layers.Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    # 第二CNN层\n",
    "    conv_first1 = keras.layers.Conv2D(32, (1, 2), strides=(1, 2))(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = keras.layers.Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = keras.layers.Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    # 第三CNN层\n",
    "    conv_first1 = keras.layers.Conv2D(32, (1, 10))(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = keras.layers.Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = keras.layers.Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\n",
    "    # 通道一\n",
    "    convsecond_1 = keras.layers.Conv2D(64, (1, 1), padding='same')(conv_first1)\n",
    "    convsecond_1 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_1)\n",
    "    convsecond_1 = keras.layers.Conv2D(64, (3, 1), padding='same')(convsecond_1)\n",
    "    convsecond_1 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_1)\n",
    "    # 通道二\n",
    "    convsecond_2 = keras.layers.Conv2D(64, (1, 1), padding='same')(conv_first1)\n",
    "    convsecond_2 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_2)\n",
    "    convsecond_2 = keras.layers.Conv2D(64, (5, 1), padding='same')(convsecond_2)\n",
    "    convsecond_2 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_2)\n",
    "    # 通道三\n",
    "    convsecond_3 = keras.layers.MaxPooling2D((3, 1), strides=(1, 1), padding='same')(conv_first1)\n",
    "    convsecond_3 = keras.layers.Conv2D(64, (1, 1), padding='same')(convsecond_3)\n",
    "    convsecond_3 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_3)\n",
    "\n",
    "    convsecond_output = keras.layers.concatenate([convsecond_1, convsecond_2, convsecond_3], axis=3)\n",
    "    conv_reshape = keras.layers.Reshape((int(convsecond_output.shape[1]), int(convsecond_output.shape[3])))(\n",
    "        convsecond_output)\n",
    "\n",
    "    # Encoder：由LSTM担任\n",
    "    encoder_inputs = conv_reshape\n",
    "    encoder = keras.layers.LSTM(latent_dim, return_state=True, return_sequences=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    states = [state_h, state_c]\n",
    "\n",
    "    # Decoder：依然使用LSTM，每一次只处理一个时间步\n",
    "    decoder_inputs = keras.layers.Input(shape=(1, 3))\n",
    "    decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_dense = keras.layers.Dense(3, activation='softmax', name='output_layer')\n",
    "\n",
    "    all_outputs = []\n",
    "    all_attention = []\n",
    "\n",
    "    encoder_state_h = keras.layers.Reshape((1, int(state_h.shape[1])))(state_h)\n",
    "    inputs = keras.layers.concatenate([decoder_inputs, encoder_state_h], axis=2)\n",
    "    # Decoder同时输出5个预测范围下的结果，循环使用5个Decoder\n",
    "    for _ in range(5):\n",
    "        outputs, state_h, state_c = decoder_lstm(inputs, initial_state=states)\n",
    "        # 做dot得到Attention\n",
    "        attention = keras.layers.dot([outputs, encoder_outputs], axes=2)\n",
    "        attention = keras.layers.Activation('softmax')(attention)\n",
    "        # 得到context vector\n",
    "        context = keras.layers.dot([attention, encoder_outputs], axes=[2, 1])\n",
    "        context = keras.layers.BatchNormalization(momentum=0.6)(context)\n",
    "\n",
    "        # Decoder的Input\n",
    "        decoder_combined_context = keras.layers.concatenate([context, outputs])\n",
    "        # 得到Decoder的输出\n",
    "        outputs = decoder_dense(decoder_combined_context)\n",
    "        all_outputs.append(outputs)\n",
    "        all_attention.append(attention)\n",
    "\n",
    "        inputs = keras.layers.concatenate([outputs, context], axis=2)\n",
    "        states = [state_h, state_c]\n",
    "\n",
    "    # decoder_attention = keras.layers.Lambda(lambda x: K.concatenate(x, axis=1), name='attentions')(all_attention)\n",
    "    # 综合5个Decoder的输出作为最终模型的输出\n",
    "    decoder_outputs = keras.layers.Lambda(lambda x: K.concatenate(x, axis=1), name='outputs')(all_outputs)\n",
    "    # 定义模型\n",
    "    model = keras.models.Model([input_train, decoder_inputs], decoder_outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 20\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "n_hidden = 64\n",
    "stockIndex = 1\n",
    "checkpoint_filepath = f'./attentionWeights/stock{stockIndex}_final_42_y_{T}T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_encoder_input.shape = (50931, 20, 42, 1),train_decoder_target.shape = (50931, 5, 3)\n",
      "test_encoder_input.shape = (28558, 20, 42, 1),test_decoder_target.shape = (28558, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "dec_train = pd.read_csv(f'../../data/processed/stock{stockIndex}/final_train7_part{stockIndex}.csv')\n",
    "dec_test1 = pd.read_csv(f'../../data/processed/stock{stockIndex}/final_test7_part{stockIndex}.csv')\n",
    "dec_test2 = pd.read_csv(f'../../data/processed/stock{stockIndex}/final_test8_part{stockIndex}.csv')\n",
    "dec_test3 = pd.read_csv(f'../../data/processed/stock{stockIndex}/final_test9_part{stockIndex}.csv')\n",
    "frames = [dec_test1, dec_test2, dec_test3]\n",
    "dec_test = pd.concat(frames)\n",
    "\n",
    "# 指定使用源数据中的42个特征\n",
    "train_lob = prepare_x(dec_train, num_features=42)\n",
    "test_lob = prepare_x(dec_test, num_features=42)\n",
    "\n",
    "# 指定预测标签\n",
    "train_label = get_label(np.array(dec_train))\n",
    "test_label = get_label(np.array(dec_test))\n",
    "\n",
    "# 准备好Encoder和Decoder的训练输入和groundTruth\n",
    "train_encoder_input, train_decoder_target = data_classification(train_lob, train_label, T)\n",
    "train_decoder_input = prepare_decoder_input(train_encoder_input, teacher_forcing=False)\n",
    "\n",
    "test_encoder_input, test_decoder_target = data_classification(test_lob, test_label, T)\n",
    "test_decoder_input = prepare_decoder_input(test_encoder_input, teacher_forcing=False)\n",
    "\n",
    "print(f'train_encoder_input.shape = {train_encoder_input.shape},'\n",
    "      f'train_decoder_target.shape = {train_decoder_target.shape}')\n",
    "print(f'test_encoder_input.shape = {test_encoder_input.shape},'\n",
    "      f'test_decoder_target.shape = {test_decoder_target.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = attention(n_hidden)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 10:38:50.774062: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14950137856 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-06 10:38:50.775294: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14950137856 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-06 10:38:50.776427: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14950137856 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-06 10:38:50.777504: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14950137856 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-06 10:38:50.778593: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14950137856 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-06 10:38:53.303337: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n",
      "2022-06-06 10:38:55.622851: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-06-06 10:39:39.105259: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14950137856 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-06 10:39:39.105712: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14950137856 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-06 10:39:39.106114: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14950137856 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-06 10:39:39.106493: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14950137856 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-06 10:39:39.106883: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14950137856 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1274/1274 - 61s - loss: 1.0314 - accuracy: 0.4542 - val_loss: 1.0938 - val_accuracy: 0.3833 - 61s/epoch - 48ms/step\n",
      "Epoch 2/50\n",
      "1274/1274 - 44s - loss: 0.9042 - accuracy: 0.5727 - val_loss: 0.8625 - val_accuracy: 0.6089 - 44s/epoch - 35ms/step\n",
      "Epoch 3/50\n",
      "1274/1274 - 46s - loss: 0.7612 - accuracy: 0.6751 - val_loss: 0.7872 - val_accuracy: 0.6793 - 46s/epoch - 36ms/step\n",
      "Epoch 4/50\n",
      "1274/1274 - 45s - loss: 0.6734 - accuracy: 0.7238 - val_loss: 0.6840 - val_accuracy: 0.7184 - 45s/epoch - 35ms/step\n",
      "Epoch 5/50\n",
      "1274/1274 - 44s - loss: 0.6341 - accuracy: 0.7434 - val_loss: 0.6504 - val_accuracy: 0.7361 - 44s/epoch - 35ms/step\n",
      "Epoch 6/50\n",
      "1274/1274 - 45s - loss: 0.6132 - accuracy: 0.7521 - val_loss: 0.6270 - val_accuracy: 0.7429 - 45s/epoch - 35ms/step\n",
      "Epoch 7/50\n",
      "1274/1274 - 42s - loss: 0.5948 - accuracy: 0.7606 - val_loss: 0.6957 - val_accuracy: 0.7224 - 42s/epoch - 33ms/step\n",
      "Epoch 8/50\n",
      "1274/1274 - 44s - loss: 0.5801 - accuracy: 0.7671 - val_loss: 0.6234 - val_accuracy: 0.7475 - 44s/epoch - 35ms/step\n",
      "Epoch 9/50\n",
      "1274/1274 - 45s - loss: 0.5663 - accuracy: 0.7722 - val_loss: 0.6572 - val_accuracy: 0.7403 - 45s/epoch - 35ms/step\n",
      "Epoch 10/50\n",
      "1274/1274 - 44s - loss: 0.5545 - accuracy: 0.7785 - val_loss: 0.6459 - val_accuracy: 0.7386 - 44s/epoch - 35ms/step\n",
      "Epoch 11/50\n",
      "1274/1274 - 43s - loss: 0.5446 - accuracy: 0.7821 - val_loss: 0.6512 - val_accuracy: 0.7490 - 43s/epoch - 34ms/step\n",
      "Epoch 12/50\n",
      "1274/1274 - 42s - loss: 0.5339 - accuracy: 0.7850 - val_loss: 0.6413 - val_accuracy: 0.7471 - 42s/epoch - 33ms/step\n",
      "Epoch 13/50\n",
      "1274/1274 - 42s - loss: 0.5242 - accuracy: 0.7887 - val_loss: 0.6557 - val_accuracy: 0.7397 - 42s/epoch - 33ms/step\n",
      "Epoch 14/50\n",
      "1274/1274 - 43s - loss: 0.5147 - accuracy: 0.7933 - val_loss: 0.6556 - val_accuracy: 0.7395 - 43s/epoch - 34ms/step\n",
      "Epoch 15/50\n",
      "1274/1274 - 43s - loss: 0.5035 - accuracy: 0.7978 - val_loss: 0.6563 - val_accuracy: 0.7453 - 43s/epoch - 34ms/step\n",
      "Epoch 16/50\n",
      "1274/1274 - 45s - loss: 0.4943 - accuracy: 0.8010 - val_loss: 0.6718 - val_accuracy: 0.7393 - 45s/epoch - 35ms/step\n",
      "Epoch 17/50\n",
      "1274/1274 - 44s - loss: 0.4860 - accuracy: 0.8047 - val_loss: 0.6788 - val_accuracy: 0.7333 - 44s/epoch - 35ms/step\n",
      "Epoch 18/50\n",
      "1274/1274 - 45s - loss: 0.4781 - accuracy: 0.8068 - val_loss: 0.7080 - val_accuracy: 0.7286 - 45s/epoch - 35ms/step\n",
      "Epoch 19/50\n",
      "1274/1274 - 43s - loss: 0.4703 - accuracy: 0.8100 - val_loss: 0.6864 - val_accuracy: 0.7283 - 43s/epoch - 34ms/step\n",
      "Epoch 20/50\n",
      "1274/1274 - 44s - loss: 0.4620 - accuracy: 0.8136 - val_loss: 0.7143 - val_accuracy: 0.7210 - 44s/epoch - 34ms/step\n",
      "Epoch 21/50\n",
      "1274/1274 - 46s - loss: 0.4540 - accuracy: 0.8163 - val_loss: 0.7195 - val_accuracy: 0.7220 - 46s/epoch - 36ms/step\n",
      "Epoch 22/50\n",
      "1274/1274 - 42s - loss: 0.4467 - accuracy: 0.8195 - val_loss: 0.7150 - val_accuracy: 0.7290 - 42s/epoch - 33ms/step\n",
      "Epoch 23/50\n",
      "1274/1274 - 45s - loss: 0.4411 - accuracy: 0.8219 - val_loss: 0.7208 - val_accuracy: 0.7204 - 45s/epoch - 35ms/step\n",
      "Epoch 24/50\n",
      "1274/1274 - 44s - loss: 0.4329 - accuracy: 0.8249 - val_loss: 0.7461 - val_accuracy: 0.7083 - 44s/epoch - 35ms/step\n",
      "Epoch 25/50\n",
      "1274/1274 - 45s - loss: 0.4249 - accuracy: 0.8273 - val_loss: 0.7484 - val_accuracy: 0.7154 - 45s/epoch - 35ms/step\n",
      "Epoch 26/50\n",
      "1274/1274 - 43s - loss: 0.4177 - accuracy: 0.8310 - val_loss: 0.8043 - val_accuracy: 0.7020 - 43s/epoch - 34ms/step\n",
      "Epoch 27/50\n",
      "1274/1274 - 41s - loss: 0.4142 - accuracy: 0.8318 - val_loss: 0.7984 - val_accuracy: 0.7020 - 41s/epoch - 32ms/step\n",
      "Epoch 28/50\n",
      "1274/1274 - 43s - loss: 0.4058 - accuracy: 0.8358 - val_loss: 0.7688 - val_accuracy: 0.7156 - 43s/epoch - 34ms/step\n",
      "Epoch 29/50\n",
      "1274/1274 - 43s - loss: 0.3981 - accuracy: 0.8387 - val_loss: 0.7880 - val_accuracy: 0.7141 - 43s/epoch - 34ms/step\n",
      "Epoch 30/50\n",
      "1274/1274 - 43s - loss: 0.3928 - accuracy: 0.8406 - val_loss: 0.8167 - val_accuracy: 0.7052 - 43s/epoch - 34ms/step\n",
      "Epoch 31/50\n",
      "1274/1274 - 43s - loss: 0.3859 - accuracy: 0.8445 - val_loss: 0.8448 - val_accuracy: 0.7020 - 43s/epoch - 34ms/step\n",
      "Epoch 32/50\n",
      "1274/1274 - 41s - loss: 0.3799 - accuracy: 0.8465 - val_loss: 0.8221 - val_accuracy: 0.7099 - 41s/epoch - 32ms/step\n",
      "Epoch 33/50\n",
      "1274/1274 - 44s - loss: 0.3717 - accuracy: 0.8498 - val_loss: 0.8396 - val_accuracy: 0.6977 - 44s/epoch - 35ms/step\n",
      "Epoch 34/50\n",
      "1274/1274 - 44s - loss: 0.3688 - accuracy: 0.8508 - val_loss: 0.8727 - val_accuracy: 0.7011 - 44s/epoch - 34ms/step\n",
      "Epoch 35/50\n",
      "1274/1274 - 42s - loss: 0.3600 - accuracy: 0.8553 - val_loss: 0.8584 - val_accuracy: 0.6988 - 42s/epoch - 33ms/step\n",
      "Epoch 36/50\n",
      "1274/1274 - 44s - loss: 0.3566 - accuracy: 0.8570 - val_loss: 0.8910 - val_accuracy: 0.6980 - 44s/epoch - 34ms/step\n",
      "Epoch 37/50\n",
      "1274/1274 - 42s - loss: 0.3488 - accuracy: 0.8596 - val_loss: 0.8801 - val_accuracy: 0.7012 - 42s/epoch - 33ms/step\n",
      "Epoch 38/50\n",
      "1274/1274 - 45s - loss: 0.3437 - accuracy: 0.8610 - val_loss: 0.8783 - val_accuracy: 0.6924 - 45s/epoch - 35ms/step\n",
      "Epoch 39/50\n",
      "1274/1274 - 45s - loss: 0.3368 - accuracy: 0.8657 - val_loss: 0.8941 - val_accuracy: 0.6932 - 45s/epoch - 35ms/step\n",
      "Epoch 40/50\n",
      "1274/1274 - 46s - loss: 0.3347 - accuracy: 0.8656 - val_loss: 0.8950 - val_accuracy: 0.6897 - 46s/epoch - 36ms/step\n",
      "Epoch 41/50\n",
      "1274/1274 - 45s - loss: 0.3301 - accuracy: 0.8675 - val_loss: 0.9323 - val_accuracy: 0.6932 - 45s/epoch - 35ms/step\n",
      "Epoch 42/50\n",
      "1274/1274 - 45s - loss: 0.3231 - accuracy: 0.8706 - val_loss: 0.9509 - val_accuracy: 0.6927 - 45s/epoch - 35ms/step\n",
      "Epoch 43/50\n",
      "1274/1274 - 45s - loss: 0.3187 - accuracy: 0.8720 - val_loss: 0.9967 - val_accuracy: 0.6882 - 45s/epoch - 35ms/step\n",
      "Epoch 44/50\n",
      "1274/1274 - 45s - loss: 0.3147 - accuracy: 0.8746 - val_loss: 0.9531 - val_accuracy: 0.6846 - 45s/epoch - 36ms/step\n",
      "Epoch 45/50\n",
      "1274/1274 - 44s - loss: 0.3106 - accuracy: 0.8759 - val_loss: 0.9853 - val_accuracy: 0.6851 - 44s/epoch - 35ms/step\n",
      "Epoch 46/50\n",
      "1274/1274 - 46s - loss: 0.3042 - accuracy: 0.8782 - val_loss: 0.9850 - val_accuracy: 0.6895 - 46s/epoch - 36ms/step\n",
      "Epoch 47/50\n",
      "1274/1274 - 45s - loss: 0.2993 - accuracy: 0.8808 - val_loss: 1.0085 - val_accuracy: 0.6769 - 45s/epoch - 35ms/step\n",
      "Epoch 48/50\n",
      "1274/1274 - 46s - loss: 0.2988 - accuracy: 0.8815 - val_loss: 0.9809 - val_accuracy: 0.6878 - 46s/epoch - 36ms/step\n",
      "Epoch 49/50\n",
      "1274/1274 - 44s - loss: 0.2948 - accuracy: 0.8830 - val_loss: 0.9741 - val_accuracy: 0.6971 - 44s/epoch - 35ms/step\n",
      "Epoch 50/50\n",
      "1274/1274 - 46s - loss: 0.2917 - accuracy: 0.8846 - val_loss: 1.0205 - val_accuracy: 0.6738 - 46s/epoch - 36ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda9c265f90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_train_val = int(np.floor(len(train_encoder_input) * 0.8))\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)\n",
    "\n",
    "model.fit([train_encoder_input[:split_train_val], train_decoder_input[:split_train_val]], \n",
    "          train_decoder_target[:split_train_val],\n",
    "          validation_data=([train_encoder_input[split_train_val:], train_decoder_input[split_train_val:]], \n",
    "          train_decoder_target[split_train_val:]),\n",
    "          epochs=epochs, batch_size=batch_size, verbose=2, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 20, 42, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 20, 21, 32)   96          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 20, 21, 32)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 20, 21, 32)   4128        ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 20, 21, 32)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 20, 21, 32)   4128        ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 20, 21, 32)   0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 20, 10, 32)   2080        ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 20, 10, 32)   0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 20, 10, 32)   4128        ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 20, 10, 32)   0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 20, 10, 32)   4128        ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 20, 10, 32)   0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 20, 1, 32)    10272       ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 20, 1, 32)    0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 20, 1, 32)    4128        ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 20, 1, 32)    0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 20, 1, 32)    4128        ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 20, 1, 32)    0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 20, 1, 64)    2112        ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 20, 1, 64)    2112        ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 20, 1, 64)    0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 20, 1, 64)    0           ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 20, 1, 32)    0           ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 20, 1, 64)    12352       ['leaky_re_lu_9[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 20, 1, 64)    20544       ['leaky_re_lu_11[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 20, 1, 64)    2112        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 20, 1, 64)    0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 20, 1, 64)    0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 20, 1, 64)    0           ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 20, 1, 192)   0           ['leaky_re_lu_10[0][0]',         \n",
      "                                                                  'leaky_re_lu_12[0][0]',         \n",
      "                                                                  'leaky_re_lu_13[0][0]']         \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 20, 192)      0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 20, 64),     65792       ['reshape[0][0]']                \n",
      "                                 (None, 64),                                                      \n",
      "                                 (None, 64)]                                                      \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1, 3)]       0           []                               \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1, 64)        0           ['lstm[0][1]']                   \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 1, 67)        0           ['input_2[0][0]',                \n",
      "                                                                  'reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 1, 64),      33792       ['concatenate_1[0][0]',          \n",
      "                                 (None, 64),                      'lstm[0][1]',                   \n",
      "                                 (None, 64)]                      'lstm[0][2]',                   \n",
      "                                                                  'concatenate_3[0][0]',          \n",
      "                                                                  'lstm_1[0][1]',                 \n",
      "                                                                  'lstm_1[0][2]',                 \n",
      "                                                                  'concatenate_5[0][0]',          \n",
      "                                                                  'lstm_1[1][1]',                 \n",
      "                                                                  'lstm_1[1][2]',                 \n",
      "                                                                  'concatenate_7[0][0]',          \n",
      "                                                                  'lstm_1[2][1]',                 \n",
      "                                                                  'lstm_1[2][2]',                 \n",
      "                                                                  'concatenate_9[0][0]',          \n",
      "                                                                  'lstm_1[3][1]',                 \n",
      "                                                                  'lstm_1[3][2]']                 \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1, 20)        0           ['lstm_1[0][0]',                 \n",
      "                                                                  'lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1, 20)        0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                    (None, 1, 64)        0           ['activation[0][0]',             \n",
      "                                                                  'lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1, 64)       256         ['dot_1[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 1, 128)       0           ['batch_normalization[0][0]',    \n",
      "                                                                  'lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, 1, 3)         387         ['concatenate_2[0][0]',          \n",
      "                                                                  'concatenate_4[0][0]',          \n",
      "                                                                  'concatenate_6[0][0]',          \n",
      "                                                                  'concatenate_8[0][0]',          \n",
      "                                                                  'concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 1, 67)        0           ['output_layer[0][0]',           \n",
      "                                                                  'batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dot_2 (Dot)                    (None, 1, 20)        0           ['lstm_1[1][0]',                 \n",
      "                                                                  'lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 1, 20)        0           ['dot_2[0][0]']                  \n",
      "                                                                                                  \n",
      " dot_3 (Dot)                    (None, 1, 64)        0           ['activation_1[0][0]',           \n",
      "                                                                  'lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 1, 64)       256         ['dot_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 1, 128)       0           ['batch_normalization_1[0][0]',  \n",
      "                                                                  'lstm_1[1][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 1, 67)        0           ['output_layer[1][0]',           \n",
      "                                                                  'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dot_4 (Dot)                    (None, 1, 20)        0           ['lstm_1[2][0]',                 \n",
      "                                                                  'lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 1, 20)        0           ['dot_4[0][0]']                  \n",
      "                                                                                                  \n",
      " dot_5 (Dot)                    (None, 1, 64)        0           ['activation_2[0][0]',           \n",
      "                                                                  'lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 1, 64)       256         ['dot_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 1, 128)       0           ['batch_normalization_2[0][0]',  \n",
      "                                                                  'lstm_1[2][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 1, 67)        0           ['output_layer[2][0]',           \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dot_6 (Dot)                    (None, 1, 20)        0           ['lstm_1[3][0]',                 \n",
      "                                                                  'lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 1, 20)        0           ['dot_6[0][0]']                  \n",
      "                                                                                                  \n",
      " dot_7 (Dot)                    (None, 1, 64)        0           ['activation_3[0][0]',           \n",
      "                                                                  'lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 1, 64)       256         ['dot_7[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 1, 128)       0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'lstm_1[3][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 1, 67)        0           ['output_layer[3][0]',           \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dot_8 (Dot)                    (None, 1, 20)        0           ['lstm_1[4][0]',                 \n",
      "                                                                  'lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 1, 20)        0           ['dot_8[0][0]']                  \n",
      "                                                                                                  \n",
      " dot_9 (Dot)                    (None, 1, 64)        0           ['activation_4[0][0]',           \n",
      "                                                                  'lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 1, 64)       256         ['dot_9[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 1, 128)       0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  'lstm_1[4][0]']                 \n",
      "                                                                                                  \n",
      " outputs (Lambda)               (None, 5, 3)         0           ['output_layer[0][0]',           \n",
      "                                                                  'output_layer[1][0]',           \n",
      "                                                                  'output_layer[2][0]',           \n",
      "                                                                  'output_layer[3][0]',           \n",
      "                                                                  'output_layer[4][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 177,699\n",
      "Trainable params: 177,059\n",
      "Non-trainable params: 640\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_filepath)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 11:17:25.950351: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14950137856 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-06 11:17:25.950812: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14950137856 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-06 11:17:25.951215: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14950137856 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-06 11:17:25.951630: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14950137856 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-06 11:17:25.952028: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14950137856 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction horizon = 0\n",
      "accuracy_score = 0.8432663351775335\n",
      "classification_report =               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9046    0.5163    0.6574      4573\n",
      "           1     0.8507    0.9585    0.9014     19839\n",
      "           2     0.7527    0.6527    0.6991      4146\n",
      "\n",
      "    accuracy                         0.8433     28558\n",
      "   macro avg     0.8360    0.7091    0.7526     28558\n",
      "weighted avg     0.8451    0.8433    0.8329     28558\n",
      "\n",
      "-------------------------------\n",
      "Prediction horizon = 1\n",
      "accuracy_score = 0.7583164087120947\n",
      "classification_report =               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8701    0.4049    0.5527      5907\n",
      "           1     0.7553    0.9450    0.8396     17384\n",
      "           2     0.6989    0.5384    0.6083      5267\n",
      "\n",
      "    accuracy                         0.7583     28558\n",
      "   macro avg     0.7748    0.6295    0.6668     28558\n",
      "weighted avg     0.7686    0.7583    0.7376     28558\n",
      "\n",
      "-------------------------------\n",
      "Prediction horizon = 2\n",
      "accuracy_score = 0.7832131101617761\n",
      "classification_report =               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8462    0.5961    0.6995      7161\n",
      "           1     0.7698    0.9248    0.8402     15115\n",
      "           2     0.7695    0.6558    0.7081      6282\n",
      "\n",
      "    accuracy                         0.7832     28558\n",
      "   macro avg     0.7952    0.7256    0.7493     28558\n",
      "weighted avg     0.7889    0.7832    0.7759     28558\n",
      "\n",
      "-------------------------------\n",
      "Prediction horizon = 3\n",
      "accuracy_score = 0.809055255970306\n",
      "classification_report =               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8684    0.7047    0.7780      8687\n",
      "           1     0.7899    0.9165    0.8485     12353\n",
      "           2     0.7891    0.7530    0.7706      7518\n",
      "\n",
      "    accuracy                         0.8091     28558\n",
      "   macro avg     0.8158    0.7914    0.7991     28558\n",
      "weighted avg     0.8135    0.8091    0.8066     28558\n",
      "\n",
      "-------------------------------\n",
      "Prediction horizon = 4\n",
      "accuracy_score = 0.8364731423769172\n",
      "classification_report =               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8008    0.8865    0.8415     11006\n",
      "           1     0.8678    0.8354    0.8513      8130\n",
      "           2     0.8587    0.7789    0.8169      9422\n",
      "\n",
      "    accuracy                         0.8365     28558\n",
      "   macro avg     0.8424    0.8336    0.8365     28558\n",
      "weighted avg     0.8390    0.8365    0.8361     28558\n",
      "\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict([test_encoder_input, test_decoder_input])\n",
    "evaluation_metrics(test_decoder_target, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 针对不同时间步的attention权重实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Model(inputs=model.input,\n",
    "              outputs=[model.output, model.get_layer('activation_10').output, model.get_layer('activation_11').output, model.get_layer('activation_12').output, model.get_layer('activation_13').output, model.get_layer('activation_14').output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-04 14:42:33.189805: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 12453478400 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-04 14:42:33.190221: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 12453478400 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-04 14:42:33.190603: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 12453478400 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-04 14:42:33.190977: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 12453478400 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-04 14:42:33.191348: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 12453478400 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    }
   ],
   "source": [
    "# model.load_weights(checkpoint_filepath)\n",
    "outputs = model.predict([test_encoder_input, test_decoder_input])\n",
    "pred = outputs[0]\n",
    "# attention1是k=10时，attention5是k=30时\n",
    "attention1 = outputs[1]\n",
    "attention2 = outputs[2]\n",
    "attention3 = outputs[3]\n",
    "attention4 = outputs[4]\n",
    "attention5 = outputs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01078201 0.01074526 0.00638794 0.00416656 0.00330497 0.00224654\n",
      " 0.00211841 0.00248389 0.00406273 0.0056353  0.00857462 0.01496092\n",
      " 0.02481331 0.03352311 0.04155738 0.05759889 0.09970216 0.16343136\n",
      " 0.23426698 0.26963764]\n"
     ]
    }
   ],
   "source": [
    "print(attention1[0][0])\n",
    "# attention[0]中的排序方式为：第一时间步、第二时间步。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01078201, 0.01074526, 0.00638794, 0.00416656, 0.00330497,\n",
       "        0.00224654, 0.00211841, 0.00248389, 0.00406273, 0.0056353 ,\n",
       "        0.00857462, 0.01496092, 0.02481331, 0.03352311, 0.04155738,\n",
       "        0.05759889, 0.09970216, 0.16343136, 0.23426698, 0.26963764],\n",
       "       [0.01654554, 0.01434477, 0.00895939, 0.00625188, 0.00565409,\n",
       "        0.00459414, 0.00504766, 0.00658041, 0.01078756, 0.01434906,\n",
       "        0.02167361, 0.03733276, 0.0578718 , 0.07327807, 0.08661943,\n",
       "        0.10715756, 0.13552585, 0.14669506, 0.12633039, 0.11440093],\n",
       "       [0.01261244, 0.00906536, 0.0074229 , 0.00688024, 0.00760894,\n",
       "        0.00841871, 0.0115451 , 0.01710195, 0.02794451, 0.03668655,\n",
       "        0.05037608, 0.0708454 , 0.08892323, 0.10353905, 0.11773416,\n",
       "        0.12543571, 0.11303692, 0.08553535, 0.05444882, 0.04483857],\n",
       "       [0.00970477, 0.00638762, 0.0059907 , 0.00632423, 0.00756557,\n",
       "        0.01015535, 0.01609576, 0.02636916, 0.04399814, 0.05643775,\n",
       "        0.07714269, 0.09945808, 0.10515121, 0.10981141, 0.11768772,\n",
       "        0.11368377, 0.0846378 , 0.05362665, 0.02845263, 0.02131899],\n",
       "       [0.00327774, 0.00155676, 0.00207924, 0.00424492, 0.00937931,\n",
       "        0.0244679 , 0.06656224, 0.14408728, 0.20794232, 0.20008926,\n",
       "        0.13482498, 0.06975619, 0.03779357, 0.02864783, 0.02522109,\n",
       "        0.01973119, 0.01089412, 0.00515578, 0.00250844, 0.00177991]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 得到attention矩阵\n",
    "array1,array2,array3,array4,array5 = np.array(attention1[0][0]),np.array(attention2[0][0]),np.array(attention3[0][0]),np.array(attention4[0][0]),np.array(attention5[0][0])\n",
    "attention_matrix = np.stack((array1,array2,array3,array4,array5),axis=0)\n",
    "attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01078201, 0.01074526, 0.00638794, 0.00416656, 0.00330497,\n",
       "        0.00224654, 0.00211841, 0.00248389, 0.00406273, 0.0056353 ,\n",
       "        0.00857462, 0.01496092, 0.02481331, 0.03352311, 0.04155738,\n",
       "        0.05759889, 0.09970216, 0.16343136, 0.23426698, 0.26963764],\n",
       "       [0.01654554, 0.01434477, 0.00895939, 0.00625188, 0.00565409,\n",
       "        0.00459414, 0.00504766, 0.00658041, 0.01078756, 0.01434906,\n",
       "        0.02167361, 0.03733276, 0.0578718 , 0.07327807, 0.08661943,\n",
       "        0.10715756, 0.13552585, 0.14669506, 0.12633039, 0.11440093],\n",
       "       [0.01261244, 0.00906536, 0.0074229 , 0.00688024, 0.00760894,\n",
       "        0.00841871, 0.0115451 , 0.01710195, 0.02794451, 0.03668655,\n",
       "        0.05037608, 0.0708454 , 0.08892323, 0.10353905, 0.11773416,\n",
       "        0.12543571, 0.11303692, 0.08553535, 0.05444882, 0.04483857],\n",
       "       [0.00970477, 0.00638762, 0.0059907 , 0.00632423, 0.00756557,\n",
       "        0.01015535, 0.01609576, 0.02636916, 0.04399814, 0.05643775,\n",
       "        0.07714269, 0.09945808, 0.10515121, 0.10981141, 0.11768772,\n",
       "        0.11368377, 0.0846378 , 0.05362665, 0.02845263, 0.02131899],\n",
       "       [0.00327774, 0.00155676, 0.00207924, 0.00424492, 0.00937931,\n",
       "        0.0244679 , 0.06656224, 0.14408728, 0.20794232, 0.20008926,\n",
       "        0.13482498, 0.06975619, 0.03779357, 0.02864783, 0.02522109,\n",
       "        0.01973119, 0.01089412, 0.00515578, 0.00250844, 0.00177991]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.savetxt(f'./attentionWeights/stock{stockIndex}_final_42_y_{T}T',attention_matrix)\n",
    "matrix = np.loadtxt(f'./attentionWeights/stock{stockIndex}_final_42_y_{T}T')\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# fig, axes = plt.subplots()\n",
    "plt.figure(figsize=(15,6))\n",
    "# df_cm = pd.DataFrame(attention_matrix, index=['$K=10$','$K=15$','$K=20$','$K=25$','$K=30$'], columns=['$H_{t-49}$','$H_{t-48}$','$H_{t-47}$','$H_{t-46}$','$H_{t-45}$','$H_{t-44}$','$H_{t-43}$','$H_{t-42}$','$H_{t-41}$','$H_{t-40}$','$H_{t-39}$','$H_{t-38}$','$H_{t-37}$','$H_{t-36}$','$H_{t-35}$','$H_{t-34}$','$H_{t-33}$','$H_{t-32}$','$H_{t-31}$','$H_{t-30}$','$H_{t-29}$','$H_{t-28}$','$H_{t-27}$','$H_{t-26}$','$H_{t-25}$','$H_{t-24}$','$H_{t-23}$','$H_{t-22}$','$H_{t-21}$','$H_{t-20}$','$H_{t-19}$','$H_{t-18}$','$H_{t-17}$','$H_{t-16}$','$H_{t-15}$','$H_{t-14}$','$H_{t-13}$','$H_{t-12}$','$H_{t-11}$','$H_{t-10}$','$H_{t-9}$','$H_{t-8}$','$H_{t-7}$','$H_{t-6}$','$H_{t-5}$','$H_{t-4}$','$H_{t-3}$','$H_{t-2}$','$H_{t-1}$','$H_{t}$'])\n",
    "# df_cm = pd.DataFrame(attention_matrix, index=['$K=10$','$K=15$','$K=20$','$K=25$','$K=30$'], columns=['49','48','47','46','45','44','43','42','41','40','39','38','37','36','35','34','33','32','31','30','29','28','27','26','25','24','23','22','21','20','19','18','17','16','15','14','13','12','11','10','9','8','7','6','5','4','3','2','1','0'])\n",
    "df_cm = pd.DataFrame(attention_matrix, index=['$K=10$','$K=15$','$K=20$','$K=25$','$K=30$'], columns=['19','18','17','16','15','14','13','12','11','10','9','8','7','6','5','4','3','2','1','0'])\n",
    "heatmap = sns.heatmap(df_cm,annot=False, cmap='YlGnBu')\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0,fontsize=14)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, fontsize=14)\n",
    "plt.title(\"Attention Weights of every timesteps under different $K$\", fontsize=16)\n",
    "# axes.set_ylabel(\"true label\")\n",
    "# axes.set_xlabel(\"predict label\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6379a49a5f1dae8e2bf9e9571591081e3adb0c6993333bb633f7202ba89f625"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
