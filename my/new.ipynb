{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Study\\Anaconda\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_x(data):\n",
    "    df1 = data[:40, :].T\n",
    "    return np.array(df1)\n",
    "\n",
    "def get_label(data):\n",
    "    lob = data[-5:, :].T\n",
    "    return lob\n",
    "\n",
    "def data_classification(X, Y, T):\n",
    "    [N, D] = X.shape\n",
    "    df = np.array(X)\n",
    "\n",
    "    dY = np.array(Y)\n",
    "\n",
    "    dataY = dY[T - 1:N]\n",
    "\n",
    "    dataX = np.zeros((N - T + 1, T, D))\n",
    "    for i in range(T, N + 1):\n",
    "        dataX[i - T] = df[i - T:i, :]\n",
    "\n",
    "    return dataX, dataY\n",
    "\n",
    "def torch_data(x, y):\n",
    "    x = torch.from_numpy(x)\n",
    "    x = torch.unsqueeze(x, 1)\n",
    "    y = torch.from_numpy(y)\n",
    "    y = F.one_hot(y, num_classes=3)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, data, k, num_classes, T):\n",
    "        \"\"\"Initialization\"\"\" \n",
    "        self.k = k\n",
    "        self.num_classes = num_classes\n",
    "        self.T = T\n",
    "            \n",
    "        x = prepare_x(data)\n",
    "        y = get_label(data)\n",
    "        x, y = data_classification(x, y, self.T)\n",
    "        y = y[:,self.k] - 1\n",
    "        self.length = len(x)\n",
    "\n",
    "        x = torch.from_numpy(x)\n",
    "        self.x = torch.unsqueeze(x, 1)\n",
    "        self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates samples of data\"\"\"\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "We used no auction dataset that is normalised by decimal precision approach in their work. The first seven days are training data and the last three days are testing data. A validation set (20%) from the training set is used to monitor the overfitting behaviours.  \n",
    "\n",
    "The first 40 columns of the FI-2010 dataset are 10 levels ask and bid information for a limit order book and we only use these 40 features in our network. The last 5 columns of the FI-2010 dataset are the labels with different prediction horizons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 203800) (149, 50950) (149, 139587)\n"
     ]
    }
   ],
   "source": [
    "dec_data = np.loadtxt('./data/Train_Dst_NoAuction_DecPre_CF_7.txt')\n",
    "dec_train = dec_data[:, :int(np.floor(dec_data.shape[1] * 0.8))]\n",
    "dec_val = dec_data[:, int(np.floor(dec_data.shape[1] * 0.8)):]\n",
    "\n",
    "dec_test1 = np.loadtxt('./data/Test_Dst_NoAuction_DecPre_CF_7.txt')\n",
    "dec_test2 = np.loadtxt('./data/Test_Dst_NoAuction_DecPre_CF_8.txt')\n",
    "dec_test3 = np.loadtxt('./data/Test_Dst_NoAuction_DecPre_CF_9.txt')\n",
    "dec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n",
    "\n",
    "print(dec_train.shape, dec_val.shape, dec_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([203701, 1, 100, 40]) torch.Size([203701])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "dataset_train = Dataset(data=dec_train, k=4, num_classes=3, T=100)\n",
    "dataset_val = Dataset(data=dec_val, k=4, num_classes=3, T=100)\n",
    "dataset_test = Dataset(data=dec_test, k=4, num_classes=3, T=100)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(dataset_train.x.shape, dataset_train.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2615, 0.0035, 0.2606, 0.0033, 0.2618, 0.0020, 0.2604, 0.0068, 0.2619,\n",
      "        0.0016, 0.2602, 0.0079, 0.2620, 0.0053, 0.2600, 0.0089, 0.2621, 0.0015,\n",
      "        0.2599, 0.0016, 0.2623, 0.0084, 0.2595, 0.0010, 0.2625, 0.0015, 0.2593,\n",
      "        0.0014, 0.2626, 0.0079, 0.2591, 0.0013, 0.2629, 0.0015, 0.2588, 0.0012,\n",
      "        0.2633, 0.0031, 0.2579, 0.0013], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train.x[0][0][0])\n",
    "# 发现40个特征的排列顺序为：Ask1，Ask1的volumu，Bid1，Bid1的Volumu。。。类推"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.1734, 0.0178, 0.1730,  ..., 0.0040, 0.1717, 0.0931],\n",
      "          [0.1734, 0.0178, 0.1730,  ..., 0.0040, 0.1717, 0.0931],\n",
      "          [0.1734, 0.0178, 0.1730,  ..., 0.0040, 0.1717, 0.0931],\n",
      "          ...,\n",
      "          [0.1731, 0.0120, 0.1728,  ..., 0.0161, 0.1717, 0.0931],\n",
      "          [0.1729, 0.0120, 0.1728,  ..., 0.0362, 0.1718, 0.0112],\n",
      "          [0.1729, 0.0120, 0.1728,  ..., 0.0362, 0.1718, 0.0112]]]],\n",
      "       dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "torch.Size([1, 1, 100, 40]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "tmp_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=1, shuffle=True)\n",
    "\n",
    "for x, y in tmp_loader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "\n",
    "Please find the detailed discussion of our model architecture in our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deeplob(nn.Module):\n",
    "    def __init__(self, y_len):\n",
    "        super().__init__()\n",
    "        self.y_len = y_len\n",
    "        \n",
    "        # convolution blocks\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "#             nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,10)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        \n",
    "        # inception moduels\n",
    "        self.inp1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.inp2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(5,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.inp3 = nn.Sequential(\n",
    "            nn.MaxPool2d((3, 1), stride=(1, 1), padding=(1, 0)),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        \n",
    "        # lstm layers\n",
    "        self.lstm = nn.LSTM(input_size=192, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, self.y_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # h0: (number of hidden layers, batch size, hidden size)\n",
    "        h0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x_inp1 = self.inp1(x)\n",
    "        x_inp2 = self.inp2(x)\n",
    "        x_inp3 = self.inp3(x)  \n",
    "        \n",
    "        x = torch.cat((x_inp1, x_inp2, x_inp3), dim=1)\n",
    "        \n",
    "#         x = torch.transpose(x, 1, 2)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        x = torch.reshape(x, (-1, x.shape[1], x.shape[2]))\n",
    "        \n",
    "        x, _ = self.lstm(x, (h0, c0))\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc1(x)\n",
    "        forecast_y = torch.softmax(x, dim=1)\n",
    "        \n",
    "        return forecast_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 直接加载训练好的模型\n",
    "## 测试accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.7535\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('best_val_model_pytorch')\n",
    "\n",
    "n_correct = 0.\n",
    "n_total = 0.\n",
    "for inputs, targets in test_loader:\n",
    "    # Move to GPU\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    # update counts\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "\n",
    "test_acc = n_correct / n_total\n",
    "print(f\"Test acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重跑测试以给出classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.753505677907777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7341    0.7524    0.7431     47915\n",
      "           1     0.8074    0.7622    0.7841     48050\n",
      "           2     0.7204    0.7451    0.7326     43523\n",
      "\n",
      "    accuracy                         0.7535    139488\n",
      "   macro avg     0.7540    0.7532    0.7533    139488\n",
      "weighted avg     0.7551    0.7535    0.7540    139488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = torch.load('best_val_model_pytorch')\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for inputs, targets in test_loader:\n",
    "    # Move to GPU\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    all_targets.append(targets.cpu().numpy())\n",
    "    all_predictions.append(predictions.cpu().numpy())\n",
    "\n",
    "all_targets = np.concatenate(all_targets)    \n",
    "all_predictions = np.concatenate(all_predictions)    \n",
    "\n",
    "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
    "print(classification_report(all_targets, all_predictions, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建账户类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class MyAccount(object):\n",
    "    def __init__(self, initialCash):\n",
    "        # 账户中的现金\n",
    "        self.cash = initialCash\n",
    "        # 当前持有的股票数量\n",
    "        self.numberOfStock = 0\n",
    "        \n",
    "    \n",
    "    def getCash(self):\n",
    "        return self.cash\n",
    "\n",
    "    def getNumberOfStock(self):\n",
    "        return self.numberOfStock\n",
    "    \n",
    "    def buy(self,askPrice):\n",
    "    # 全仓买，能买多少买多少，返回askPrice和购买的股票数量\n",
    "        buyNumber = math.floor(self.cash/askPrice)\n",
    "        self.numberOfStock+=buyNumber\n",
    "        self.cash-=buyNumber*askPrice\n",
    "        return askPrice, buyNumber\n",
    "    \n",
    "    def sell(self,bidPrice):\n",
    "    # 将手中持有的股票全部卖出，返回bidPrice和卖出的股票数量\n",
    "        self.cash+=bidPrice*self.numberOfStock\n",
    "        sellNumber = self.numberOfStock\n",
    "        self.numberOfStock = 0\n",
    "        return bidPrice, sellNumber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139488\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读入testSet，执行交易策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[2.6660e-01, 1.2900e-03, 2.6540e-01,  ..., 2.0000e-03,\n",
      "          2.6380e-01, 1.5600e-03],\n",
      "         [2.6690e-01, 3.9700e-03, 2.6560e-01,  ..., 1.1170e-02,\n",
      "          2.6340e-01, 1.6700e-03],\n",
      "         [2.6650e-01, 2.2900e-03, 2.6540e-01,  ..., 1.2400e-02,\n",
      "          2.6300e-01, 2.0000e-04],\n",
      "         ...,\n",
      "         [2.6750e-01, 3.2700e-03, 2.6720e-01,  ..., 1.1000e-02,\n",
      "          2.6530e-01, 1.2100e-03],\n",
      "         [2.6750e-01, 1.2700e-03, 2.6720e-01,  ..., 2.0000e-03,\n",
      "          2.6570e-01, 2.6500e-03],\n",
      "         [2.6750e-01, 1.2700e-03, 2.6720e-01,  ..., 1.4000e-03,\n",
      "          2.6540e-01, 1.2500e-03]]], dtype=torch.float64), tensor(0., dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "print(dataset_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3639, 0.0043, 0.3634,  ..., 0.0018, 0.3621, 0.0019],\n",
      "         [0.3639, 0.0043, 0.3634,  ..., 0.0123, 0.3620, 0.0020],\n",
      "         [0.3639, 0.0043, 0.3634,  ..., 0.0123, 0.3619, 0.0014],\n",
      "         ...,\n",
      "         [0.3640, 0.0039, 0.3635,  ..., 0.0018, 0.3619, 0.0019],\n",
      "         [0.3640, 0.0039, 0.3635,  ..., 0.0018, 0.3620, 0.0020],\n",
      "         [0.3640, 0.0039, 0.3635,  ..., 0.0019, 0.3619, 0.0019]]],\n",
      "       dtype=torch.float64)\n",
      "tensor(0., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x,y = dataset_val[1]\n",
    "print(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, -1, -1, -1, -1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 0, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1]\n",
      "[100, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 0.14750000000000796, 0.14750000000000796, 0.14750000000000796, 0.14750000000000796, 0.14750000000000796, 0.14750000000000796, 0.14750000000000796, 0.14750000000000796, 0.14750000000000796, 100.16500000000002, 100.16500000000002, 100.16500000000002, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 0.2850000000000108, 100.33000000000001, 100.33000000000001, 100.33000000000001, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 0.03160000000001162, 100.66120000000001, 100.66120000000001, 100.66120000000001, 100.66120000000001, 100.66120000000001, 100.66120000000001, 100.66120000000001, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 0.2524000000000086, 100.8268, 0.3628000000000071, 0.3628000000000071, 0.3628000000000071, 0.3628000000000071, 0.3628000000000071, 100.90960000000001, 100.90960000000001, 100.90960000000001, 100.90960000000001, 100.90960000000001, 100.90960000000001, 100.90960000000001, 100.90960000000001, 100.90960000000001, 100.90960000000001, 100.90960000000001, 100.90960000000001, 100.90960000000001, 100.90960000000001, 100.90960000000001, 100.90960000000001, 100.90960000000001, 100.90960000000001, 100.90960000000001, 100.90960000000001, 100.90960000000001, 0.33090000000001396, 0.33090000000001396, 0.33090000000001396, 0.33090000000001396, 0.33090000000001396, 0.33090000000001396, 101.15890000000002, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 0.1337000000000188, 101.29790000000001, 101.29790000000001, 101.29790000000001, 0.30050000000001376, 101.43690000000002, 0.10410000000001673, 0.10410000000001673, 0.10410000000001673, 0.10410000000001673, 0.10410000000001673, 101.57640000000002, 101.57640000000002, 101.57640000000002, 101.57640000000002, 101.57640000000002, 101.57640000000002, 101.57640000000002, 101.57640000000002, 101.57640000000002, 101.57640000000002, 101.57640000000002, 101.57640000000002, 101.57640000000002, 101.57640000000002, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 0.2715000000000316, 101.77170000000004, 101.77170000000004, 101.77170000000004, 101.77170000000004, 101.77170000000004, 101.77170000000004, 101.77170000000004, 101.77170000000004, 101.77170000000004, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 0.10370000000004609, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 101.88370000000005, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 0.24370000000004666, 101.85570000000004, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 0.07750000000002899, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 101.94000000000003, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 0.27420000000002176, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 101.99620000000002, 0.05320000000001812, 0.05320000000001812, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 102.13720000000002, 0.08140000000001635, 0.08140000000001635, 0.08140000000001635, 0.08140000000001635, 0.08140000000001635, 0.08140000000001635, 0.08140000000001635, 0.08140000000001635, 102.30640000000001, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 0.22240000000000748, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 102.4192, 0.19420000000000925, 0.19420000000000925, 0.19420000000000925, 0.19420000000000925, 0.19420000000000925, 0.19420000000000925, 0.19420000000000925, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 102.53200000000001, 0.10960000000000036, 102.56020000000001, 102.56020000000001, 102.56020000000001, 102.56020000000001, 102.56020000000001, 102.56020000000001, 102.56020000000001, 102.56020000000001, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 0.05760000000000787, 102.7866, 0.17080000000001405, 0.17080000000001405, 0.17080000000001405, 0.17080000000001405, 0.17080000000001405, 0.17080000000001405, 0.17080000000001405, 0.17080000000001405, 0.17080000000001405, 0.17080000000001405, 0.17080000000001405, 102.98470000000002, 102.98470000000002, 102.98470000000002, 102.98470000000002, 102.98470000000002, 102.98470000000002, 0.3406000000000091, 0.3406000000000091, 0.3406000000000091, 0.3406000000000091, 0.3406000000000091, 0.3406000000000091, 0.3406000000000091, 0.3406000000000091, 0.3406000000000091, 0.3406000000000091, 103.15450000000001, 103.15450000000001, 103.15450000000001, 103.15450000000001, 103.15450000000001, 103.15450000000001, 103.15450000000001, 0.005700000000004479, 0.005700000000004479, 0.005700000000004479, 0.005700000000004479, 0.005700000000004479, 0.005700000000004479, 0.005700000000004479, 0.005700000000004479, 103.2681, 103.2681, 103.2681, 103.2681, 103.2681, 103.2681, 0.09090000000000487, 103.4669, 103.4669, 103.4669, 0.14769999999998618, 0.14769999999998618, 0.14769999999998618, 0.14769999999998618, 0.14769999999998618, 0.14769999999998618, 0.14769999999998618, 0.14769999999998618, 0.14769999999998618, 0.14769999999998618, 0.14769999999998618, 0.14769999999998618, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 103.52369999999998, 0.3464999999999776, 0.3464999999999776, 0.3464999999999776, 0.3464999999999776, 0.3464999999999776, 0.3464999999999776, 0.3464999999999776, 0.3464999999999776, 0.3464999999999776, 103.66569999999999, 103.66569999999999, 0.12519999999997822, 0.12519999999997822, 0.12519999999997822, 0.12519999999997822, 0.12519999999997822, 0.12519999999997822, 0.12519999999997822, 0.12519999999997822, 0.12519999999997822, 0.12519999999997822, 103.80819999999999]\n"
     ]
    }
   ],
   "source": [
    "# myAccount = MyAccount(100)\n",
    "# tradeList = []\n",
    "# # 记录现金变化情况\n",
    "# cashList = []\n",
    "# cashList.append(myAccount.getCash())\n",
    "# # tmp_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=1, shuffle=True)\n",
    "# cnt = 0\n",
    "\n",
    "# for index in range(len(dataset_val)-2):\n",
    "#     x,y = dataset_val[index]\n",
    "#     x = torch.unsqueeze(x, dim = 0)\n",
    "#     # 考虑延迟效应，使用延迟2个时间点的价格作为交易价格\n",
    "#     afterX,afterY = dataset_val[index+2]\n",
    "#     afterX = torch.unsqueeze(afterX, dim = 0)\n",
    "#     cnt+=1\n",
    "#     x,y = x.to(device, dtype = torch.float), y.to(device, dtype=torch.int64)\n",
    "#     output = model(x)\n",
    "#     _, predictions = torch.max(output, 1)\n",
    "#     if predictions.item()==1:\n",
    "#         # 预测为保持不变,不做动作\n",
    "#         tradeList.append(0)\n",
    "#         cashList.append(myAccount.getCash())\n",
    "#     elif predictions.item()==2:\n",
    "#         # 预测为上涨趋势，则buy\n",
    "#         ask1 = afterX[0][0][0][2].item()\n",
    "#         askPrice, buyNumber = myAccount.buy(ask1)\n",
    "#         # 更新2个list\n",
    "#         tradeList.append(1)\n",
    "#         cashList.append(myAccount.getCash())\n",
    "#     else:\n",
    "#         # 预测为下降趋势，则sell\n",
    "#         bid1 = afterX[0][0][0][0].item()\n",
    "#         bidPrice, sellNumber = myAccount.sell(bid1)\n",
    "\n",
    "#         tradeList.append(-1)\n",
    "#         cashList.append(myAccount.getCash())\n",
    "#     if cnt==1000:\n",
    "#         break\n",
    "    \n",
    "# print(tradeList)\n",
    "# print(cashList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137.4417231976986\n"
     ]
    }
   ],
   "source": [
    "myAccount = MyAccount(100)\n",
    "tradeList = []\n",
    "# 记录现金变化情况\n",
    "cashList = []\n",
    "cashList.append(myAccount.getCash())\n",
    "cnt = 0\n",
    "\n",
    "tmp_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=1, shuffle=True)\n",
    "\n",
    "for x, y in tmp_loader:\n",
    "    cnt+=1\n",
    "    x,y = x.to(device, dtype = torch.float), y.to(device, dtype=torch.int64)\n",
    "    output = model(x)\n",
    "    _, predictions = torch.max(output, 1)\n",
    "    if predictions.item()==1:\n",
    "        # 预测为保持不变,不做动作\n",
    "        tradeList.append(0)\n",
    "        cashList.append(myAccount.getCash())\n",
    "    elif predictions.item()==2:\n",
    "        # 预测为上涨趋势，则buy\n",
    "        ask1 = x[0][0][0][2].item()\n",
    "        askPrice, buyNumber = myAccount.buy(ask1)\n",
    "        # 更新2个list\n",
    "        tradeList.append(1)\n",
    "        cashList.append(myAccount.getCash())\n",
    "    else:\n",
    "        # 预测为下降趋势，则sell\n",
    "        bid1 = x[0][0][0][0].item()\n",
    "        bidPrice, sellNumber = myAccount.sell(bid1)\n",
    "\n",
    "        tradeList.append(-1)\n",
    "        cashList.append(myAccount.getCash())\n",
    "    if cnt==1000:\n",
    "        bid1 = x[0][0][0][0].item()\n",
    "        bidPrice, sellNumber = myAccount.sell(bid1)\n",
    "\n",
    "        tradeList.append(-1)\n",
    "        cashList.append(myAccount.getCash())\n",
    "        break\n",
    "\n",
    "print(cashList[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots()\n",
    "axes.plot(range(len(cashList)), cashList)\n",
    "\n",
    "title = \"cash Change\"\n",
    "\n",
    "props = {'title': title,\n",
    "             'xlabel': 'time step',\n",
    "             'ylabel': 'RMB',\n",
    "             }\n",
    "axes.set(**props)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6660e-01, 1.2900e-03, 2.6540e-01, 2.2500e-03, 2.6690e-01, 2.4600e-03,\n",
      "        2.6530e-01, 1.0330e-02, 2.6700e-01, 5.0000e-04, 2.6510e-01, 2.8900e-03,\n",
      "        2.6710e-01, 1.4300e-03, 2.6500e-01, 2.0000e-02, 2.6740e-01, 1.8000e-03,\n",
      "        2.6480e-01, 1.2100e-03, 2.6770e-01, 1.0000e-02, 2.6470e-01, 4.2500e-03,\n",
      "        2.6810e-01, 2.1000e-04, 2.6460e-01, 2.6300e-03, 2.6880e-01, 5.0000e-03,\n",
      "        2.6440e-01, 1.6900e-03, 2.6900e-01, 1.2400e-02, 2.6410e-01, 2.8200e-03,\n",
      "        2.7000e-01, 2.0000e-03, 2.6380e-01, 1.5600e-03])\n",
      "tensor([0])\n",
      "tensor([2.6690e-01, 3.9700e-03, 2.6560e-01, 1.4400e-03, 2.6700e-01, 5.0000e-04,\n",
      "        2.6540e-01, 2.2500e-03, 2.6710e-01, 1.4300e-03, 2.6530e-01, 1.0330e-02,\n",
      "        2.6770e-01, 1.0000e-02, 2.6510e-01, 7.0200e-03, 2.6810e-01, 2.1000e-04,\n",
      "        2.6500e-01, 2.0000e-02, 2.6880e-01, 5.0000e-03, 2.6460e-01, 2.6300e-03,\n",
      "        2.6900e-01, 1.4200e-02, 2.6440e-01, 1.6900e-03, 2.6970e-01, 1.4810e-02,\n",
      "        2.6410e-01, 2.8200e-03, 2.7000e-01, 2.0000e-03, 2.6380e-01, 1.5600e-03,\n",
      "        2.7090e-01, 1.1170e-02, 2.6340e-01, 1.6700e-03])\n",
      "tensor([0])\n",
      "tensor([2.6650e-01, 2.2900e-03, 2.6540e-01, 2.2500e-03, 2.6660e-01, 3.0700e-03,\n",
      "        2.6530e-01, 1.0330e-02, 2.6670e-01, 3.0700e-03, 2.6510e-01, 7.0200e-03,\n",
      "        2.6690e-01, 7.0400e-03, 2.6500e-01, 2.0000e-02, 2.6700e-01, 5.0000e-04,\n",
      "        2.6460e-01, 2.6300e-03, 2.6710e-01, 1.4300e-03, 2.6440e-01, 1.6900e-03,\n",
      "        2.6770e-01, 1.0000e-02, 2.6410e-01, 2.8200e-03, 2.6810e-01, 2.1000e-04,\n",
      "        2.6380e-01, 1.5600e-03, 2.6880e-01, 5.0000e-03, 2.6340e-01, 1.6700e-03,\n",
      "        2.6900e-01, 1.2400e-02, 2.6300e-01, 2.0000e-04])\n",
      "tensor([0])\n",
      "tensor([2.6690e-01, 3.9700e-03, 2.6540e-01, 2.2500e-03, 2.6700e-01, 5.0000e-04,\n",
      "        2.6530e-01, 1.0330e-02, 2.6710e-01, 1.4300e-03, 2.6510e-01, 7.0200e-03,\n",
      "        2.6770e-01, 1.0000e-02, 2.6500e-01, 2.0000e-02, 2.6810e-01, 2.1000e-04,\n",
      "        2.6460e-01, 2.6300e-03, 2.6880e-01, 5.0000e-03, 2.6440e-01, 1.6900e-03,\n",
      "        2.6900e-01, 1.2400e-02, 2.6410e-01, 2.8200e-03, 2.6970e-01, 1.4810e-02,\n",
      "        2.6380e-01, 1.5600e-03, 2.7000e-01, 2.0000e-03, 2.6340e-01, 1.6700e-03,\n",
      "        2.7090e-01, 1.1170e-02, 2.6300e-01, 2.0000e-04])\n",
      "tensor([0])\n",
      "tensor([2.6650e-01, 2.8700e-03, 2.6540e-01, 2.2500e-03, 2.6660e-01, 3.0700e-03,\n",
      "        2.6530e-01, 1.0330e-02, 2.6690e-01, 3.9700e-03, 2.6510e-01, 7.0200e-03,\n",
      "        2.6700e-01, 5.0000e-04, 2.6500e-01, 2.0000e-02, 2.6710e-01, 1.4300e-03,\n",
      "        2.6460e-01, 2.6300e-03, 2.6770e-01, 1.0000e-02, 2.6440e-01, 1.6900e-03,\n",
      "        2.6810e-01, 2.1000e-04, 2.6410e-01, 2.8200e-03, 2.6880e-01, 5.0000e-03,\n",
      "        2.6380e-01, 1.5600e-03, 2.6900e-01, 1.2400e-02, 2.6340e-01, 1.6700e-03,\n",
      "        2.6970e-01, 1.4810e-02, 2.6300e-01, 2.0000e-04])\n",
      "tensor([0])\n",
      "tensor([0.2669, 0.0015, 0.2654, 0.0022, 0.2670, 0.0005, 0.2653, 0.0103, 0.2671,\n",
      "        0.0014, 0.2651, 0.0070, 0.2672, 0.0025, 0.2650, 0.0200, 0.2677, 0.0100,\n",
      "        0.2647, 0.0018, 0.2688, 0.0050, 0.2646, 0.0026, 0.2690, 0.0124, 0.2644,\n",
      "        0.0017, 0.2697, 0.0148, 0.2641, 0.0028, 0.2700, 0.0022, 0.2638, 0.0016,\n",
      "        0.2709, 0.0112, 0.2634, 0.0017])\n",
      "tensor([0])\n",
      "tensor([0.2669, 0.0015, 0.2654, 0.0058, 0.2670, 0.0005, 0.2653, 0.0103, 0.2671,\n",
      "        0.0046, 0.2652, 0.0028, 0.2672, 0.0025, 0.2651, 0.0088, 0.2674, 0.0026,\n",
      "        0.2650, 0.0200, 0.2677, 0.0118, 0.2649, 0.0026, 0.2688, 0.0050, 0.2644,\n",
      "        0.0017, 0.2690, 0.0014, 0.2641, 0.0028, 0.2695, 0.0110, 0.2638, 0.0016,\n",
      "        0.2697, 0.0148, 0.2634, 0.0017])\n",
      "tensor([1])\n",
      "tensor([0.2670, 0.0041, 0.2654, 0.0058, 0.2671, 0.0104, 0.2653, 0.0103, 0.2672,\n",
      "        0.0025, 0.2652, 0.0053, 0.2674, 0.0026, 0.2651, 0.0046, 0.2677, 0.0100,\n",
      "        0.2650, 0.0200, 0.2684, 0.0018, 0.2649, 0.0026, 0.2688, 0.0050, 0.2646,\n",
      "        0.0018, 0.2690, 0.0014, 0.2644, 0.0017, 0.2695, 0.0110, 0.2641, 0.0028,\n",
      "        0.2697, 0.0148, 0.2638, 0.0016])\n",
      "tensor([2])\n",
      "tensor([0.2670, 0.0041, 0.2654, 0.0058, 0.2671, 0.0084, 0.2653, 0.0103, 0.2672,\n",
      "        0.0025, 0.2652, 0.0053, 0.2674, 0.0026, 0.2651, 0.0046, 0.2677, 0.0100,\n",
      "        0.2650, 0.0200, 0.2678, 0.0018, 0.2649, 0.0026, 0.2688, 0.0050, 0.2644,\n",
      "        0.0017, 0.2690, 0.0014, 0.2641, 0.0028, 0.2695, 0.0110, 0.2638, 0.0016,\n",
      "        0.2697, 0.0148, 0.2634, 0.0017])\n",
      "tensor([2])\n",
      "tensor([2.6700e-01, 4.0900e-03, 2.6580e-01, 1.0330e-02, 2.6710e-01, 8.4400e-03,\n",
      "        2.6520e-01, 5.2800e-03, 2.6720e-01, 2.4600e-03, 2.6510e-01, 4.5700e-03,\n",
      "        2.6740e-01, 2.6300e-03, 2.6500e-01, 2.0000e-02, 2.6770e-01, 1.0000e-02,\n",
      "        2.6490e-01, 2.6300e-03, 2.6780e-01, 1.8000e-03, 2.6440e-01, 1.6900e-03,\n",
      "        2.6880e-01, 5.0000e-03, 2.6410e-01, 2.8200e-03, 2.6900e-01, 1.4000e-03,\n",
      "        2.6380e-01, 1.5600e-03, 2.6950e-01, 1.1000e-02, 2.6340e-01, 1.6700e-03,\n",
      "        2.6970e-01, 1.4810e-02, 2.6300e-01, 2.0000e-04])\n",
      "tensor([2])\n",
      "tensor([0.2670, 0.0041, 0.2659, 0.0026, 0.2671, 0.0073, 0.2658, 0.0103, 0.2672,\n",
      "        0.0025, 0.2655, 0.0013, 0.2673, 0.0012, 0.2654, 0.0024, 0.2674, 0.0026,\n",
      "        0.2652, 0.0028, 0.2675, 0.0026, 0.2651, 0.0035, 0.2677, 0.0100, 0.2650,\n",
      "        0.0200, 0.2678, 0.0018, 0.2649, 0.0026, 0.2688, 0.0050, 0.2644, 0.0017,\n",
      "        0.2690, 0.0014, 0.2641, 0.0028])\n",
      "tensor([2])\n",
      "tensor([0.2669, 0.0035, 0.2659, 0.0026, 0.2670, 0.0025, 0.2658, 0.0103, 0.2671,\n",
      "        0.0073, 0.2655, 0.0013, 0.2673, 0.0012, 0.2654, 0.0024, 0.2674, 0.0026,\n",
      "        0.2653, 0.0026, 0.2675, 0.0050, 0.2652, 0.0028, 0.2677, 0.0100, 0.2651,\n",
      "        0.0035, 0.2688, 0.0050, 0.2650, 0.0200, 0.2690, 0.0014, 0.2649, 0.0026,\n",
      "        0.2695, 0.0110, 0.2644, 0.0017])\n",
      "tensor([2])\n",
      "tensor([0.2669, 0.0035, 0.2659, 0.0026, 0.2670, 0.0025, 0.2658, 0.0103, 0.2671,\n",
      "        0.0073, 0.2655, 0.0034, 0.2673, 0.0012, 0.2654, 0.0024, 0.2674, 0.0026,\n",
      "        0.2653, 0.0026, 0.2675, 0.0050, 0.2652, 0.0028, 0.2677, 0.0118, 0.2651,\n",
      "        0.0017, 0.2688, 0.0050, 0.2650, 0.0200, 0.2690, 0.0014, 0.2649, 0.0026,\n",
      "        0.2695, 0.0110, 0.2644, 0.0017])\n",
      "tensor([2])\n",
      "tensor([0.2669, 0.0035, 0.2661, 0.0066, 0.2670, 0.0025, 0.2658, 0.0037, 0.2671,\n",
      "        0.0073, 0.2655, 0.0034, 0.2673, 0.0012, 0.2654, 0.0024, 0.2674, 0.0049,\n",
      "        0.2653, 0.0026, 0.2675, 0.0026, 0.2651, 0.0017, 0.2677, 0.0118, 0.2650,\n",
      "        0.0200, 0.2688, 0.0050, 0.2644, 0.0017, 0.2690, 0.0014, 0.2641, 0.0028,\n",
      "        0.2695, 0.0110, 0.2638, 0.0016])\n",
      "tensor([2])\n",
      "tensor([2.6700e-01, 2.8800e-03, 2.6610e-01, 1.0330e-02, 2.6710e-01, 9.2700e-03,\n",
      "        2.6550e-01, 1.6500e-03, 2.6730e-01, 1.1900e-03, 2.6540e-01, 2.4000e-03,\n",
      "        2.6740e-01, 4.9300e-03, 2.6510e-01, 1.6800e-03, 2.6750e-01, 2.6300e-03,\n",
      "        2.6500e-01, 2.0000e-02, 2.6770e-01, 1.1800e-02, 2.6440e-01, 1.6900e-03,\n",
      "        2.6880e-01, 5.0000e-03, 2.6410e-01, 2.8200e-03, 2.6900e-01, 1.4000e-03,\n",
      "        2.6380e-01, 1.5600e-03, 2.6950e-01, 1.1000e-02, 2.6300e-01, 2.0000e-04,\n",
      "        2.6970e-01, 1.4810e-02, 2.6280e-01, 1.2650e-02])\n",
      "tensor([2])\n",
      "tensor([0.2670, 0.0029, 0.2661, 0.0103, 0.2671, 0.0073, 0.2657, 0.0027, 0.2673,\n",
      "        0.0012, 0.2655, 0.0016, 0.2674, 0.0049, 0.2651, 0.0017, 0.2675, 0.0026,\n",
      "        0.2650, 0.0200, 0.2677, 0.0100, 0.2647, 0.0018, 0.2687, 0.0018, 0.2644,\n",
      "        0.0017, 0.2688, 0.0050, 0.2641, 0.0028, 0.2690, 0.0014, 0.2638, 0.0016,\n",
      "        0.2697, 0.0148, 0.2632, 0.0110])\n",
      "tensor([2])\n",
      "tensor([0.2670, 0.0029, 0.2661, 0.0103, 0.2671, 0.0073, 0.2657, 0.0027, 0.2674,\n",
      "        0.0026, 0.2656, 0.0023, 0.2675, 0.0042, 0.2655, 0.0016, 0.2677, 0.0100,\n",
      "        0.2653, 0.0018, 0.2688, 0.0050, 0.2651, 0.0017, 0.2690, 0.0014, 0.2650,\n",
      "        0.0200, 0.2697, 0.0148, 0.2644, 0.0017, 0.2699, 0.0110, 0.2641, 0.0028,\n",
      "        0.2700, 0.0022, 0.2638, 0.0016])\n",
      "tensor([2])\n",
      "tensor([0.2670, 0.0030, 0.2661, 0.0103, 0.2671, 0.0073, 0.2657, 0.0027, 0.2674,\n",
      "        0.0026, 0.2656, 0.0023, 0.2675, 0.0042, 0.2655, 0.0016, 0.2676, 0.0023,\n",
      "        0.2653, 0.0027, 0.2677, 0.0100, 0.2651, 0.0017, 0.2687, 0.0018, 0.2650,\n",
      "        0.0200, 0.2688, 0.0050, 0.2644, 0.0017, 0.2690, 0.0014, 0.2641, 0.0028,\n",
      "        0.2697, 0.0148, 0.2638, 0.0016])\n",
      "tensor([2])\n",
      "tensor([0.2670, 0.0005, 0.2663, 0.0066, 0.2671, 0.0073, 0.2661, 0.0037, 0.2674,\n",
      "        0.0026, 0.2657, 0.0027, 0.2675, 0.0016, 0.2656, 0.0023, 0.2676, 0.0023,\n",
      "        0.2655, 0.0016, 0.2677, 0.0100, 0.2654, 0.0018, 0.2687, 0.0018, 0.2653,\n",
      "        0.0027, 0.2688, 0.0050, 0.2651, 0.0017, 0.2690, 0.0014, 0.2650, 0.0200,\n",
      "        0.2697, 0.0148, 0.2644, 0.0017])\n",
      "tensor([2])\n",
      "tensor([2.6700e-01, 5.0000e-04, 2.6630e-01, 1.0330e-02, 2.6710e-01, 7.2700e-03,\n",
      "        2.6600e-01, 1.8000e-03, 2.6740e-01, 2.6300e-03, 2.6570e-01, 2.6600e-03,\n",
      "        2.6750e-01, 1.6000e-03, 2.6560e-01, 2.2900e-03, 2.6760e-01, 2.3000e-03,\n",
      "        2.6550e-01, 1.6500e-03, 2.6770e-01, 1.0000e-02, 2.6510e-01, 1.6800e-03,\n",
      "        2.6880e-01, 5.0000e-03, 2.6500e-01, 2.0000e-02, 2.6900e-01, 1.4000e-03,\n",
      "        2.6440e-01, 1.6900e-03, 2.6970e-01, 1.4810e-02, 2.6410e-01, 2.8200e-03,\n",
      "        2.6980e-01, 2.1000e-04, 2.6380e-01, 1.5600e-03])\n",
      "tensor([2])\n",
      "tensor([2.6700e-01, 5.0000e-04, 2.6630e-01, 1.0330e-02, 2.6710e-01, 7.2700e-03,\n",
      "        2.6610e-01, 2.8800e-03, 2.6750e-01, 1.6000e-03, 2.6570e-01, 2.6600e-03,\n",
      "        2.6770e-01, 1.2300e-02, 2.6560e-01, 2.2900e-03, 2.6880e-01, 5.0000e-03,\n",
      "        2.6550e-01, 1.6500e-03, 2.6900e-01, 1.4000e-03, 2.6510e-01, 1.6800e-03,\n",
      "        2.6940e-01, 2.1000e-04, 2.6500e-01, 2.0000e-02, 2.6970e-01, 1.4810e-02,\n",
      "        2.6440e-01, 1.6900e-03, 2.6990e-01, 1.1000e-02, 2.6410e-01, 2.8200e-03,\n",
      "        2.7000e-01, 2.0000e-03, 2.6380e-01, 1.5600e-03])\n",
      "tensor([2])\n",
      "tensor([2.6700e-01, 5.0000e-04, 2.6630e-01, 1.0330e-02, 2.6710e-01, 7.2700e-03,\n",
      "        2.6620e-01, 1.6900e-03, 2.6750e-01, 1.0970e-02, 2.6610e-01, 2.8800e-03,\n",
      "        2.6770e-01, 1.2300e-02, 2.6570e-01, 4.9500e-03, 2.6810e-01, 2.1000e-04,\n",
      "        2.6550e-01, 1.6500e-03, 2.6870e-01, 1.8000e-03, 2.6510e-01, 1.6800e-03,\n",
      "        2.6880e-01, 5.0000e-03, 2.6500e-01, 2.0000e-02, 2.6900e-01, 1.4000e-03,\n",
      "        2.6440e-01, 1.6900e-03, 2.6970e-01, 1.4810e-02, 2.6410e-01, 2.8200e-03,\n",
      "        2.6990e-01, 1.1000e-02, 2.6380e-01, 1.5600e-03])\n",
      "tensor([2])\n",
      "tensor([2.6700e-01, 5.0000e-04, 2.6620e-01, 1.6900e-03, 2.6710e-01, 7.2700e-03,\n",
      "        2.6610e-01, 2.8800e-03, 2.6750e-01, 2.0340e-02, 2.6570e-01, 4.9500e-03,\n",
      "        2.6770e-01, 1.2300e-02, 2.6550e-01, 1.6500e-03, 2.6780e-01, 1.8000e-03,\n",
      "        2.6510e-01, 1.6800e-03, 2.6810e-01, 2.1000e-04, 2.6500e-01, 2.0000e-02,\n",
      "        2.6880e-01, 5.0000e-03, 2.6440e-01, 1.6900e-03, 2.6900e-01, 1.4000e-03,\n",
      "        2.6410e-01, 2.8200e-03, 2.6970e-01, 1.4810e-02, 2.6380e-01, 1.5600e-03,\n",
      "        2.6990e-01, 1.1000e-02, 2.6320e-01, 1.1000e-02])\n",
      "tensor([2])\n",
      "tensor([0.2665, 0.0017, 0.2662, 0.0017, 0.2666, 0.0031, 0.2661, 0.0029, 0.2670,\n",
      "        0.0005, 0.2659, 0.0121, 0.2671, 0.0093, 0.2657, 0.0027, 0.2673, 0.0011,\n",
      "        0.2656, 0.0072, 0.2675, 0.0187, 0.2655, 0.0016, 0.2676, 0.0023, 0.2654,\n",
      "        0.0062, 0.2677, 0.0100, 0.2651, 0.0017, 0.2678, 0.0018, 0.2650, 0.0200,\n",
      "        0.2688, 0.0050, 0.2644, 0.0035])\n",
      "tensor([2])\n",
      "tensor([0.2665, 0.0017, 0.2662, 0.0017, 0.2666, 0.0031, 0.2661, 0.0029, 0.2670,\n",
      "        0.0005, 0.2659, 0.0121, 0.2671, 0.0093, 0.2657, 0.0027, 0.2673, 0.0034,\n",
      "        0.2656, 0.0049, 0.2675, 0.0187, 0.2655, 0.0016, 0.2677, 0.0100, 0.2654,\n",
      "        0.0062, 0.2678, 0.0018, 0.2653, 0.0023, 0.2688, 0.0050, 0.2651, 0.0017,\n",
      "        0.2690, 0.0014, 0.2650, 0.0200])\n",
      "tensor([2])\n",
      "tensor([0.2664, 0.0006, 0.2662, 0.0017, 0.2665, 0.0017, 0.2661, 0.0029, 0.2666,\n",
      "        0.0031, 0.2660, 0.0121, 0.2670, 0.0005, 0.2656, 0.0049, 0.2671, 0.0078,\n",
      "        0.2655, 0.0016, 0.2673, 0.0039, 0.2654, 0.0062, 0.2675, 0.0190, 0.2653,\n",
      "        0.0023, 0.2677, 0.0100, 0.2651, 0.0017, 0.2678, 0.0018, 0.2650, 0.0200,\n",
      "        0.2680, 0.0013, 0.2647, 0.0014])\n",
      "tensor([2])\n",
      "tensor([0.2664, 0.0006, 0.2662, 0.0017, 0.2665, 0.0048, 0.2661, 0.0029, 0.2670,\n",
      "        0.0005, 0.2660, 0.0121, 0.2671, 0.0058, 0.2656, 0.0075, 0.2673, 0.0039,\n",
      "        0.2654, 0.0132, 0.2675, 0.0190, 0.2653, 0.0023, 0.2677, 0.0100, 0.2651,\n",
      "        0.0017, 0.2678, 0.0018, 0.2650, 0.0200, 0.2680, 0.0013, 0.2647, 0.0014,\n",
      "        0.2688, 0.0050, 0.2644, 0.0017])\n",
      "tensor([2])\n",
      "tensor([0.2665, 0.0048, 0.2662, 0.0017, 0.2670, 0.0005, 0.2661, 0.0029, 0.2671,\n",
      "        0.0060, 0.2660, 0.0121, 0.2673, 0.0039, 0.2656, 0.0075, 0.2675, 0.0187,\n",
      "        0.2654, 0.0132, 0.2677, 0.0100, 0.2653, 0.0023, 0.2680, 0.0013, 0.2651,\n",
      "        0.0017, 0.2688, 0.0050, 0.2650, 0.0200, 0.2690, 0.0014, 0.2647, 0.0014,\n",
      "        0.2697, 0.0148, 0.2644, 0.0035])\n",
      "tensor([2])\n",
      "tensor([0.2670, 0.0005, 0.2662, 0.0045, 0.2671, 0.0060, 0.2661, 0.0029, 0.2673,\n",
      "        0.0023, 0.2660, 0.0121, 0.2675, 0.0204, 0.2657, 0.0011, 0.2677, 0.0100,\n",
      "        0.2656, 0.0075, 0.2680, 0.0013, 0.2654, 0.0132, 0.2688, 0.0050, 0.2653,\n",
      "        0.0023, 0.2690, 0.0014, 0.2651, 0.0017, 0.2697, 0.0148, 0.2650, 0.0200,\n",
      "        0.2699, 0.0110, 0.2647, 0.0014])\n",
      "tensor([2])\n",
      "tensor([0.2670, 0.0005, 0.2662, 0.0017, 0.2671, 0.0060, 0.2661, 0.0029, 0.2675,\n",
      "        0.0204, 0.2660, 0.0121, 0.2677, 0.0100, 0.2657, 0.0029, 0.2680, 0.0013,\n",
      "        0.2656, 0.0047, 0.2688, 0.0050, 0.2654, 0.0132, 0.2690, 0.0014, 0.2651,\n",
      "        0.0017, 0.2697, 0.0148, 0.2650, 0.0200, 0.2699, 0.0110, 0.2647, 0.0014,\n",
      "        0.2700, 0.0020, 0.2644, 0.0017])\n",
      "tensor([2])\n",
      "tensor([0.2670, 0.0005, 0.2662, 0.0017, 0.2671, 0.0060, 0.2661, 0.0029, 0.2675,\n",
      "        0.0204, 0.2660, 0.0121, 0.2676, 0.0022, 0.2657, 0.0011, 0.2677, 0.0100,\n",
      "        0.2656, 0.0047, 0.2680, 0.0013, 0.2654, 0.0132, 0.2688, 0.0050, 0.2651,\n",
      "        0.0017, 0.2690, 0.0014, 0.2650, 0.0200, 0.2697, 0.0148, 0.2647, 0.0014,\n",
      "        0.2699, 0.0110, 0.2644, 0.0017])\n",
      "tensor([2])\n",
      "tensor([2.6700e-01, 2.1900e-03, 2.6620e-01, 1.6900e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6610e-01, 1.5020e-02, 2.6750e-01, 2.0360e-02, 2.6570e-01, 1.5900e-03,\n",
      "        2.6760e-01, 2.1700e-03, 2.6560e-01, 4.7500e-03, 2.6770e-01, 1.0000e-02,\n",
      "        2.6540e-01, 1.3190e-02, 2.6800e-01, 1.2600e-03, 2.6510e-01, 1.6800e-03,\n",
      "        2.6860e-01, 1.8000e-03, 2.6500e-01, 2.0000e-02, 2.6880e-01, 5.0000e-03,\n",
      "        2.6470e-01, 1.4200e-03, 2.6900e-01, 1.4000e-03, 2.6440e-01, 1.6900e-03,\n",
      "        2.6910e-01, 2.1000e-04, 2.6410e-01, 2.8200e-03])\n",
      "tensor([0])\n",
      "tensor([2.6700e-01, 4.1900e-03, 2.6620e-01, 1.6900e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6610e-01, 1.5020e-02, 2.6750e-01, 2.0360e-02, 2.6580e-01, 2.2100e-03,\n",
      "        2.6760e-01, 2.1700e-03, 2.6570e-01, 1.5900e-03, 2.6770e-01, 1.0000e-02,\n",
      "        2.6560e-01, 1.4790e-02, 2.6800e-01, 1.2600e-03, 2.6540e-01, 6.9800e-03,\n",
      "        2.6880e-01, 5.0000e-03, 2.6510e-01, 1.6800e-03, 2.6900e-01, 1.4000e-03,\n",
      "        2.6500e-01, 2.0000e-02, 2.6910e-01, 2.1000e-04, 2.6470e-01, 1.4200e-03,\n",
      "        2.6970e-01, 1.4810e-02, 2.6440e-01, 1.6900e-03])\n",
      "tensor([2])\n",
      "tensor([2.6700e-01, 4.1900e-03, 2.6620e-01, 1.6900e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6610e-01, 1.5020e-02, 2.6750e-01, 2.0360e-02, 2.6580e-01, 2.2100e-03,\n",
      "        2.6760e-01, 2.1700e-03, 2.6570e-01, 1.5900e-03, 2.6770e-01, 1.0000e-02,\n",
      "        2.6560e-01, 1.1340e-02, 2.6780e-01, 1.8000e-03, 2.6540e-01, 1.2500e-03,\n",
      "        2.6800e-01, 1.2600e-03, 2.6510e-01, 1.6800e-03, 2.6880e-01, 5.0000e-03,\n",
      "        2.6500e-01, 2.0000e-02, 2.6900e-01, 1.4000e-03, 2.6470e-01, 1.4200e-03,\n",
      "        2.6910e-01, 2.1000e-04, 2.6440e-01, 1.6900e-03])\n",
      "tensor([2])\n",
      "tensor([2.6690e-01, 1.7020e-02, 2.6620e-01, 1.6900e-03, 2.6700e-01, 2.1900e-03,\n",
      "        2.6610e-01, 1.5020e-02, 2.6710e-01, 5.8400e-03, 2.6580e-01, 2.2100e-03,\n",
      "        2.6750e-01, 2.2500e-02, 2.6560e-01, 1.9250e-02, 2.6770e-01, 1.0000e-02,\n",
      "        2.6540e-01, 1.2500e-03, 2.6780e-01, 1.8000e-03, 2.6510e-01, 3.4800e-03,\n",
      "        2.6800e-01, 1.2600e-03, 2.6500e-01, 2.0000e-02, 2.6880e-01, 5.0000e-03,\n",
      "        2.6470e-01, 1.4200e-03, 2.6900e-01, 1.4000e-03, 2.6440e-01, 1.6900e-03,\n",
      "        2.6910e-01, 2.1000e-04, 2.6410e-01, 2.8200e-03])\n",
      "tensor([2])\n",
      "tensor([2.6670e-01, 4.9000e-04, 2.6620e-01, 1.6900e-03, 2.6690e-01, 1.7020e-02,\n",
      "        2.6610e-01, 1.5020e-02, 2.6700e-01, 2.1900e-03, 2.6560e-01, 2.1460e-02,\n",
      "        2.6710e-01, 5.8400e-03, 2.6550e-01, 3.9300e-03, 2.6750e-01, 2.2500e-02,\n",
      "        2.6540e-01, 1.2500e-03, 2.6770e-01, 1.0000e-02, 2.6510e-01, 1.6800e-03,\n",
      "        2.6800e-01, 1.2600e-03, 2.6500e-01, 2.0000e-02, 2.6880e-01, 5.0000e-03,\n",
      "        2.6470e-01, 1.4200e-03, 2.6900e-01, 1.4000e-03, 2.6440e-01, 1.6900e-03,\n",
      "        2.6940e-01, 2.1000e-04, 2.6410e-01, 2.8200e-03])\n",
      "tensor([2])\n",
      "tensor([2.6670e-01, 4.9000e-04, 2.6620e-01, 1.6900e-03, 2.6690e-01, 1.7020e-02,\n",
      "        2.6610e-01, 2.8800e-03, 2.6700e-01, 2.1900e-03, 2.6590e-01, 1.2140e-02,\n",
      "        2.6710e-01, 5.8400e-03, 2.6560e-01, 1.4140e-02, 2.6750e-01, 2.2500e-02,\n",
      "        2.6550e-01, 3.9300e-03, 2.6770e-01, 1.0000e-02, 2.6540e-01, 1.2500e-03,\n",
      "        2.6800e-01, 1.2600e-03, 2.6510e-01, 1.6800e-03, 2.6850e-01, 2.1000e-04,\n",
      "        2.6500e-01, 2.0000e-02, 2.6880e-01, 5.0000e-03, 2.6470e-01, 1.4200e-03,\n",
      "        2.6900e-01, 1.4000e-03, 2.6440e-01, 1.6900e-03])\n",
      "tensor([2])\n",
      "tensor([2.6670e-01, 4.9000e-04, 2.6620e-01, 1.6900e-03, 2.6690e-01, 1.7020e-02,\n",
      "        2.6610e-01, 2.8800e-03, 2.6700e-01, 2.1900e-03, 2.6600e-01, 1.8400e-03,\n",
      "        2.6710e-01, 5.8400e-03, 2.6590e-01, 1.2140e-02, 2.6750e-01, 2.0360e-02,\n",
      "        2.6560e-01, 7.4600e-03, 2.6770e-01, 1.0000e-02, 2.6550e-01, 2.1300e-03,\n",
      "        2.6780e-01, 1.8000e-03, 2.6540e-01, 1.5250e-02, 2.6800e-01, 1.2600e-03,\n",
      "        2.6510e-01, 1.6800e-03, 2.6850e-01, 2.1000e-04, 2.6470e-01, 1.4200e-03,\n",
      "        2.6880e-01, 5.0000e-03, 2.6440e-01, 1.6900e-03])\n",
      "tensor([2])\n",
      "tensor([2.6670e-01, 4.9000e-04, 2.6620e-01, 1.6900e-03, 2.6690e-01, 1.7020e-02,\n",
      "        2.6610e-01, 2.8800e-03, 2.6700e-01, 2.1900e-03, 2.6600e-01, 1.8400e-03,\n",
      "        2.6710e-01, 5.8400e-03, 2.6560e-01, 7.4600e-03, 2.6730e-01, 6.3800e-03,\n",
      "        2.6550e-01, 2.1300e-03, 2.6750e-01, 2.0910e-02, 2.6540e-01, 1.1690e-02,\n",
      "        2.6770e-01, 1.0000e-02, 2.6530e-01, 1.8000e-03, 2.6780e-01, 1.8000e-03,\n",
      "        2.6510e-01, 1.6800e-03, 2.6800e-01, 1.2600e-03, 2.6470e-01, 1.4200e-03,\n",
      "        2.6840e-01, 2.1000e-04, 2.6440e-01, 1.6900e-03])\n",
      "tensor([0])\n",
      "tensor([2.6670e-01, 4.9000e-04, 2.6620e-01, 1.6900e-03, 2.6690e-01, 1.7020e-02,\n",
      "        2.6610e-01, 2.8800e-03, 2.6700e-01, 2.1900e-03, 2.6600e-01, 1.3980e-02,\n",
      "        2.6710e-01, 5.8400e-03, 2.6560e-01, 7.4600e-03, 2.6730e-01, 3.7500e-03,\n",
      "        2.6550e-01, 2.1300e-03, 2.6740e-01, 2.1700e-03, 2.6540e-01, 1.1690e-02,\n",
      "        2.6750e-01, 1.8740e-02, 2.6530e-01, 1.8000e-03, 2.6770e-01, 1.0000e-02,\n",
      "        2.6510e-01, 1.6800e-03, 2.6800e-01, 1.2600e-03, 2.6470e-01, 1.4200e-03,\n",
      "        2.6840e-01, 2.1000e-04, 2.6440e-01, 1.6900e-03])\n",
      "tensor([0])\n",
      "tensor([2.6670e-01, 4.9000e-04, 2.6620e-01, 3.6900e-03, 2.6690e-01, 1.5020e-02,\n",
      "        2.6610e-01, 2.8800e-03, 2.6700e-01, 2.1900e-03, 2.6600e-01, 1.3980e-02,\n",
      "        2.6710e-01, 5.8400e-03, 2.6570e-01, 5.2500e-03, 2.6730e-01, 1.1200e-03,\n",
      "        2.6550e-01, 2.1300e-03, 2.6750e-01, 2.0720e-02, 2.6540e-01, 1.1690e-02,\n",
      "        2.6770e-01, 1.1800e-02, 2.6530e-01, 1.8000e-03, 2.6800e-01, 1.2600e-03,\n",
      "        2.6510e-01, 1.6800e-03, 2.6810e-01, 2.1000e-04, 2.6470e-01, 1.4200e-03,\n",
      "        2.6880e-01, 5.0000e-03, 2.6440e-01, 1.6900e-03])\n",
      "tensor([0])\n",
      "tensor([2.6670e-01, 4.9000e-04, 2.6630e-01, 2.0000e-03, 2.6690e-01, 1.5020e-02,\n",
      "        2.6620e-01, 1.6900e-03, 2.6700e-01, 2.1900e-03, 2.6610e-01, 1.5020e-02,\n",
      "        2.6710e-01, 5.8400e-03, 2.6600e-01, 1.8400e-03, 2.6730e-01, 1.1200e-03,\n",
      "        2.6570e-01, 5.2500e-03, 2.6750e-01, 2.0720e-02, 2.6550e-01, 2.1300e-03,\n",
      "        2.6770e-01, 1.1800e-02, 2.6540e-01, 1.1690e-02, 2.6800e-01, 1.2600e-03,\n",
      "        2.6530e-01, 1.8000e-03, 2.6810e-01, 2.1000e-04, 2.6510e-01, 1.6800e-03,\n",
      "        2.6880e-01, 5.0000e-03, 2.6470e-01, 1.4200e-03])\n",
      "tensor([0])\n",
      "tensor([2.6700e-01, 2.1900e-03, 2.6640e-01, 5.0000e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6630e-01, 2.0000e-03, 2.6730e-01, 1.1200e-03, 2.6620e-01, 1.6900e-03,\n",
      "        2.6750e-01, 2.0720e-02, 2.6610e-01, 1.5020e-02, 2.6770e-01, 1.1800e-02,\n",
      "        2.6600e-01, 1.8400e-03, 2.6800e-01, 1.2600e-03, 2.6570e-01, 6.4600e-03,\n",
      "        2.6810e-01, 2.1000e-04, 2.6560e-01, 1.9500e-03, 2.6880e-01, 5.0000e-03,\n",
      "        2.6550e-01, 6.5700e-03, 2.6900e-01, 1.4000e-03, 2.6540e-01, 7.0000e-03,\n",
      "        2.6970e-01, 1.4810e-02, 2.6530e-01, 1.8000e-03])\n",
      "tensor([0])\n",
      "tensor([2.6700e-01, 2.1900e-03, 2.6620e-01, 1.6900e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6610e-01, 1.5020e-02, 2.6730e-01, 1.1200e-03, 2.6600e-01, 1.8400e-03,\n",
      "        2.6750e-01, 2.0720e-02, 2.6570e-01, 6.4600e-03, 2.6770e-01, 1.1800e-02,\n",
      "        2.6560e-01, 1.9500e-03, 2.6800e-01, 1.2600e-03, 2.6550e-01, 6.5700e-03,\n",
      "        2.6810e-01, 2.1000e-04, 2.6540e-01, 7.0000e-03, 2.6880e-01, 5.0000e-03,\n",
      "        2.6530e-01, 1.8000e-03, 2.6900e-01, 1.4000e-03, 2.6510e-01, 1.6800e-03,\n",
      "        2.6970e-01, 1.4810e-02, 2.6470e-01, 1.4200e-03])\n",
      "tensor([0])\n",
      "tensor([2.6700e-01, 2.1900e-03, 2.6630e-01, 2.0000e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6620e-01, 1.6900e-03, 2.6730e-01, 1.1200e-03, 2.6610e-01, 1.5020e-02,\n",
      "        2.6750e-01, 2.0720e-02, 2.6600e-01, 1.8400e-03, 2.6770e-01, 1.1800e-02,\n",
      "        2.6570e-01, 6.4600e-03, 2.6800e-01, 1.2600e-03, 2.6560e-01, 1.9500e-03,\n",
      "        2.6810e-01, 2.1000e-04, 2.6550e-01, 6.5700e-03, 2.6880e-01, 5.0000e-03,\n",
      "        2.6540e-01, 7.0000e-03, 2.6900e-01, 1.4000e-03, 2.6530e-01, 1.8000e-03,\n",
      "        2.6970e-01, 1.4810e-02, 2.6510e-01, 1.6800e-03])\n",
      "tensor([0])\n",
      "tensor([2.6700e-01, 2.1900e-03, 2.6630e-01, 2.0000e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6620e-01, 1.6900e-03, 2.6730e-01, 1.1200e-03, 2.6610e-01, 1.5020e-02,\n",
      "        2.6750e-01, 2.0720e-02, 2.6600e-01, 1.8400e-03, 2.6770e-01, 1.0000e-02,\n",
      "        2.6570e-01, 8.2600e-03, 2.6800e-01, 1.2600e-03, 2.6550e-01, 6.5700e-03,\n",
      "        2.6810e-01, 2.1000e-04, 2.6540e-01, 7.0000e-03, 2.6850e-01, 1.8000e-03,\n",
      "        2.6510e-01, 1.6800e-03, 2.6880e-01, 5.0000e-03, 2.6470e-01, 1.4200e-03,\n",
      "        2.6900e-01, 1.4000e-03, 2.6440e-01, 1.6900e-03])\n",
      "tensor([0])\n",
      "tensor([2.6700e-01, 2.1900e-03, 2.6640e-01, 5.0000e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6630e-01, 2.0000e-03, 2.6750e-01, 1.9940e-02, 2.6620e-01, 1.6900e-03,\n",
      "        2.6760e-01, 1.9600e-03, 2.6610e-01, 1.5020e-02, 2.6770e-01, 1.0000e-02,\n",
      "        2.6600e-01, 1.8400e-03, 2.6790e-01, 1.8000e-03, 2.6570e-01, 1.0210e-02,\n",
      "        2.6800e-01, 1.2600e-03, 2.6550e-01, 6.5700e-03, 2.6810e-01, 2.1000e-04,\n",
      "        2.6540e-01, 7.0000e-03, 2.6880e-01, 5.0000e-03, 2.6510e-01, 1.6800e-03,\n",
      "        2.6900e-01, 1.4000e-03, 2.6470e-01, 1.4200e-03])\n",
      "tensor([0])\n",
      "tensor([2.6700e-01, 2.1900e-03, 2.6640e-01, 2.0000e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6620e-01, 1.6900e-03, 2.6750e-01, 1.9940e-02, 2.6610e-01, 1.5020e-02,\n",
      "        2.6760e-01, 1.9600e-03, 2.6600e-01, 1.8400e-03, 2.6770e-01, 1.0000e-02,\n",
      "        2.6570e-01, 1.0210e-02, 2.6790e-01, 1.8000e-03, 2.6550e-01, 6.5700e-03,\n",
      "        2.6800e-01, 1.2600e-03, 2.6540e-01, 7.0000e-03, 2.6810e-01, 2.1000e-04,\n",
      "        2.6510e-01, 1.6800e-03, 2.6880e-01, 5.0000e-03, 2.6470e-01, 1.4200e-03,\n",
      "        2.6900e-01, 1.4000e-03, 2.6440e-01, 1.6900e-03])\n",
      "tensor([0])\n",
      "tensor([2.6700e-01, 2.1900e-03, 2.6620e-01, 1.6900e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6610e-01, 1.5020e-02, 2.6750e-01, 1.9940e-02, 2.6600e-01, 1.8400e-03,\n",
      "        2.6760e-01, 1.9600e-03, 2.6570e-01, 1.0210e-02, 2.6770e-01, 1.0000e-02,\n",
      "        2.6550e-01, 6.5700e-03, 2.6800e-01, 1.2600e-03, 2.6540e-01, 7.0000e-03,\n",
      "        2.6810e-01, 2.1000e-04, 2.6510e-01, 1.6800e-03, 2.6880e-01, 5.0000e-03,\n",
      "        2.6470e-01, 1.4200e-03, 2.6900e-01, 1.4000e-03, 2.6440e-01, 1.6900e-03,\n",
      "        2.6970e-01, 1.4810e-02, 2.6410e-01, 2.8200e-03])\n",
      "tensor([0])\n",
      "tensor([2.6700e-01, 2.1900e-03, 2.6630e-01, 2.0000e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6620e-01, 1.6900e-03, 2.6750e-01, 1.9940e-02, 2.6610e-01, 1.5020e-02,\n",
      "        2.6760e-01, 1.9600e-03, 2.6600e-01, 1.8400e-03, 2.6770e-01, 1.0000e-02,\n",
      "        2.6590e-01, 2.2100e-03, 2.6800e-01, 1.2600e-03, 2.6570e-01, 1.0210e-02,\n",
      "        2.6820e-01, 1.8000e-03, 2.6550e-01, 6.5700e-03, 2.6870e-01, 2.1000e-04,\n",
      "        2.6540e-01, 7.0000e-03, 2.6880e-01, 5.0000e-03, 2.6510e-01, 1.6800e-03,\n",
      "        2.6900e-01, 1.4000e-03, 2.6470e-01, 1.4200e-03])\n",
      "tensor([0])\n",
      "tensor([2.6700e-01, 2.1900e-03, 2.6630e-01, 1.4140e-02, 2.6710e-01, 5.8400e-03,\n",
      "        2.6620e-01, 1.6900e-03, 2.6750e-01, 1.9940e-02, 2.6610e-01, 2.8800e-03,\n",
      "        2.6760e-01, 1.9600e-03, 2.6600e-01, 1.8400e-03, 2.6770e-01, 1.0000e-02,\n",
      "        2.6590e-01, 2.2100e-03, 2.6800e-01, 1.2600e-03, 2.6570e-01, 1.0210e-02,\n",
      "        2.6820e-01, 1.8000e-03, 2.6550e-01, 6.5700e-03, 2.6870e-01, 2.1000e-04,\n",
      "        2.6540e-01, 1.2500e-03, 2.6880e-01, 5.0000e-03, 2.6510e-01, 1.6800e-03,\n",
      "        2.6900e-01, 1.4000e-03, 2.6470e-01, 1.4200e-03])\n",
      "tensor([0])\n",
      "tensor([2.6700e-01, 2.1900e-03, 2.6640e-01, 7.0000e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6630e-01, 1.2140e-02, 2.6750e-01, 1.9940e-02, 2.6620e-01, 1.6900e-03,\n",
      "        2.6770e-01, 1.1960e-02, 2.6610e-01, 2.8800e-03, 2.6800e-01, 1.2600e-03,\n",
      "        2.6600e-01, 1.8400e-03, 2.6870e-01, 2.1000e-04, 2.6590e-01, 2.2100e-03,\n",
      "        2.6880e-01, 5.0000e-03, 2.6580e-01, 1.9500e-03, 2.6900e-01, 1.4000e-03,\n",
      "        2.6570e-01, 1.0120e-02, 2.6970e-01, 1.4810e-02, 2.6550e-01, 6.5700e-03,\n",
      "        2.6990e-01, 1.1000e-02, 2.6540e-01, 1.2500e-03])\n",
      "tensor([0])\n",
      "tensor([2.6700e-01, 2.1900e-03, 2.6660e-01, 5.0000e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6650e-01, 6.3400e-03, 2.6750e-01, 1.9940e-02, 2.6640e-01, 2.0000e-03,\n",
      "        2.6770e-01, 1.1960e-02, 2.6630e-01, 1.2140e-02, 2.6800e-01, 1.2600e-03,\n",
      "        2.6610e-01, 2.8800e-03, 2.6860e-01, 2.1000e-04, 2.6590e-01, 6.7400e-03,\n",
      "        2.6880e-01, 5.0000e-03, 2.6580e-01, 1.9500e-03, 2.6900e-01, 1.4000e-03,\n",
      "        2.6570e-01, 1.0440e-02, 2.6970e-01, 1.4810e-02, 2.6550e-01, 6.5700e-03,\n",
      "        2.6990e-01, 1.1000e-02, 2.6540e-01, 1.2500e-03])\n",
      "tensor([0])\n",
      "tensor([2.6700e-01, 2.1900e-03, 2.6660e-01, 5.0000e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6650e-01, 6.3400e-03, 2.6750e-01, 1.9940e-02, 2.6640e-01, 2.0000e-03,\n",
      "        2.6770e-01, 1.0000e-02, 2.6630e-01, 1.2140e-02, 2.6780e-01, 1.9600e-03,\n",
      "        2.6610e-01, 2.8800e-03, 2.6800e-01, 1.2600e-03, 2.6590e-01, 6.7400e-03,\n",
      "        2.6830e-01, 2.1000e-04, 2.6580e-01, 1.9500e-03, 2.6880e-01, 5.0000e-03,\n",
      "        2.6570e-01, 1.0440e-02, 2.6900e-01, 1.4000e-03, 2.6540e-01, 1.2500e-03,\n",
      "        2.6970e-01, 1.4810e-02, 2.6510e-01, 1.6800e-03])\n",
      "tensor([0])\n",
      "tensor([2.6700e-01, 2.1900e-03, 2.6660e-01, 5.0000e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6650e-01, 6.3400e-03, 2.6750e-01, 1.8740e-02, 2.6640e-01, 2.0000e-03,\n",
      "        2.6760e-01, 1.3400e-03, 2.6630e-01, 1.2140e-02, 2.6770e-01, 1.0000e-02,\n",
      "        2.6610e-01, 2.8800e-03, 2.6780e-01, 1.9600e-03, 2.6600e-01, 2.1300e-03,\n",
      "        2.6800e-01, 1.2600e-03, 2.6590e-01, 8.6900e-03, 2.6830e-01, 2.1000e-04,\n",
      "        2.6570e-01, 1.0440e-02, 2.6880e-01, 5.0000e-03, 2.6540e-01, 1.2500e-03,\n",
      "        2.6900e-01, 1.4000e-03, 2.6530e-01, 1.2100e-03])\n",
      "tensor([0])\n",
      "tensor([2.6700e-01, 2.1900e-03, 2.6660e-01, 5.0000e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6650e-01, 6.3400e-03, 2.6750e-01, 1.8740e-02, 2.6640e-01, 1.4140e-02,\n",
      "        2.6760e-01, 1.3400e-03, 2.6600e-01, 2.1300e-03, 2.6770e-01, 1.0000e-02,\n",
      "        2.6590e-01, 1.9500e-03, 2.6780e-01, 1.9600e-03, 2.6570e-01, 3.3300e-03,\n",
      "        2.6800e-01, 1.2600e-03, 2.6540e-01, 1.2500e-03, 2.6830e-01, 2.1000e-04,\n",
      "        2.6530e-01, 1.2100e-03, 2.6870e-01, 1.8000e-03, 2.6510e-01, 1.6800e-03,\n",
      "        2.6880e-01, 5.0000e-03, 2.6470e-01, 1.4200e-03])\n",
      "tensor([0])\n",
      "tensor([2.6700e-01, 2.1900e-03, 2.6660e-01, 5.0000e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6650e-01, 1.1390e-02, 2.6750e-01, 1.8740e-02, 2.6640e-01, 1.6890e-02,\n",
      "        2.6760e-01, 1.3400e-03, 2.6600e-01, 8.8700e-03, 2.6770e-01, 1.0000e-02,\n",
      "        2.6590e-01, 1.9500e-03, 2.6780e-01, 1.9600e-03, 2.6580e-01, 1.2800e-02,\n",
      "        2.6800e-01, 1.2600e-03, 2.6570e-01, 3.0100e-03, 2.6830e-01, 2.1000e-04,\n",
      "        2.6540e-01, 1.2500e-03, 2.6870e-01, 1.8000e-03, 2.6530e-01, 1.2100e-03,\n",
      "        2.6880e-01, 5.0000e-03, 2.6510e-01, 1.6800e-03])\n",
      "tensor([0])\n",
      "tensor([2.6700e-01, 2.1900e-03, 2.6660e-01, 5.0000e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6650e-01, 8.1100e-03, 2.6750e-01, 1.8740e-02, 2.6640e-01, 1.6890e-02,\n",
      "        2.6760e-01, 1.3400e-03, 2.6610e-01, 2.8900e-03, 2.6770e-01, 1.0000e-02,\n",
      "        2.6600e-01, 7.6800e-03, 2.6780e-01, 1.9600e-03, 2.6590e-01, 8.6300e-03,\n",
      "        2.6800e-01, 1.2600e-03, 2.6580e-01, 7.3200e-03, 2.6830e-01, 2.1000e-04,\n",
      "        2.6570e-01, 3.0100e-03, 2.6870e-01, 1.8000e-03, 2.6540e-01, 1.2500e-03,\n",
      "        2.6880e-01, 5.0000e-03, 2.6530e-01, 1.2100e-03])\n",
      "tensor([0])\n",
      "tensor([2.6700e-01, 4.1900e-03, 2.6670e-01, 2.8300e-03, 2.6710e-01, 5.8400e-03,\n",
      "        2.6660e-01, 5.0000e-03, 2.6750e-01, 1.8740e-02, 2.6650e-01, 4.9900e-03,\n",
      "        2.6760e-01, 1.3400e-03, 2.6640e-01, 1.4890e-02, 2.6770e-01, 1.0000e-02,\n",
      "        2.6610e-01, 2.8900e-03, 2.6780e-01, 1.9600e-03, 2.6600e-01, 1.4100e-03,\n",
      "        2.6800e-01, 1.2600e-03, 2.6590e-01, 8.6300e-03, 2.6810e-01, 1.8000e-03,\n",
      "        2.6580e-01, 7.3200e-03, 2.6830e-01, 2.1000e-04, 2.6570e-01, 3.0100e-03,\n",
      "        2.6880e-01, 5.0000e-03, 2.6540e-01, 1.2500e-03])\n",
      "tensor([0])\n",
      "tensor([0.2670, 0.0042, 0.2667, 0.0028, 0.2671, 0.0058, 0.2666, 0.0050, 0.2675,\n",
      "        0.0187, 0.2665, 0.0171, 0.2676, 0.0013, 0.2664, 0.0027, 0.2677, 0.0100,\n",
      "        0.2661, 0.0029, 0.2678, 0.0020, 0.2660, 0.0014, 0.2680, 0.0015, 0.2659,\n",
      "        0.0086, 0.2688, 0.0050, 0.2658, 0.0073, 0.2690, 0.0014, 0.2657, 0.0030,\n",
      "        0.2697, 0.0148, 0.2654, 0.0012])\n",
      "tensor([0])\n",
      "tensor([0.2670, 0.0062, 0.2667, 0.0028, 0.2671, 0.0058, 0.2666, 0.0050, 0.2675,\n",
      "        0.0187, 0.2665, 0.0196, 0.2676, 0.0013, 0.2664, 0.0027, 0.2677, 0.0100,\n",
      "        0.2662, 0.0046, 0.2678, 0.0020, 0.2661, 0.0029, 0.2680, 0.0015, 0.2660,\n",
      "        0.0069, 0.2688, 0.0050, 0.2659, 0.0086, 0.2690, 0.0014, 0.2657, 0.0030,\n",
      "        0.2697, 0.0148, 0.2654, 0.0012])\n",
      "tensor([0])\n",
      "tensor([0.2670, 0.0042, 0.2667, 0.0028, 0.2671, 0.0058, 0.2666, 0.0050, 0.2675,\n",
      "        0.0187, 0.2665, 0.0196, 0.2676, 0.0013, 0.2664, 0.0027, 0.2677, 0.0100,\n",
      "        0.2662, 0.0075, 0.2678, 0.0020, 0.2660, 0.0069, 0.2680, 0.0015, 0.2659,\n",
      "        0.0086, 0.2688, 0.0050, 0.2658, 0.0018, 0.2690, 0.0014, 0.2657, 0.0012,\n",
      "        0.2697, 0.0148, 0.2654, 0.0012])\n",
      "tensor([0])\n",
      "tensor([0.2671, 0.0058, 0.2667, 0.0028, 0.2676, 0.0013, 0.2666, 0.0050, 0.2677,\n",
      "        0.0100, 0.2665, 0.0196, 0.2678, 0.0020, 0.2664, 0.0027, 0.2680, 0.0015,\n",
      "        0.2662, 0.0075, 0.2687, 0.0018, 0.2660, 0.0046, 0.2688, 0.0050, 0.2659,\n",
      "        0.0086, 0.2690, 0.0014, 0.2658, 0.0018, 0.2697, 0.0148, 0.2657, 0.0012,\n",
      "        0.2699, 0.0110, 0.2654, 0.0012])\n",
      "tensor([0])\n",
      "tensor([0.2671, 0.0058, 0.2667, 0.0028, 0.2676, 0.0013, 0.2666, 0.0050, 0.2677,\n",
      "        0.0194, 0.2665, 0.0196, 0.2678, 0.0020, 0.2664, 0.0027, 0.2680, 0.0015,\n",
      "        0.2662, 0.0075, 0.2687, 0.0018, 0.2660, 0.0046, 0.2688, 0.0050, 0.2659,\n",
      "        0.0086, 0.2690, 0.0014, 0.2657, 0.0012, 0.2697, 0.0148, 0.2654, 0.0012,\n",
      "        0.2700, 0.0020, 0.2653, 0.0012])\n",
      "tensor([2])\n",
      "tensor([0.2671, 0.0058, 0.2667, 0.0150, 0.2677, 0.0205, 0.2665, 0.0075, 0.2678,\n",
      "        0.0020, 0.2664, 0.0027, 0.2680, 0.0015, 0.2662, 0.0075, 0.2687, 0.0018,\n",
      "        0.2660, 0.0066, 0.2688, 0.0050, 0.2659, 0.0067, 0.2690, 0.0014, 0.2657,\n",
      "        0.0012, 0.2697, 0.0148, 0.2654, 0.0012, 0.2700, 0.0020, 0.2653, 0.0012,\n",
      "        0.2705, 0.0110, 0.2651, 0.0017])\n",
      "tensor([2])\n",
      "tensor([0.2676, 0.0040, 0.2669, 0.0032, 0.2677, 0.0205, 0.2668, 0.0050, 0.2678,\n",
      "        0.0113, 0.2667, 0.0180, 0.2680, 0.0015, 0.2665, 0.0019, 0.2687, 0.0018,\n",
      "        0.2664, 0.0027, 0.2688, 0.0050, 0.2662, 0.0075, 0.2690, 0.0014, 0.2660,\n",
      "        0.0084, 0.2697, 0.0148, 0.2659, 0.0067, 0.2700, 0.0020, 0.2657, 0.0012,\n",
      "        0.2705, 0.0110, 0.2654, 0.0012])\n",
      "tensor([1])\n",
      "tensor([0.2676, 0.0040, 0.2669, 0.0032, 0.2677, 0.0205, 0.2668, 0.0050, 0.2678,\n",
      "        0.0094, 0.2667, 0.0206, 0.2680, 0.0013, 0.2665, 0.0019, 0.2682, 0.0019,\n",
      "        0.2662, 0.0029, 0.2687, 0.0018, 0.2660, 0.0084, 0.2688, 0.0050, 0.2657,\n",
      "        0.0012, 0.2690, 0.0014, 0.2654, 0.0012, 0.2697, 0.0150, 0.2653, 0.0012,\n",
      "        0.2700, 0.0020, 0.2651, 0.0017])\n",
      "tensor([0])\n",
      "tensor([0.2676, 0.0040, 0.2667, 0.0188, 0.2677, 0.0194, 0.2665, 0.0019, 0.2678,\n",
      "        0.0094, 0.2664, 0.0013, 0.2680, 0.0013, 0.2663, 0.0019, 0.2681, 0.0011,\n",
      "        0.2662, 0.0055, 0.2682, 0.0019, 0.2660, 0.0064, 0.2687, 0.0018, 0.2657,\n",
      "        0.0012, 0.2688, 0.0050, 0.2654, 0.0012, 0.2690, 0.0014, 0.2653, 0.0012,\n",
      "        0.2697, 0.0150, 0.2651, 0.0017])\n",
      "tensor([0])\n",
      "tensor([0.2676, 0.0040, 0.2667, 0.0188, 0.2677, 0.0194, 0.2665, 0.0019, 0.2678,\n",
      "        0.0094, 0.2664, 0.0013, 0.2680, 0.0013, 0.2663, 0.0019, 0.2681, 0.0011,\n",
      "        0.2662, 0.0029, 0.2682, 0.0019, 0.2660, 0.0046, 0.2687, 0.0018, 0.2657,\n",
      "        0.0012, 0.2688, 0.0050, 0.2654, 0.0012, 0.2690, 0.0014, 0.2653, 0.0012,\n",
      "        0.2697, 0.0150, 0.2652, 0.0018])\n",
      "tensor([0])\n",
      "tensor([0.2676, 0.0040, 0.2667, 0.0188, 0.2677, 0.0194, 0.2665, 0.0019, 0.2678,\n",
      "        0.0094, 0.2664, 0.0013, 0.2680, 0.0015, 0.2660, 0.0046, 0.2682, 0.0019,\n",
      "        0.2657, 0.0012, 0.2686, 0.0015, 0.2654, 0.0012, 0.2687, 0.0018, 0.2653,\n",
      "        0.0012, 0.2688, 0.0050, 0.2652, 0.0018, 0.2690, 0.0014, 0.2651, 0.0017,\n",
      "        0.2697, 0.0150, 0.2647, 0.0014])\n",
      "tensor([0])\n",
      "tensor([0.2676, 0.0040, 0.2667, 0.0066, 0.2677, 0.0194, 0.2665, 0.0019, 0.2678,\n",
      "        0.0094, 0.2664, 0.0013, 0.2680, 0.0015, 0.2663, 0.0121, 0.2681, 0.0019,\n",
      "        0.2662, 0.0019, 0.2686, 0.0015, 0.2660, 0.0046, 0.2687, 0.0018, 0.2659,\n",
      "        0.0018, 0.2688, 0.0050, 0.2657, 0.0026, 0.2690, 0.0014, 0.2654, 0.0012,\n",
      "        0.2697, 0.0148, 0.2653, 0.0012])\n",
      "tensor([0])\n",
      "tensor([0.2676, 0.0040, 0.2667, 0.0010, 0.2677, 0.0194, 0.2666, 0.0013, 0.2678,\n",
      "        0.0094, 0.2665, 0.0087, 0.2680, 0.0015, 0.2664, 0.0013, 0.2681, 0.0019,\n",
      "        0.2663, 0.0121, 0.2686, 0.0015, 0.2660, 0.0046, 0.2687, 0.0018, 0.2657,\n",
      "        0.0026, 0.2688, 0.0050, 0.2654, 0.0012, 0.2690, 0.0014, 0.2653, 0.0012,\n",
      "        0.2697, 0.0148, 0.2651, 0.0017])\n",
      "tensor([0])\n",
      "tensor([0.2675, 0.0013, 0.2667, 0.0010, 0.2676, 0.0060, 0.2665, 0.0019, 0.2677,\n",
      "        0.0194, 0.2664, 0.0013, 0.2678, 0.0094, 0.2663, 0.0121, 0.2680, 0.0015,\n",
      "        0.2661, 0.0019, 0.2681, 0.0019, 0.2660, 0.0046, 0.2686, 0.0015, 0.2659,\n",
      "        0.0018, 0.2687, 0.0018, 0.2657, 0.0026, 0.2688, 0.0050, 0.2654, 0.0012,\n",
      "        0.2690, 0.0014, 0.2653, 0.0012])\n",
      "tensor([0])\n",
      "tensor([0.2675, 0.0013, 0.2667, 0.0010, 0.2676, 0.0060, 0.2666, 0.0006, 0.2677,\n",
      "        0.0194, 0.2665, 0.0113, 0.2678, 0.0094, 0.2664, 0.0013, 0.2680, 0.0015,\n",
      "        0.2663, 0.0121, 0.2681, 0.0019, 0.2661, 0.0019, 0.2683, 0.0018, 0.2660,\n",
      "        0.0077, 0.2686, 0.0015, 0.2657, 0.0026, 0.2688, 0.0050, 0.2654, 0.0012,\n",
      "        0.2690, 0.0014, 0.2653, 0.0012])\n",
      "tensor([0])\n",
      "tensor([0.2674, 0.0030, 0.2667, 0.0010, 0.2675, 0.0033, 0.2665, 0.0069, 0.2677,\n",
      "        0.0194, 0.2663, 0.0136, 0.2678, 0.0094, 0.2661, 0.0019, 0.2680, 0.0015,\n",
      "        0.2660, 0.0077, 0.2681, 0.0019, 0.2657, 0.0026, 0.2683, 0.0018, 0.2654,\n",
      "        0.0012, 0.2686, 0.0015, 0.2653, 0.0012, 0.2688, 0.0050, 0.2651, 0.0017,\n",
      "        0.2690, 0.0014, 0.2647, 0.0014])\n",
      "tensor([2])\n",
      "tensor([0.2674, 0.0020, 0.2667, 0.0010, 0.2675, 0.0013, 0.2665, 0.0113, 0.2676,\n",
      "        0.0051, 0.2663, 0.0136, 0.2677, 0.0194, 0.2661, 0.0019, 0.2678, 0.0094,\n",
      "        0.2660, 0.0044, 0.2680, 0.0034, 0.2657, 0.0044, 0.2683, 0.0018, 0.2654,\n",
      "        0.0012, 0.2686, 0.0015, 0.2653, 0.0012, 0.2688, 0.0050, 0.2651, 0.0017,\n",
      "        0.2690, 0.0014, 0.2647, 0.0014])\n",
      "tensor([0])\n",
      "tensor([2.6750e-01, 1.2700e-03, 2.6670e-01, 9.9000e-04, 2.6760e-01, 5.0700e-03,\n",
      "        2.6660e-01, 6.5000e-04, 2.6770e-01, 1.9360e-02, 2.6650e-01, 9.1200e-03,\n",
      "        2.6780e-01, 9.3600e-03, 2.6640e-01, 1.2140e-02, 2.6800e-01, 3.4200e-03,\n",
      "        2.6630e-01, 1.4100e-03, 2.6830e-01, 1.8000e-03, 2.6620e-01, 7.4600e-03,\n",
      "        2.6860e-01, 1.4800e-03, 2.6610e-01, 1.9300e-03, 2.6880e-01, 5.0000e-03,\n",
      "        2.6600e-01, 4.4400e-03, 2.6900e-01, 1.4000e-03, 2.6570e-01, 4.4500e-03,\n",
      "        2.6910e-01, 2.1000e-04, 2.6540e-01, 1.2500e-03])\n",
      "tensor([0])\n",
      "tensor([0.2673, 0.0027, 0.2667, 0.0010, 0.2674, 0.0032, 0.2665, 0.0069, 0.2675,\n",
      "        0.0033, 0.2664, 0.0121, 0.2677, 0.0194, 0.2662, 0.0075, 0.2678, 0.0094,\n",
      "        0.2661, 0.0019, 0.2680, 0.0034, 0.2660, 0.0044, 0.2683, 0.0018, 0.2657,\n",
      "        0.0044, 0.2686, 0.0015, 0.2654, 0.0012, 0.2688, 0.0050, 0.2653, 0.0012,\n",
      "        0.2690, 0.0014, 0.2651, 0.0017])\n",
      "tensor([0])\n",
      "tensor([0.2673, 0.0047, 0.2667, 0.0010, 0.2675, 0.0013, 0.2665, 0.0069, 0.2677,\n",
      "        0.0194, 0.2664, 0.0121, 0.2678, 0.0094, 0.2662, 0.0075, 0.2679, 0.0019,\n",
      "        0.2660, 0.0064, 0.2680, 0.0015, 0.2659, 0.0031, 0.2683, 0.0018, 0.2657,\n",
      "        0.0044, 0.2686, 0.0015, 0.2654, 0.0012, 0.2688, 0.0050, 0.2653, 0.0012,\n",
      "        0.2690, 0.0014, 0.2651, 0.0017])\n",
      "tensor([0])\n",
      "tensor([2.6730e-01, 4.6600e-03, 2.6670e-01, 9.9000e-04, 2.6750e-01, 1.2700e-03,\n",
      "        2.6660e-01, 6.6000e-04, 2.6770e-01, 1.9360e-02, 2.6650e-01, 6.9200e-03,\n",
      "        2.6780e-01, 9.3600e-03, 2.6640e-01, 1.2140e-02, 2.6800e-01, 3.4300e-03,\n",
      "        2.6620e-01, 7.4600e-03, 2.6830e-01, 1.8000e-03, 2.6610e-01, 1.9400e-03,\n",
      "        2.6860e-01, 1.4800e-03, 2.6600e-01, 5.7000e-03, 2.6880e-01, 5.0000e-03,\n",
      "        2.6590e-01, 6.6300e-03, 2.6900e-01, 1.4000e-03, 2.6570e-01, 4.4500e-03,\n",
      "        2.6910e-01, 2.1000e-04, 2.6540e-01, 1.2500e-03])\n",
      "tensor([0])\n",
      "tensor([2.6730e-01, 4.6600e-03, 2.6670e-01, 9.9000e-04, 2.6750e-01, 1.2700e-03,\n",
      "        2.6660e-01, 6.8000e-04, 2.6770e-01, 1.9360e-02, 2.6650e-01, 6.9200e-03,\n",
      "        2.6780e-01, 9.3600e-03, 2.6640e-01, 1.2140e-02, 2.6800e-01, 3.4300e-03,\n",
      "        2.6620e-01, 7.4600e-03, 2.6830e-01, 1.8000e-03, 2.6610e-01, 1.9400e-03,\n",
      "        2.6860e-01, 1.4800e-03, 2.6600e-01, 5.7000e-03, 2.6880e-01, 5.0000e-03,\n",
      "        2.6570e-01, 4.4500e-03, 2.6900e-01, 1.4000e-03, 2.6540e-01, 1.2500e-03,\n",
      "        2.6910e-01, 2.1000e-04, 2.6530e-01, 1.2100e-03])\n",
      "tensor([0])\n",
      "tensor([2.6730e-01, 4.6600e-03, 2.6670e-01, 9.9000e-04, 2.6750e-01, 1.2700e-03,\n",
      "        2.6660e-01, 8.1000e-04, 2.6770e-01, 1.9360e-02, 2.6650e-01, 1.0080e-02,\n",
      "        2.6780e-01, 9.3600e-03, 2.6620e-01, 7.4600e-03, 2.6800e-01, 3.4300e-03,\n",
      "        2.6610e-01, 1.9400e-03, 2.6830e-01, 1.8000e-03, 2.6600e-01, 1.4550e-02,\n",
      "        2.6860e-01, 1.4800e-03, 2.6570e-01, 4.4500e-03, 2.6880e-01, 5.0000e-03,\n",
      "        2.6540e-01, 1.2500e-03, 2.6900e-01, 1.4000e-03, 2.6530e-01, 1.2100e-03,\n",
      "        2.6910e-01, 2.1000e-04, 2.6510e-01, 1.6800e-03])\n",
      "tensor([2])\n",
      "tensor([0.2673, 0.0027, 0.2667, 0.0013, 0.2675, 0.0013, 0.2665, 0.0101, 0.2676,\n",
      "        0.0042, 0.2664, 0.0121, 0.2677, 0.0194, 0.2662, 0.0075, 0.2678, 0.0094,\n",
      "        0.2661, 0.0019, 0.2680, 0.0034, 0.2660, 0.0084, 0.2683, 0.0018, 0.2657,\n",
      "        0.0044, 0.2686, 0.0015, 0.2654, 0.0012, 0.2688, 0.0050, 0.2653, 0.0012,\n",
      "        0.2690, 0.0014, 0.2651, 0.0017])\n",
      "tensor([2])\n",
      "tensor([2.6730e-01, 2.6600e-03, 2.6670e-01, 1.3200e-03, 2.6750e-01, 1.2700e-03,\n",
      "        2.6660e-01, 7.3000e-04, 2.6770e-01, 1.9360e-02, 2.6650e-01, 1.0080e-02,\n",
      "        2.6780e-01, 9.3600e-03, 2.6640e-01, 1.2140e-02, 2.6800e-01, 3.4300e-03,\n",
      "        2.6620e-01, 7.4600e-03, 2.6830e-01, 1.8000e-03, 2.6610e-01, 1.9400e-03,\n",
      "        2.6860e-01, 1.4800e-03, 2.6600e-01, 1.5150e-02, 2.6880e-01, 5.0000e-03,\n",
      "        2.6570e-01, 4.4500e-03, 2.6900e-01, 1.4000e-03, 2.6540e-01, 1.2500e-03,\n",
      "        2.6910e-01, 2.1000e-04, 2.6530e-01, 1.2100e-03])\n",
      "tensor([2])\n",
      "tensor([0.2673, 0.0027, 0.2667, 0.0013, 0.2675, 0.0013, 0.2665, 0.0101, 0.2676,\n",
      "        0.0044, 0.2663, 0.0121, 0.2677, 0.0194, 0.2662, 0.0075, 0.2678, 0.0094,\n",
      "        0.2661, 0.0019, 0.2680, 0.0034, 0.2660, 0.0152, 0.2683, 0.0018, 0.2657,\n",
      "        0.0044, 0.2686, 0.0015, 0.2654, 0.0012, 0.2688, 0.0050, 0.2653, 0.0012,\n",
      "        0.2690, 0.0014, 0.2651, 0.0017])\n",
      "tensor([2])\n",
      "tensor([0.2673, 0.0027, 0.2667, 0.0081, 0.2675, 0.0013, 0.2665, 0.0047, 0.2676,\n",
      "        0.0044, 0.2664, 0.0121, 0.2677, 0.0194, 0.2662, 0.0075, 0.2678, 0.0094,\n",
      "        0.2661, 0.0019, 0.2680, 0.0034, 0.2660, 0.0152, 0.2683, 0.0018, 0.2657,\n",
      "        0.0044, 0.2686, 0.0015, 0.2654, 0.0012, 0.2688, 0.0050, 0.2653, 0.0012,\n",
      "        0.2690, 0.0014, 0.2651, 0.0017])\n",
      "tensor([2])\n",
      "tensor([2.6730e-01, 2.6600e-03, 2.6670e-01, 1.0100e-02, 2.6750e-01, 1.2700e-03,\n",
      "        2.6660e-01, 1.7200e-03, 2.6760e-01, 4.3900e-03, 2.6650e-01, 2.7500e-03,\n",
      "        2.6770e-01, 1.9360e-02, 2.6640e-01, 1.2140e-02, 2.6780e-01, 9.3600e-03,\n",
      "        2.6620e-01, 7.4600e-03, 2.6800e-01, 3.4300e-03, 2.6610e-01, 1.9400e-03,\n",
      "        2.6860e-01, 1.4800e-03, 2.6600e-01, 8.4100e-03, 2.6880e-01, 5.0000e-03,\n",
      "        2.6570e-01, 4.4500e-03, 2.6900e-01, 1.4000e-03, 2.6540e-01, 1.2500e-03,\n",
      "        2.6910e-01, 2.1000e-04, 2.6530e-01, 1.2100e-03])\n",
      "tensor([2])\n",
      "tensor([0.2673, 0.0027, 0.2668, 0.0043, 0.2675, 0.0013, 0.2667, 0.0078, 0.2676,\n",
      "        0.0044, 0.2666, 0.0017, 0.2677, 0.0194, 0.2665, 0.0027, 0.2678, 0.0094,\n",
      "        0.2664, 0.0121, 0.2680, 0.0034, 0.2662, 0.0075, 0.2684, 0.0018, 0.2661,\n",
      "        0.0037, 0.2686, 0.0015, 0.2660, 0.0153, 0.2688, 0.0050, 0.2657, 0.0026,\n",
      "        0.2690, 0.0014, 0.2654, 0.0012])\n",
      "tensor([2])\n",
      "tensor([2.6730e-01, 2.6600e-03, 2.6680e-01, 4.3200e-03, 2.6750e-01, 1.2700e-03,\n",
      "        2.6670e-01, 7.7700e-03, 2.6760e-01, 4.3900e-03, 2.6650e-01, 2.7500e-03,\n",
      "        2.6770e-01, 1.9360e-02, 2.6640e-01, 1.2140e-02, 2.6780e-01, 9.3600e-03,\n",
      "        2.6620e-01, 5.8500e-03, 2.6800e-01, 1.4800e-03, 2.6610e-01, 1.9400e-03,\n",
      "        2.6810e-01, 2.2700e-03, 2.6600e-01, 1.5310e-02, 2.6840e-01, 1.8000e-03,\n",
      "        2.6570e-01, 4.4500e-03, 2.6850e-01, 2.1000e-04, 2.6540e-01, 1.2500e-03,\n",
      "        2.6860e-01, 1.4800e-03, 2.6530e-01, 1.2100e-03])\n",
      "tensor([2])\n",
      "tensor([2.6730e-01, 1.4600e-03, 2.6680e-01, 1.8460e-02, 2.6750e-01, 1.2700e-03,\n",
      "        2.6670e-01, 7.7700e-03, 2.6760e-01, 4.3900e-03, 2.6650e-01, 2.7500e-03,\n",
      "        2.6770e-01, 1.9360e-02, 2.6620e-01, 8.1100e-03, 2.6780e-01, 9.3600e-03,\n",
      "        2.6600e-01, 1.1020e-02, 2.6800e-01, 1.4800e-03, 2.6570e-01, 4.4500e-03,\n",
      "        2.6810e-01, 2.2700e-03, 2.6540e-01, 1.2500e-03, 2.6840e-01, 1.8000e-03,\n",
      "        2.6530e-01, 1.2100e-03, 2.6850e-01, 2.1000e-04, 2.6510e-01, 1.6800e-03,\n",
      "        2.6860e-01, 1.4800e-03, 2.6480e-01, 1.1300e-02])\n",
      "tensor([2])\n",
      "tensor([2.6730e-01, 1.4600e-03, 2.6690e-01, 3.2200e-03, 2.6750e-01, 1.2700e-03,\n",
      "        2.6680e-01, 1.6460e-02, 2.6760e-01, 4.3900e-03, 2.6670e-01, 7.7700e-03,\n",
      "        2.6770e-01, 1.9360e-02, 2.6650e-01, 2.7500e-03, 2.6780e-01, 9.3600e-03,\n",
      "        2.6640e-01, 1.7100e-03, 2.6800e-01, 1.4800e-03, 2.6620e-01, 8.1100e-03,\n",
      "        2.6810e-01, 2.2700e-03, 2.6610e-01, 1.8000e-03, 2.6840e-01, 1.8000e-03,\n",
      "        2.6600e-01, 8.3100e-03, 2.6850e-01, 2.1000e-04, 2.6570e-01, 2.6500e-03,\n",
      "        2.6860e-01, 1.4800e-03, 2.6540e-01, 1.2500e-03])\n",
      "tensor([2])\n",
      "tensor([2.6730e-01, 1.4600e-03, 2.6690e-01, 1.5360e-02, 2.6750e-01, 1.2700e-03,\n",
      "        2.6680e-01, 4.3200e-03, 2.6760e-01, 4.3900e-03, 2.6670e-01, 7.7700e-03,\n",
      "        2.6770e-01, 1.9360e-02, 2.6650e-01, 8.5000e-03, 2.6780e-01, 9.3600e-03,\n",
      "        2.6640e-01, 1.7100e-03, 2.6800e-01, 1.4800e-03, 2.6630e-01, 6.5500e-03,\n",
      "        2.6810e-01, 2.2700e-03, 2.6620e-01, 2.3600e-03, 2.6820e-01, 2.1000e-04,\n",
      "        2.6610e-01, 1.8000e-03, 2.6840e-01, 1.8000e-03, 2.6600e-01, 1.4100e-03,\n",
      "        2.6860e-01, 1.4800e-03, 2.6570e-01, 2.6500e-03])\n",
      "tensor([2])\n",
      "tensor([0.2673, 0.0015, 0.2669, 0.0157, 0.2675, 0.0013, 0.2668, 0.0040, 0.2676,\n",
      "        0.0044, 0.2667, 0.0078, 0.2677, 0.0194, 0.2665, 0.0085, 0.2678, 0.0094,\n",
      "        0.2663, 0.0086, 0.2680, 0.0015, 0.2661, 0.0018, 0.2682, 0.0023, 0.2660,\n",
      "        0.0014, 0.2684, 0.0018, 0.2657, 0.0026, 0.2686, 0.0015, 0.2654, 0.0012,\n",
      "        0.2688, 0.0050, 0.2653, 0.0012])\n",
      "tensor([0])\n",
      "tensor([0.2675, 0.0013, 0.2669, 0.0145, 0.2676, 0.0044, 0.2668, 0.0040, 0.2677,\n",
      "        0.0194, 0.2667, 0.0078, 0.2678, 0.0094, 0.2665, 0.0102, 0.2680, 0.0015,\n",
      "        0.2663, 0.0155, 0.2682, 0.0021, 0.2660, 0.0014, 0.2684, 0.0018, 0.2659,\n",
      "        0.0018, 0.2686, 0.0015, 0.2657, 0.0026, 0.2688, 0.0050, 0.2654, 0.0012,\n",
      "        0.2690, 0.0016, 0.2653, 0.0012])\n",
      "tensor([0])\n",
      "tensor([0.2675, 0.0013, 0.2670, 0.0020, 0.2676, 0.0032, 0.2669, 0.0125, 0.2677,\n",
      "        0.0194, 0.2668, 0.0040, 0.2678, 0.0094, 0.2667, 0.0078, 0.2680, 0.0015,\n",
      "        0.2665, 0.0102, 0.2682, 0.0021, 0.2663, 0.0155, 0.2684, 0.0018, 0.2660,\n",
      "        0.0014, 0.2686, 0.0015, 0.2657, 0.0026, 0.2688, 0.0050, 0.2654, 0.0012,\n",
      "        0.2690, 0.0016, 0.2653, 0.0012])\n",
      "tensor([0])\n",
      "tensor([2.6750e-01, 3.2700e-03, 2.6710e-01, 1.0000e-03, 2.6770e-01, 1.9360e-02,\n",
      "        2.6690e-01, 3.3000e-04, 2.6780e-01, 9.3600e-03, 2.6680e-01, 1.6130e-02,\n",
      "        2.6800e-01, 1.4800e-03, 2.6670e-01, 7.7700e-03, 2.6820e-01, 2.0500e-03,\n",
      "        2.6650e-01, 8.5000e-03, 2.6840e-01, 1.8000e-03, 2.6630e-01, 1.5510e-02,\n",
      "        2.6860e-01, 1.4800e-03, 2.6600e-01, 1.4100e-03, 2.6870e-01, 2.1000e-04,\n",
      "        2.6580e-01, 1.8000e-03, 2.6880e-01, 5.0000e-03, 2.6570e-01, 2.6500e-03,\n",
      "        2.6900e-01, 1.4000e-03, 2.6540e-01, 1.2500e-03])\n",
      "tensor([0])\n",
      "tensor([0.2675, 0.0033, 0.2672, 0.0023, 0.2677, 0.0194, 0.2671, 0.0010, 0.2678,\n",
      "        0.0094, 0.2668, 0.0121, 0.2682, 0.0031, 0.2667, 0.0095, 0.2684, 0.0020,\n",
      "        0.2665, 0.0058, 0.2686, 0.0015, 0.2663, 0.0155, 0.2688, 0.0050, 0.2660,\n",
      "        0.0014, 0.2690, 0.0014, 0.2658, 0.0018, 0.2700, 0.0020, 0.2657, 0.0026,\n",
      "        0.2705, 0.0110, 0.2654, 0.0012])\n",
      "tensor([0])\n",
      "tensor([0.2675, 0.0033, 0.2672, 0.0023, 0.2677, 0.0194, 0.2670, 0.0121, 0.2678,\n",
      "        0.0094, 0.2667, 0.0152, 0.2682, 0.0035, 0.2665, 0.0051, 0.2684, 0.0020,\n",
      "        0.2663, 0.0086, 0.2686, 0.0015, 0.2660, 0.0014, 0.2688, 0.0050, 0.2658,\n",
      "        0.0018, 0.2690, 0.0014, 0.2657, 0.0026, 0.2700, 0.0020, 0.2654, 0.0012,\n",
      "        0.2705, 0.0110, 0.2653, 0.0012])\n",
      "tensor([0])\n",
      "tensor([0.2675, 0.0013, 0.2672, 0.0023, 0.2677, 0.0194, 0.2671, 0.0029, 0.2678,\n",
      "        0.0094, 0.2670, 0.0150, 0.2682, 0.0015, 0.2667, 0.0107, 0.2683, 0.0023,\n",
      "        0.2665, 0.0122, 0.2684, 0.0020, 0.2664, 0.0022, 0.2686, 0.0015, 0.2663,\n",
      "        0.0012, 0.2688, 0.0050, 0.2660, 0.0014, 0.2690, 0.0014, 0.2658, 0.0018,\n",
      "        0.2700, 0.0020, 0.2657, 0.0026])\n",
      "tensor([0])\n",
      "tensor([2.6750e-01, 1.2700e-03, 2.6720e-01, 2.3300e-03, 2.6770e-01, 1.9360e-02,\n",
      "        2.6710e-01, 2.9400e-03, 2.6780e-01, 9.3600e-03, 2.6700e-01, 1.5010e-02,\n",
      "        2.6820e-01, 1.4600e-03, 2.6670e-01, 1.0740e-02, 2.6830e-01, 2.2900e-03,\n",
      "        2.6650e-01, 5.1000e-03, 2.6840e-01, 2.1000e-04, 2.6640e-01, 4.0100e-03,\n",
      "        2.6850e-01, 1.8000e-03, 2.6630e-01, 1.2000e-03, 2.6860e-01, 1.4800e-03,\n",
      "        2.6600e-01, 1.4100e-03, 2.6880e-01, 5.0000e-03, 2.6570e-01, 2.6500e-03,\n",
      "        2.6900e-01, 1.4000e-03, 2.6540e-01, 1.2500e-03])\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "tmp_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=1, shuffle=False)\n",
    "cnt = 0\n",
    "for x, y in tmp_loader:\n",
    "    cnt+=1\n",
    "    x,y = x.to(dtype = torch.float), y.to(dtype=torch.int64)\n",
    "    print(x[0][0][0])\n",
    "    print(y)\n",
    "    if cnt==100:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27000001072883606\n",
      "0.12479999661445618\n"
     ]
    }
   ],
   "source": [
    "# 找寻bid1最大值和ask1最小值\n",
    "tmp_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=64, shuffle=False)\n",
    "ask1List = []\n",
    "bid1List = []\n",
    "cnt = 0\n",
    "for x, y in tmp_loader:\n",
    "    cnt+=1\n",
    "    x,y = x.to(device, dtype = torch.float), y.to(device, dtype=torch.int64)\n",
    "    ask1List.append(x[0][0][0][0].item())\n",
    "    bid1List.append(x[0][0][0][2].item())\n",
    "    if cnt==300:\n",
    "        break\n",
    "print(max(bid1List))\n",
    "print(min(ask1List))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e63b02e998af1dcb7a74034bbdbbd78c02ec113abb29c701110c66208fedae2"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
