{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Model Tuning\n",
    "\n",
    "In this notebook, we will take the folds generated by the OU class in the previous notebook  and try to find the best set of parameters for our SVM to perform binary classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pickle\n",
    "\n",
    "import OU\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = np.load(save_dir + \"/info.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to recompile the fold dictionary into one large dataframe so that sci-kit learn's GridSearchCV class can search for the optimal parameters efficiently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "splits = []\n",
    "multi_cv_df = pd.DataFrame()\n",
    "multi_cv_labels = pd.Series()\n",
    "\n",
    "for i in range(len(info)):\n",
    "    train = info[i]['train']['df_scale'].copy()\n",
    "    train_labels = info[i]['train']['labels'].copy()\n",
    "    \n",
    "    test = info[i]['test']['df_scale'].copy()\n",
    "    test_labels = info[i]['test']['labels'].copy()\n",
    "    \n",
    "    train_len = train.shape[0]\n",
    "    test_len = test.shape[0]\n",
    "    \n",
    "    # Append rows to dataframe\n",
    "    multi_cv_df = multi_cv_df.append(train, ignore_index=True)\n",
    "    multi_cv_labels = multi_cv_labels.append(train_labels, ignore_index=True)\n",
    "    \n",
    "    # Append labels to a dataframe\n",
    "    multi_cv_df = multi_cv_df.append(test, ignore_index=True)\n",
    "    multi_cv_labels = multi_cv_labels.append(test_labels, ignore_index=True)\n",
    "    \n",
    "    # Append the indices of the folds to a list\n",
    "    splits.append((multi_cv_df.iloc[-train_len-test_len:-test_len].index, multi_cv_df.iloc[-test_len:].index))\n",
    "    \n",
    "    # Quality Assurance\n",
    "    assert(np.array_equal(multi_cv_df.loc[splits[i][0]].values, train.values))\n",
    "    assert(np.array_equal(multi_cv_labels.loc[splits[i][0]].values, train_labels.values))\n",
    "    assert(np.array_equal(multi_cv_df.loc[splits[i][1]], test.values))\n",
    "    assert(np.array_equal(multi_cv_labels.loc[splits[i][1]], test_labels))\n",
    "    \n",
    "splits = np.array(splits)\n",
    "\n",
    "np.save(save_dir + 'splits.npy', splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save off data\n",
    "multi_cv_df.to_csv(save_dir + 'df.csv')\n",
    "multi_cv_labels.to_csv(save_dir + 'labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridsearch\n",
    "\n",
    "We want to find the optimal hyperparameters for our SVM by exploring all combinations of possible hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{ 'kernel': ['rbf'],\n",
    "            'C': [0.1,1,10,100], \n",
    "            'gamma': [1, 0.1, 0.001, 0.0001], \n",
    "            'cache_size': [2000], \n",
    "            'class_weight': [{0: 0.5, 1: 0.5}, {0: 0.6, 1: 0.4}, \n",
    "                             {0: 0.7, 1: 0.3}, {0: 0.8, 1: 0.2}]\n",
    "          }, \n",
    "          { 'kernel': ['poly'], \n",
    "            'C': [0.1, 1,10,100,], \n",
    "            'gamma': [1, 0.1, 0.001, 0.0001],\n",
    "            'degree': [3, 5],\n",
    "            'cache_size': [2000],\n",
    "            'class_weight': [{0: 0.5, 1: 0.5}, \n",
    "                             {0: 0.6, 1: 0.4}, {0: 0.7, 1: 0.3}]\n",
    "          }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2005 folds for each of 160 candidates, totalling 320800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:   44.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1768 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2418 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3168 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4018 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4968 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6018 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7168 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8418 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 9768 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 11218 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 12768 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 14418 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 16168 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 18018 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 19968 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 22018 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 24168 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done 26418 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=-1)]: Done 28768 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=-1)]: Done 31218 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=-1)]: Done 33768 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=-1)]: Done 36418 tasks      | elapsed: 19.7min\n",
      "[Parallel(n_jobs=-1)]: Done 39168 tasks      | elapsed: 21.2min\n",
      "[Parallel(n_jobs=-1)]: Done 42018 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=-1)]: Done 44968 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=-1)]: Done 48018 tasks      | elapsed: 26.2min\n",
      "[Parallel(n_jobs=-1)]: Done 51168 tasks      | elapsed: 27.8min\n",
      "[Parallel(n_jobs=-1)]: Done 54418 tasks      | elapsed: 29.4min\n",
      "[Parallel(n_jobs=-1)]: Done 57768 tasks      | elapsed: 31.0min\n",
      "[Parallel(n_jobs=-1)]: Done 61218 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=-1)]: Done 64768 tasks      | elapsed: 34.2min\n",
      "[Parallel(n_jobs=-1)]: Done 68418 tasks      | elapsed: 36.6min\n",
      "[Parallel(n_jobs=-1)]: Done 72168 tasks      | elapsed: 38.7min\n",
      "[Parallel(n_jobs=-1)]: Done 76018 tasks      | elapsed: 41.0min\n",
      "[Parallel(n_jobs=-1)]: Done 79968 tasks      | elapsed: 43.1min\n",
      "[Parallel(n_jobs=-1)]: Done 84018 tasks      | elapsed: 45.3min\n",
      "[Parallel(n_jobs=-1)]: Done 88168 tasks      | elapsed: 47.4min\n",
      "[Parallel(n_jobs=-1)]: Done 92418 tasks      | elapsed: 49.5min\n",
      "[Parallel(n_jobs=-1)]: Done 96768 tasks      | elapsed: 51.4min\n",
      "[Parallel(n_jobs=-1)]: Done 101218 tasks      | elapsed: 54.4min\n",
      "[Parallel(n_jobs=-1)]: Done 105768 tasks      | elapsed: 57.5min\n",
      "[Parallel(n_jobs=-1)]: Done 110418 tasks      | elapsed: 60.4min\n",
      "[Parallel(n_jobs=-1)]: Done 115168 tasks      | elapsed: 63.7min\n",
      "[Parallel(n_jobs=-1)]: Done 120018 tasks      | elapsed: 66.2min\n",
      "[Parallel(n_jobs=-1)]: Done 124968 tasks      | elapsed: 69.4min\n",
      "[Parallel(n_jobs=-1)]: Done 130018 tasks      | elapsed: 71.7min\n",
      "[Parallel(n_jobs=-1)]: Done 135168 tasks      | elapsed: 73.6min\n",
      "[Parallel(n_jobs=-1)]: Done 140418 tasks      | elapsed: 76.1min\n",
      "[Parallel(n_jobs=-1)]: Done 145768 tasks      | elapsed: 78.2min\n",
      "[Parallel(n_jobs=-1)]: Done 151218 tasks      | elapsed: 80.1min\n",
      "[Parallel(n_jobs=-1)]: Done 156768 tasks      | elapsed: 82.8min\n",
      "[Parallel(n_jobs=-1)]: Done 162418 tasks      | elapsed: 84.8min\n",
      "[Parallel(n_jobs=-1)]: Done 168168 tasks      | elapsed: 86.8min\n",
      "[Parallel(n_jobs=-1)]: Done 174018 tasks      | elapsed: 89.3min\n",
      "[Parallel(n_jobs=-1)]: Done 179968 tasks      | elapsed: 91.9min\n",
      "[Parallel(n_jobs=-1)]: Done 186018 tasks      | elapsed: 96.8min\n",
      "[Parallel(n_jobs=-1)]: Done 192168 tasks      | elapsed: 99.4min\n",
      "[Parallel(n_jobs=-1)]: Done 198418 tasks      | elapsed: 102.1min\n",
      "[Parallel(n_jobs=-1)]: Done 204768 tasks      | elapsed: 109.0min\n",
      "[Parallel(n_jobs=-1)]: Done 211218 tasks      | elapsed: 111.6min\n",
      "[Parallel(n_jobs=-1)]: Done 217768 tasks      | elapsed: 117.1min\n",
      "[Parallel(n_jobs=-1)]: Done 224418 tasks      | elapsed: 121.0min\n",
      "[Parallel(n_jobs=-1)]: Done 231168 tasks      | elapsed: 126.1min\n",
      "[Parallel(n_jobs=-1)]: Done 238018 tasks      | elapsed: 145.9min\n",
      "[Parallel(n_jobs=-1)]: Done 244968 tasks      | elapsed: 151.8min\n",
      "[Parallel(n_jobs=-1)]: Done 252018 tasks      | elapsed: 194.3min\n",
      "[Parallel(n_jobs=-1)]: Done 259168 tasks      | elapsed: 200.2min\n",
      "[Parallel(n_jobs=-1)]: Done 266418 tasks      | elapsed: 256.8min\n",
      "[Parallel(n_jobs=-1)]: Done 273768 tasks      | elapsed: 281.4min\n",
      "[Parallel(n_jobs=-1)]: Done 281218 tasks      | elapsed: 305.2min\n",
      "[Parallel(n_jobs=-1)]: Done 288768 tasks      | elapsed: 336.6min\n",
      "[Parallel(n_jobs=-1)]: Done 296418 tasks      | elapsed: 385.6min\n",
      "[Parallel(n_jobs=-1)]: Done 304168 tasks      | elapsed: 494.6min\n",
      "[Parallel(n_jobs=-1)]: Done 312018 tasks      | elapsed: 556.0min\n",
      "[Parallel(n_jobs=-1)]: Done 319968 tasks      | elapsed: 727.1min\n",
      "[Parallel(n_jobs=-1)]: Done 320800 out of 320800 | elapsed: 727.4min finished\n",
      "/home/alex/.conda/envs/analysis/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=[array([RangeIndex(start=0, stop=3000, step=1),\n",
       "       RangeIndex(start=3000, stop=3100, step=1)], dtype=object), array([RangeIndex(start=3100, stop=6100, step=1),\n",
       "       RangeIndex(start=6100, stop=6200, step=1)], dtype=object), array([RangeIndex(start=6200, stop=9200, step=1),\n",
       "       RangeIndex...2400, stop=6215400, step=1),\n",
       "       RangeIndex(start=6215400, stop=6215447, step=1)], dtype=object)],\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid=[{'kernel': ['rbf'], 'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.001, 0.0001], 'cache_size': [2000], 'class_weight': [{0: 0.5, 1: 0.5}, {0: 0.6, 1: 0.4}, {0: 0.7, 1: 0.3}, {0: 0.8, 1: 0.2}]}, {'kernel': ['poly'], 'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.001, 0.0001], 'degree': [3, 5], 'cache_size': [2000], 'class_weight': [{0: 0.5, 1: 0.5}, {0: 0.6, 1: 0.4}, {0: 0.7, 1: 0.3}]}],\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score='warn',\n",
       "       scoring=['precision'], verbose=1)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use all cores (n_jobs-1)\n",
    "gridcv = GridSearchCV(svm.SVC(), params, verbose=1, cv=list(splits), n_jobs=-1, \n",
    "                    scoring=['precision'], refit=False)\n",
    "\n",
    "gridcv.fit(multi_cv_df, multi_cv_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the object to a file\n",
    "with open(save_dir+'gridsearch_results.pkl', 'wb') as f:\n",
    "    pickle.dump(gridcv, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
