{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import SGD\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "\n",
    "os.chdir('../Utils/')\n",
    "import featureGenerator\n",
    "from featureGenerator import *\n",
    "os.chdir('../src/')\n",
    "import orderbook_lstm\n",
    "from orderbook_lstm import OrderBookLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features and Response Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../../../ProjectData/'\n",
    "in_path = data_dir+'msft-orderbook.csv'\n",
    "out_path = data_dir+'msft-orderbook-all.csv'\n",
    "out_path2 = data_dir+'msft-orderbook-final.csv'\n",
    "response_type = \"Regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['msft-20170417-orderbook.csv', 'msft-20170418-orderbook.csv', 'msft-20170419-orderbook.csv', 'msft-20170420-orderbook.csv', 'msft-20170421-orderbook.csv', 'msft-20170424-orderbook.csv', 'msft-20170425-orderbook.csv', 'msft-20170426-orderbook.csv', 'msft-20170427-orderbook.csv', 'msft-20170428-orderbook.csv']\n",
      "../../../../ProjectData/msft-20170417-orderbook.csv\n",
      "../../../../ProjectData/msft-20170418-orderbook.csv\n",
      "../../../../ProjectData/msft-20170419-orderbook.csv\n",
      "../../../../ProjectData/msft-20170420-orderbook.csv\n",
      "../../../../ProjectData/msft-20170421-orderbook.csv\n",
      "../../../../ProjectData/msft-20170424-orderbook.csv\n",
      "../../../../ProjectData/msft-20170425-orderbook.csv\n",
      "../../../../ProjectData/msft-20170426-orderbook.csv\n",
      "../../../../ProjectData/msft-20170427-orderbook.csv\n",
      "../../../../ProjectData/msft-20170428-orderbook.csv\n"
     ]
    }
   ],
   "source": [
    "mergeOrderBookDays(data_dir, out_path, ['msft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/Desktop/Stanford/MSE 448/448Project/448Project/LSTM/Utils/featureGenerator.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data['Response'] = response_col\n"
     ]
    }
   ],
   "source": [
    "createFeatures(out_path, out_path2, response_type = response_type, look_forward =1)\n",
    "data = pd.read_csv(out_path2)\n",
    "data_orig = pd.read_csv(out_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>direct.vwap</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.100361</td>\n",
       "      <td>65.081990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.081990</td>\n",
       "      <td>65.097505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.097505</td>\n",
       "      <td>65.099488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.099488</td>\n",
       "      <td>65.101385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.101385</td>\n",
       "      <td>65.101807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   direct.vwap   Response\n",
       "0    65.100361  65.081990\n",
       "1    65.081990  65.097505\n",
       "2    65.097505  65.099488\n",
       "3    65.099488  65.101385\n",
       "4    65.101385  65.101807"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(out_path2)\n",
    "#data = data.drop(['datetime', 'direct.last_SRO'], axis = 1)\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cols_to_normalize = [col for col in data.columns if col != 'Response']\n",
    "data[cols_to_normalize] = scaler.fit_transform(data[cols_to_normalize])\n",
    "\n",
    "dataset = data.values\n",
    "dataset = dataset.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "corr = data.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots\n",
    "data_orig = pd.read_csv(out_path)\n",
    "\n",
    "plt.plot(np.arange(len(data_orig)), data_orig['direct.bsize1'])\n",
    "plt.plot(np.arange(len(data_orig)),data_orig['direct.bsize2'])\n",
    "plt.plot(np.arange(len(data_orig)),data_orig['direct.bsize3'])\n",
    "plt.plot(np.arange(len(data_orig)),data_orig['direct.bsize4'])\n",
    "plt.plot(np.arange(len(data_orig)),data_orig['direct.bsize5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156779 77220\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back, response_type):\n",
    "    if response_type == 'Classification':\n",
    "        dataY = get_one_hot(dataset[look_back+1:,dataset.shape[1]-1].astype(int).reshape(-1),3)\n",
    "        dataX = []\n",
    "        for i in range(len(dataset)-look_back-1):\n",
    "            a = dataset[i:(i+look_back), :]    \n",
    "            dataX.append(a)\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "    \n",
    "    elif response_type == 'Regression':\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-look_back-1):\n",
    "            a = dataset[i:(i+look_back), :]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i, dataset.shape[1]-1])\n",
    "            #print(i + look_back)\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert response variable to one-hot vectors\n",
    "def get_one_hot(targets, nb_classes):\n",
    "    return np.eye(nb_classes)[np.array(targets).reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 30\n",
    "trainX, trainY = create_dataset(train, look_back, response_type = response_type)\n",
    "testX, testY = create_dataset(test, look_back, response_type = response_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building regression model...\n",
      "Compiling model...\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "os.chdir('../src/')\n",
    "import orderbook_lstm\n",
    "from orderbook_lstm import OrderBookLSTM\n",
    "reload(orderbook_lstm)\n",
    "\n",
    "#tf.reset_default_graph()\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "#timesteps = 10\n",
    "n_features = 69\n",
    "n_neurons = 100\n",
    "n_classes = 3\n",
    "n_hidden = 1\n",
    "dropout = None\n",
    "\n",
    "#lstm = OrderBookLSTM(lookback, n_neurons, (timesteps,n_features), n_classes, n_hidden, response_type, dropout)\n",
    "\n",
    "lstm = OrderBookLSTM(timesteps = look_back, \n",
    "                     layer_neurons = 100, \n",
    "                     input_shape = (look_back,1), \n",
    "                     output_shape = 3, # doesn't matter if regression\n",
    "                     num_hidden_layers = 0, \n",
    "                     response_type = response_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = lstm.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 30, 100)           40800     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 3001      \n",
      "=================================================================\n",
      "Total params: 43,801\n",
      "Trainable params: 43,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Class weights to change\n",
    "class_weight = {0 : 1.,\n",
    "    1: 1.,\n",
    "    2: 1.} \n",
    "\n",
    "if response_type == 'Classification':\n",
    "    mod.fit(trainX, trainY, validation_data=([testX, testY]), \n",
    "              epochs=5,  \n",
    "              batch_size=128, \n",
    "              verbose=1, \n",
    "              class_weight = class_weight,\n",
    "              callbacks=[TensorBoard(log_dir='Logs/', write_graph=True)])\n",
    "    \n",
    "\n",
    "if response_type == 'Regression':\n",
    "    mod.fit(trainX, trainY, validation_data=([testX, testY]),\n",
    "              epochs=5,  \n",
    "              batch_size=256, \n",
    "              verbose=1, \n",
    "              callbacks=[TensorBoard(log_dir='Logs/', write_graph=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(dataset[:,68], return_counts=True)\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions and get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Error\n",
    "if response_type == 'Classification':\n",
    "    preds_training = mod.predict(trainX).argmax(axis=-1)\n",
    "    pd.Series(preds_training).value_counts()\n",
    "    precision_recall_fscore_support(np.argmax(trainY, axis=1), preds_training)\n",
    "else:\n",
    "    preds_training = mod.predict(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Error\n",
    "if response_type == 'Classification':\n",
    "    preds = mod.predict(testX).argmax(axis=-1)\n",
    "    pd.Series(preds).value_counts()\n",
    "    print(precision_recall_fscore_support(np.argmax(testY, axis=1), preds))\n",
    "    preds_probs = mod.predict(testX)\n",
    "else:\n",
    "    preds_test = mod.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(class_labels, preds)\n",
    "df_cm = pd.DataFrame(cm, range(3),\n",
    "                  range(3))\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 10})# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "l = list(preds)\n",
    "Counter(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate PnL (+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "starting_money = 10000\n",
    "pnl_lstm = 0\n",
    "buffer = 0.05\n",
    "pnl_history_lstm = []\n",
    "pnl_history_by_trade = []\n",
    "\n",
    "if response_type == 'Regression':\n",
    "    for i in range(len(testX)):\n",
    "        pred = preds_test[i][0]\n",
    "        current = testY[i] \n",
    "        \n",
    "        '''\n",
    "        At time t:\n",
    "         - if pred > current:\n",
    "             - buy at ask price\n",
    "         \n",
    "         - if pred < current:\n",
    "             - sell at bid price\n",
    "             \n",
    "             \n",
    "        At time t+1:\n",
    "        Liquidate assets\n",
    "        \n",
    "         - if bought at time t:\n",
    "             - sell at bid price at t + 1\n",
    "             \n",
    "         - if sold at time t:\n",
    "             - buy at bid price at t + 1\n",
    "             \n",
    "        '''\n",
    "        buy_bool = None\n",
    "        buy_price = None\n",
    "        sell_price = None\n",
    "        amount_buy = 1\n",
    "        amount_sell = 1\n",
    "        \n",
    "        \n",
    "        # buy\n",
    "        if pred > (current + buffer):\n",
    "            '''\n",
    "            - Buy at ask price\n",
    "            - \n",
    "            '''\n",
    "            buy_bool = True\n",
    "            buy_price = data_orig.loc[i, 'direct.ask1']\n",
    "            amount_buy = 1000\n",
    "        # sell\n",
    "        elif pred < (current - buffer):\n",
    "            '''\n",
    "            Sell at bid price\n",
    "            '''\n",
    "            buy_bool = False\n",
    "            sell_price = data_orig.loc[i, 'direct.bid1']\n",
    "            amount_sell = 1000\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        # liquidate\n",
    "        if buy_bool == True:\n",
    "            ask_next = data_orig.loc[i+1, 'direct.ask1']\n",
    "            pnl_lstm += (ask_next - buy_price) * amount_buy\n",
    "            pnl_history_by_trade.append((ask_next - buy_price) * amount_buy)\n",
    "            \n",
    "        else:\n",
    "            bid_next = data_orig.loc[i+1, 'direct.bid1']\n",
    "            pnl_lstm += (bid_next - sell_price) * amount_sell\n",
    "            pnl_history_by_trade.append((bid_next - sell_price) * amount_sell)\n",
    "        \n",
    "        pnl_history_lstm.append(pnl_lstm) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VWAP Crossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_money = 10000\n",
    "pnl_lstm = 0\n",
    "buffer = 0.05\n",
    "pnl_history_lstm = []\n",
    "pnl_history_by_trade = []\n",
    "\n",
    "inventory = 1000\n",
    "inventory_history = [1000]\n",
    "\n",
    "test_data = data_orig.loc[train_size:len(data_orig),:].reset_index(drop = True)\n",
    "\n",
    "\n",
    "n = len(testX)\n",
    "n = 50\n",
    "if response_type == 'Regression':\n",
    "    for i in range(n):\n",
    "        pred = preds_test[i][0]\n",
    "        current_ask = test_data.loc[i, 'direct.ask1']\n",
    "        current_bid = test_data.loc[i, 'direct.bid1']\n",
    "\n",
    "        '''\n",
    "        At time t:\n",
    "         - if pred > current_ask:\n",
    "             - buy at ask price\n",
    "         \n",
    "         - if pred < current_bid:\n",
    "             - sell at bid price\n",
    "             \n",
    "             \n",
    "        At time t+1:\n",
    "        Liquidate assets\n",
    "        \n",
    "         - if bought at time t:\n",
    "             - sell at bid price at t + 1\n",
    "             \n",
    "         - if sold at time t:\n",
    "             - buy at bid price at t + 1\n",
    "             \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        # buy\n",
    "        if pred > (current_ask + buffer):\n",
    "            '''\n",
    "            - Buy at ask price\n",
    "            '''\n",
    "            amount_buy = 100\n",
    "            inventory += amount_buy\n",
    "            inventory_history.append(inventory_history[len(inventory_history)-1] + amount_buy)\n",
    "            buy_bool = True\n",
    "            \n",
    "        # sell\n",
    "        elif pred < (current_bid - buffer):\n",
    "            '''\n",
    "            Sell at bid price\n",
    "            '''\n",
    "            amount_sell = 100\n",
    "            inventory -= amount_sell\n",
    "            inventory_history.append(inventory_history[len(inventory_history)-1] - amount_sell)\n",
    "            buy_bool = False\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        # liquidate\n",
    "        #if i % 60 == 0 and i > 0:\n",
    "        if buy_bool == True:\n",
    "            \n",
    "            ask_next = data_orig.loc[i+1, 'direct.ask1']\n",
    "            pnl_lstm += (ask_next - current_ask) * amount_buy\n",
    "            pnl_history_by_trade.append((ask_next - current_ask) * amount_buy)\n",
    "            \n",
    "        else:\n",
    "            bid_next = data_orig.loc[i+1, 'direct.bid1']\n",
    "            pnl_lstm += (bid_next - current_bid) * amount_sell\n",
    "            pnl_history_by_trade.append((bid_next - current_bid) * amount_sell)\n",
    "        \n",
    "        pnl_history_lstm.append(pnl_lstm) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(pnl_history_lstm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PnL (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_money = 100000\n",
    "stop_loss = -50000\n",
    "pnl_lstm = 0\n",
    "pnl_history_lstm = []\n",
    "pnl_history_by_trade = []\n",
    "prob_limit = 0.8\n",
    "inventory = [1000]\n",
    "\n",
    "test_data = data_orig.loc[train_size:len(data_orig),:].reset_index(drop = True)\n",
    "\n",
    "if response_type == 'Classification':\n",
    "    for i in range(len(testX)):\n",
    "        pred = preds[i]\n",
    "        prob = preds_probs[i][pred]\n",
    "        if prob < prob_limit:\n",
    "            continue\n",
    "\n",
    "        '''\n",
    "        At time t:\n",
    "         - if pred > current:\n",
    "             - buy at ask price\n",
    "         \n",
    "         - if pred < current:\n",
    "             - sell at bid price\n",
    "             \n",
    "             \n",
    "        At time t+1:\n",
    "        Liquidate assets\n",
    "        \n",
    "         - if bought at time t:\n",
    "             - sell at bid price at t + 1\n",
    "             \n",
    "         - if sold at time t:\n",
    "             - buy at bid price at t + 1\n",
    "             \n",
    "        '''\n",
    "        #buy_bool = None\n",
    "        #buy_price = None\n",
    "        #sell_price = None\n",
    "        #amount_buy = 1\n",
    "        #amount_sell = 1\n",
    "        \n",
    "        # buy\n",
    "        if pred == 1:\n",
    "            '''\n",
    "            - Buy at ask price\n",
    "            - \n",
    "            '''\n",
    "            buy_price = test_data.loc[i, 'direct.ask1']\n",
    "            amount_buy = 100*prob\n",
    "            buy_bool = True\n",
    "            \n",
    "        \n",
    "        # sell\n",
    "        elif pred == 2:\n",
    "            '''\n",
    "            Sell at bid price\n",
    "            '''\n",
    "            #if inventory - 100*prob >= 0:\n",
    "            sell_price = test_data.loc[i, 'direct.bid1']\n",
    "            amount_sell = 100*prob\n",
    "            buy_bool = False\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        if buy_bool == True:\n",
    "            ask_next = test_data.loc[i+1, 'direct.ask1']\n",
    "            pnl_lstm += (ask_next - buy_price) * amount_buy\n",
    "            pnl_history_by_trade.append((ask_next - buy_price) * amount_buy)\n",
    "\n",
    "        else:\n",
    "            bid_next = test_data.loc[i+1, 'direct.bid1']\n",
    "            pnl_lstm += (bid_next - sell_price) * amount_sell\n",
    "            pnl_history_by_trade.append((bid_next - sell_price) * amount_sell)\n",
    "\n",
    "        \n",
    "        \n",
    "        pnl_history_lstm.append(pnl_lstm) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(pnl_history_lstm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in pnl_history_by_trade if x > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in pnl_history_by_trade if x < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive strategy: predict mid price/vwap/AREA for the next time period. If we predict the this metric will go up, we buy. If we predict the metric will go down, we sell. We close positions after each time period. Calculate PnL for that period as ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weights to change\n",
    "class_weight = {0 : 1.,\n",
    "    1: 15.,\n",
    "    2: 18.} \n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(5,69), return_sequences=False))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "model.fit(trainX, trainY, \n",
    "          epochs=2,  \n",
    "          batch_size=10, \n",
    "          #verbose=2, \n",
    "          class_weight = class_weight,\n",
    "          callbacks=[TensorBoard(log_dir='Logs/testlog', write_graph=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(testX).argmax(axis=-1)\n",
    "pd.Series(preds).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(np.argmax(testY, axis=1), preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
